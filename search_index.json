[["index.html", "A Taxonomy of Data Synthesis: A Tutorial Chapter 1 Workspace 1.1 Packages 1.2 Directory Path 1.3 Introduction 1.4 Codebook 1.5 Navigating This Tutorial", " A Taxonomy of Data Synthesis: A Tutorial Emorie D. Beck Feinberg School of Medicine Emily C. Willroth Feinberg School of Medicine Daniel K. Mroczek Feinberg School of Medicine, Northwestern University Eileen K. Graham Feinberg School of Medicine 16 May 2024 Chapter 1 Workspace In this section, we’ll set up everything we need to clean data in the next section. This includes: Loading in all packages Loading in the codebook Setting up data frames for personality traits / well-being, outcomes, covariates, and moderators, so that we can more easily rename their short-hand names to production ready ones later Loading in and rendering html tables of some descriptives, measures, etc. 1.1 Packages library(psych) # psychometrics library(knitr) # knit documents library(kableExtra) # formatted tables library(brms) # bayesian models library(readxl) # read excel files library(haven) # read spss files library(estimatr) # robust standard error regression library(lme4) # Frequentist MLM library(broom.mixed) # summaries of models library(bootpredictlme4) # for calculating prediction intervals library(effectsize) # effect sizes for meta-analysis library(metafor) # Frequentist meta-analysis library(rstan) # bayes underpinnings library(tidybayes) # pretty bayes draws and plots library(cowplot) # Plotting and faceting library(plyr) # data wrangling library(tidyverse) # data wrangling library(furrr) # parallel purrr mapping pkg &lt;- c(&quot;psych&quot;,&quot;knitr&quot;,&quot;kableExtra&quot;,&quot;brms&quot;,&quot;readxl&quot;,&quot;haven&quot;,&quot;estimatr&quot;, &quot;lme4&quot;,&quot;broom.mixed&quot;,&quot;bootpredictlme4&quot;,&quot;effectsize&quot;,&quot;metafor&quot;, &quot;rstan&quot;,&quot;tidybayes&quot;,&quot;cowplot&quot;,&quot;plyr&quot;,&quot;tidyverse&quot;,&quot;furrr&quot;) lapply(pkg[!pkg %in% rownames(installed.packages())], function(x) install.packages(x)) ## list() lapply(pkg, function(x) print(citation(x), bibtex = T)) ## To cite package &#39;psych&#39; in publications use: ## ## William Revelle (2024). _psych: Procedures for Psychological, Psychometric, and Personality Research_. ## Northwestern University, Evanston, Illinois. R package version 2.4.1, ## &lt;https://CRAN.R-project.org/package=psych&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {psych: Procedures for Psychological, Psychometric, and Personality Research}, ## author = {{William Revelle}}, ## organization = {Northwestern University}, ## address = {Evanston, Illinois}, ## year = {2024}, ## note = {R package version 2.4.1}, ## url = {https://CRAN.R-project.org/package=psych}, ## } ## To cite package &#39;knitr&#39; in publications use: ## ## Xie Y (2023). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.45, ## &lt;https://yihui.org/knitr/&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {knitr: A General-Purpose Package for Dynamic Report Generation in R}, ## author = {Yihui Xie}, ## year = {2023}, ## note = {R package version 1.45}, ## url = {https://yihui.org/knitr/}, ## } ## ## Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition. Chapman and Hall/CRC. ISBN 978-1498716963 ## ## A BibTeX entry for LaTeX users is ## ## @Book{, ## title = {Dynamic Documents with {R} and knitr}, ## author = {Yihui Xie}, ## publisher = {Chapman and Hall/CRC}, ## address = {Boca Raton, Florida}, ## year = {2015}, ## edition = {2nd}, ## note = {ISBN 978-1498716963}, ## url = {https://yihui.org/knitr/}, ## } ## ## Yihui Xie (2014) knitr: A Comprehensive Tool for Reproducible Research in R. In Victoria Stodden, Friedrich ## Leisch and Roger D. Peng, editors, Implementing Reproducible Computational Research. Chapman and Hall/CRC. ## ISBN 978-1466561595 ## ## A BibTeX entry for LaTeX users is ## ## @InCollection{, ## booktitle = {Implementing Reproducible Computational Research}, ## editor = {Victoria Stodden and Friedrich Leisch and Roger D. Peng}, ## title = {knitr: A Comprehensive Tool for Reproducible Research in {R}}, ## author = {Yihui Xie}, ## publisher = {Chapman and Hall/CRC}, ## year = {2014}, ## note = {ISBN 978-1466561595}, ## } ## To cite package &#39;kableExtra&#39; in publications use: ## ## Zhu H (2024). _kableExtra: Construct Complex Table with &#39;kable&#39; and Pipe Syntax_. R package version 1.4.0, ## &lt;https://CRAN.R-project.org/package=kableExtra&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {kableExtra: Construct Complex Table with &#39;kable&#39; and Pipe Syntax}, ## author = {Hao Zhu}, ## year = {2024}, ## note = {R package version 1.4.0}, ## url = {https://CRAN.R-project.org/package=kableExtra}, ## } ## To cite brms in publications use: ## ## Paul-Christian Bürkner (2017). brms: An R Package for Bayesian Multilevel Models Using Stan. Journal of ## Statistical Software, 80(1), 1-28. doi:10.18637/jss.v080.i01 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {{brms}: An {R} Package for {Bayesian} Multilevel Models Using {Stan}}, ## author = {Paul-Christian Bürkner}, ## journal = {Journal of Statistical Software}, ## year = {2017}, ## volume = {80}, ## number = {1}, ## pages = {1--28}, ## doi = {10.18637/jss.v080.i01}, ## encoding = {UTF-8}, ## } ## ## Paul-Christian Bürkner (2018). Advanced Bayesian Multilevel Modeling with the R Package brms. The R Journal, ## 10(1), 395-411. doi:10.32614/RJ-2018-017 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Advanced {Bayesian} Multilevel Modeling with the {R} Package {brms}}, ## author = {Paul-Christian Bürkner}, ## journal = {The R Journal}, ## year = {2018}, ## volume = {10}, ## number = {1}, ## pages = {395--411}, ## doi = {10.32614/RJ-2018-017}, ## encoding = {UTF-8}, ## } ## ## Paul-Christian Bürkner (2021). Bayesian Item Response Modeling in R with brms and Stan. Journal of Statistical ## Software, 100(5), 1-54. doi:10.18637/jss.v100.i05 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Bayesian Item Response Modeling in {R} with {brms} and {Stan}}, ## author = {Paul-Christian Bürkner}, ## journal = {Journal of Statistical Software}, ## year = {2021}, ## volume = {100}, ## number = {5}, ## pages = {1--54}, ## doi = {10.18637/jss.v100.i05}, ## encoding = {UTF-8}, ## } ## To cite package &#39;readxl&#39; in publications use: ## ## Wickham H, Bryan J (2023). _readxl: Read Excel Files_. R package version 1.4.3, ## &lt;https://CRAN.R-project.org/package=readxl&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {readxl: Read Excel Files}, ## author = {Hadley Wickham and Jennifer Bryan}, ## year = {2023}, ## note = {R package version 1.4.3}, ## url = {https://CRAN.R-project.org/package=readxl}, ## } ## To cite package &#39;haven&#39; in publications use: ## ## Wickham H, Miller E, Smith D (2023). _haven: Import and Export &#39;SPSS&#39;, &#39;Stata&#39; and &#39;SAS&#39; Files_. R package ## version 2.5.4, &lt;https://CRAN.R-project.org/package=haven&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {haven: Import and Export &#39;SPSS&#39;, &#39;Stata&#39; and &#39;SAS&#39; Files}, ## author = {Hadley Wickham and Evan Miller and Danny Smith}, ## year = {2023}, ## note = {R package version 2.5.4}, ## url = {https://CRAN.R-project.org/package=haven}, ## } ## To cite package &#39;estimatr&#39; in publications use: ## ## Blair G, Cooper J, Coppock A, Humphreys M, Sonnet L (2024). _estimatr: Fast Estimators for Design-Based ## Inference_. R package version 1.0.2, &lt;https://CRAN.R-project.org/package=estimatr&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {estimatr: Fast Estimators for Design-Based Inference}, ## author = {Graeme Blair and Jasper Cooper and Alexander Coppock and Macartan Humphreys and Luke Sonnet}, ## year = {2024}, ## note = {R package version 1.0.2}, ## url = {https://CRAN.R-project.org/package=estimatr}, ## } ## To cite lme4 in publications use: ## ## Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using ## lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01. ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Fitting Linear Mixed-Effects Models Using {lme4}}, ## author = {Douglas Bates and Martin M{\\&quot;a}chler and Ben Bolker and Steve Walker}, ## journal = {Journal of Statistical Software}, ## year = {2015}, ## volume = {67}, ## number = {1}, ## pages = {1--48}, ## doi = {10.18637/jss.v067.i01}, ## } ## To cite package &#39;broom.mixed&#39; in publications use: ## ## Bolker B, Robinson D (2022). _broom.mixed: Tidying Methods for Mixed Models_. R package version 0.2.9.4, ## &lt;https://CRAN.R-project.org/package=broom.mixed&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {broom.mixed: Tidying Methods for Mixed Models}, ## author = {Ben Bolker and David Robinson}, ## year = {2022}, ## note = {R package version 0.2.9.4}, ## url = {https://CRAN.R-project.org/package=broom.mixed}, ## } ## To cite package &#39;bootpredictlme4&#39; in publications use: ## ## Duursma R (2024). _bootpredictlme4: Predict Method For lme4 With Bootstrap_. R package version 0.1. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {bootpredictlme4: Predict Method For lme4 With Bootstrap}, ## author = {Remko Duursma}, ## year = {2024}, ## note = {R package version 0.1}, ## } ## ## ATTENTION: This citation information has been auto-generated from the package DESCRIPTION file and may need ## manual editing, see &#39;help(&quot;citation&quot;)&#39;. ## To cite effectsize in publications use: ## ## Ben-Shachar M, Lüdecke D, Makowski D (2020). effectsize: Estimation of Effect Size Indices and Standardized ## Parameters. Journal of Open Source Software, 5(56), 2815. doi: 10.21105/joss.02815 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {{e}ffectsize: Estimation of Effect Size Indices and Standardized Parameters}, ## author = {Mattan S. Ben-Shachar and Daniel Lüdecke and Dominique Makowski}, ## year = {2020}, ## journal = {Journal of Open Source Software}, ## volume = {5}, ## number = {56}, ## pages = {2815}, ## publisher = {The Open Journal}, ## doi = {10.21105/joss.02815}, ## url = {https://doi.org/10.21105/joss.02815}, ## } ## To cite the metafor package in publications, please use: ## ## Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. Journal of Statistical ## Software, 36(3), 1-48. https://doi.org/10.18637/jss.v036.i03 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Conducting meta-analyses in {R} with the {metafor} package}, ## author = {Wolfgang Viechtbauer}, ## journal = {Journal of Statistical Software}, ## year = {2010}, ## volume = {36}, ## number = {3}, ## pages = {1--48}, ## doi = {10.18637/jss.v036.i03}, ## } ## To cite RStan in publications use: ## ## Stan Development Team (2024). RStan: the R interface to Stan. R package version 2.32.5. https://mc-stan.org/. ## ## A BibTeX entry for LaTeX users is ## ## @Misc{, ## title = {{RStan}: the {R} interface to {Stan}}, ## author = {{Stan Development Team}}, ## note = {R package version 2.32.5}, ## year = {2024}, ## url = {https://mc-stan.org/}, ## } ## To cite package &#39;tidybayes&#39; in publications use: ## ## Kay M (2023). _tidybayes: Tidy Data and Geoms for Bayesian Models_. doi:10.5281/zenodo.1308151 ## &lt;https://doi.org/10.5281/zenodo.1308151&gt;, R package version 3.0.6, &lt;http://mjskay.github.io/tidybayes/&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {{tidybayes}: Tidy Data and Geoms for {Bayesian} Models}, ## author = {Matthew Kay}, ## year = {2023}, ## note = {R package version 3.0.6}, ## url = {http://mjskay.github.io/tidybayes/}, ## doi = {10.5281/zenodo.1308151}, ## } ## To cite package &#39;cowplot&#39; in publications use: ## ## Wilke C (2024). _cowplot: Streamlined Plot Theme and Plot Annotations for &#39;ggplot2&#39;_. R package version ## 1.1.3, &lt;https://CRAN.R-project.org/package=cowplot&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {cowplot: Streamlined Plot Theme and Plot Annotations for &#39;ggplot2&#39;}, ## author = {Claus O. Wilke}, ## year = {2024}, ## note = {R package version 1.1.3}, ## url = {https://CRAN.R-project.org/package=cowplot}, ## } ## To cite package &#39;plyr&#39; in publications use: ## ## Hadley Wickham (2011). The Split-Apply-Combine Strategy for Data Analysis. Journal of Statistical Software, ## 40(1), 1-29. URL https://www.jstatsoft.org/v40/i01/. ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {The Split-Apply-Combine Strategy for Data Analysis}, ## author = {Hadley Wickham}, ## journal = {Journal of Statistical Software}, ## year = {2011}, ## volume = {40}, ## number = {1}, ## pages = {1--29}, ## url = {https://www.jstatsoft.org/v40/i01/}, ## } ## To cite package &#39;tidyverse&#39; in publications use: ## ## Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn ## M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, ## Wilke C, Woo K, Yutani H (2019). &quot;Welcome to the tidyverse.&quot; _Journal of Open Source Software_, *4*(43), ## 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Welcome to the {tidyverse}}, ## author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D&#39;Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani}, ## year = {2019}, ## journal = {Journal of Open Source Software}, ## volume = {4}, ## number = {43}, ## pages = {1686}, ## doi = {10.21105/joss.01686}, ## } ## To cite package &#39;furrr&#39; in publications use: ## ## Vaughan D, Dancho M (2022). _furrr: Apply Mapping Functions in Parallel using Futures_. R package version ## 0.3.1, &lt;https://CRAN.R-project.org/package=furrr&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {furrr: Apply Mapping Functions in Parallel using Futures}, ## author = {Davis Vaughan and Matt Dancho}, ## year = {2022}, ## note = {R package version 0.3.1}, ## url = {https://CRAN.R-project.org/package=furrr}, ## } ## [[1]] ## To cite package &#39;psych&#39; in publications use: ## ## William Revelle (2024). _psych: Procedures for Psychological, Psychometric, and Personality Research_. ## Northwestern University, Evanston, Illinois. R package version 2.4.1, ## &lt;https://CRAN.R-project.org/package=psych&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {psych: Procedures for Psychological, Psychometric, and Personality Research}, ## author = {{William Revelle}}, ## organization = {Northwestern University}, ## address = {Evanston, Illinois}, ## year = {2024}, ## note = {R package version 2.4.1}, ## url = {https://CRAN.R-project.org/package=psych}, ## } ## ## [[2]] ## To cite package &#39;knitr&#39; in publications use: ## ## Xie Y (2023). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.45, ## &lt;https://yihui.org/knitr/&gt;. ## ## Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition. Chapman and Hall/CRC. ISBN 978-1498716963 ## ## Yihui Xie (2014) knitr: A Comprehensive Tool for Reproducible Research in R. In Victoria Stodden, Friedrich ## Leisch and Roger D. Peng, editors, Implementing Reproducible Computational Research. Chapman and Hall/CRC. ## ISBN 978-1466561595 ## ## To see these entries in BibTeX format, use &#39;print(&lt;citation&gt;, bibtex=TRUE)&#39;, &#39;toBibtex(.)&#39;, or set ## &#39;options(citation.bibtex.max=999)&#39;. ## ## [[3]] ## To cite package &#39;kableExtra&#39; in publications use: ## ## Zhu H (2024). _kableExtra: Construct Complex Table with &#39;kable&#39; and Pipe Syntax_. R package version 1.4.0, ## &lt;https://CRAN.R-project.org/package=kableExtra&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {kableExtra: Construct Complex Table with &#39;kable&#39; and Pipe Syntax}, ## author = {Hao Zhu}, ## year = {2024}, ## note = {R package version 1.4.0}, ## url = {https://CRAN.R-project.org/package=kableExtra}, ## } ## ## [[4]] ## To cite brms in publications use: ## ## Paul-Christian Bürkner (2017). brms: An R Package for Bayesian Multilevel Models Using Stan. Journal of ## Statistical Software, 80(1), 1-28. doi:10.18637/jss.v080.i01 ## ## Paul-Christian Bürkner (2018). Advanced Bayesian Multilevel Modeling with the R Package brms. The R Journal, ## 10(1), 395-411. doi:10.32614/RJ-2018-017 ## ## Paul-Christian Bürkner (2021). Bayesian Item Response Modeling in R with brms and Stan. Journal of Statistical ## Software, 100(5), 1-54. doi:10.18637/jss.v100.i05 ## ## To see these entries in BibTeX format, use &#39;print(&lt;citation&gt;, bibtex=TRUE)&#39;, &#39;toBibtex(.)&#39;, or set ## &#39;options(citation.bibtex.max=999)&#39;. ## ## [[5]] ## To cite package &#39;readxl&#39; in publications use: ## ## Wickham H, Bryan J (2023). _readxl: Read Excel Files_. R package version 1.4.3, ## &lt;https://CRAN.R-project.org/package=readxl&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {readxl: Read Excel Files}, ## author = {Hadley Wickham and Jennifer Bryan}, ## year = {2023}, ## note = {R package version 1.4.3}, ## url = {https://CRAN.R-project.org/package=readxl}, ## } ## ## [[6]] ## To cite package &#39;haven&#39; in publications use: ## ## Wickham H, Miller E, Smith D (2023). _haven: Import and Export &#39;SPSS&#39;, &#39;Stata&#39; and &#39;SAS&#39; Files_. R package ## version 2.5.4, &lt;https://CRAN.R-project.org/package=haven&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {haven: Import and Export &#39;SPSS&#39;, &#39;Stata&#39; and &#39;SAS&#39; Files}, ## author = {Hadley Wickham and Evan Miller and Danny Smith}, ## year = {2023}, ## note = {R package version 2.5.4}, ## url = {https://CRAN.R-project.org/package=haven}, ## } ## ## [[7]] ## To cite package &#39;estimatr&#39; in publications use: ## ## Blair G, Cooper J, Coppock A, Humphreys M, Sonnet L (2024). _estimatr: Fast Estimators for Design-Based ## Inference_. R package version 1.0.2, &lt;https://CRAN.R-project.org/package=estimatr&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {estimatr: Fast Estimators for Design-Based Inference}, ## author = {Graeme Blair and Jasper Cooper and Alexander Coppock and Macartan Humphreys and Luke Sonnet}, ## year = {2024}, ## note = {R package version 1.0.2}, ## url = {https://CRAN.R-project.org/package=estimatr}, ## } ## ## [[8]] ## To cite lme4 in publications use: ## ## Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using ## lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01. ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Fitting Linear Mixed-Effects Models Using {lme4}}, ## author = {Douglas Bates and Martin M{\\&quot;a}chler and Ben Bolker and Steve Walker}, ## journal = {Journal of Statistical Software}, ## year = {2015}, ## volume = {67}, ## number = {1}, ## pages = {1--48}, ## doi = {10.18637/jss.v067.i01}, ## } ## ## [[9]] ## To cite package &#39;broom.mixed&#39; in publications use: ## ## Bolker B, Robinson D (2022). _broom.mixed: Tidying Methods for Mixed Models_. R package version 0.2.9.4, ## &lt;https://CRAN.R-project.org/package=broom.mixed&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {broom.mixed: Tidying Methods for Mixed Models}, ## author = {Ben Bolker and David Robinson}, ## year = {2022}, ## note = {R package version 0.2.9.4}, ## url = {https://CRAN.R-project.org/package=broom.mixed}, ## } ## ## [[10]] ## To cite package &#39;bootpredictlme4&#39; in publications use: ## ## Duursma R (2024). _bootpredictlme4: Predict Method For lme4 With Bootstrap_. R package version 0.1. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {bootpredictlme4: Predict Method For lme4 With Bootstrap}, ## author = {Remko Duursma}, ## year = {2024}, ## note = {R package version 0.1}, ## } ## ## ATTENTION: This citation information has been auto-generated from the package DESCRIPTION file and may need ## manual editing, see &#39;help(&quot;citation&quot;)&#39;. ## ## [[11]] ## To cite effectsize in publications use: ## ## Ben-Shachar M, Lüdecke D, Makowski D (2020). effectsize: Estimation of Effect Size Indices and Standardized ## Parameters. Journal of Open Source Software, 5(56), 2815. doi: 10.21105/joss.02815 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {{e}ffectsize: Estimation of Effect Size Indices and Standardized Parameters}, ## author = {Mattan S. Ben-Shachar and Daniel Lüdecke and Dominique Makowski}, ## year = {2020}, ## journal = {Journal of Open Source Software}, ## volume = {5}, ## number = {56}, ## pages = {2815}, ## publisher = {The Open Journal}, ## doi = {10.21105/joss.02815}, ## url = {https://doi.org/10.21105/joss.02815}, ## } ## ## [[12]] ## To cite the metafor package in publications, please use: ## ## Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. Journal of Statistical ## Software, 36(3), 1-48. https://doi.org/10.18637/jss.v036.i03 ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Conducting meta-analyses in {R} with the {metafor} package}, ## author = {Wolfgang Viechtbauer}, ## journal = {Journal of Statistical Software}, ## year = {2010}, ## volume = {36}, ## number = {3}, ## pages = {1--48}, ## doi = {10.18637/jss.v036.i03}, ## } ## ## [[13]] ## To cite RStan in publications use: ## ## Stan Development Team (2024). RStan: the R interface to Stan. R package version 2.32.5. https://mc-stan.org/. ## ## A BibTeX entry for LaTeX users is ## ## @Misc{, ## title = {{RStan}: the {R} interface to {Stan}}, ## author = {{Stan Development Team}}, ## note = {R package version 2.32.5}, ## year = {2024}, ## url = {https://mc-stan.org/}, ## } ## ## [[14]] ## To cite package &#39;tidybayes&#39; in publications use: ## ## Kay M (2023). _tidybayes: Tidy Data and Geoms for Bayesian Models_. doi:10.5281/zenodo.1308151 ## &lt;https://doi.org/10.5281/zenodo.1308151&gt;, R package version 3.0.6, &lt;http://mjskay.github.io/tidybayes/&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {{tidybayes}: Tidy Data and Geoms for {Bayesian} Models}, ## author = {Matthew Kay}, ## year = {2023}, ## note = {R package version 3.0.6}, ## url = {http://mjskay.github.io/tidybayes/}, ## doi = {10.5281/zenodo.1308151}, ## } ## ## [[15]] ## To cite package &#39;cowplot&#39; in publications use: ## ## Wilke C (2024). _cowplot: Streamlined Plot Theme and Plot Annotations for &#39;ggplot2&#39;_. R package version ## 1.1.3, &lt;https://CRAN.R-project.org/package=cowplot&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {cowplot: Streamlined Plot Theme and Plot Annotations for &#39;ggplot2&#39;}, ## author = {Claus O. Wilke}, ## year = {2024}, ## note = {R package version 1.1.3}, ## url = {https://CRAN.R-project.org/package=cowplot}, ## } ## ## [[16]] ## To cite package &#39;plyr&#39; in publications use: ## ## Hadley Wickham (2011). The Split-Apply-Combine Strategy for Data Analysis. Journal of Statistical Software, ## 40(1), 1-29. URL https://www.jstatsoft.org/v40/i01/. ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {The Split-Apply-Combine Strategy for Data Analysis}, ## author = {Hadley Wickham}, ## journal = {Journal of Statistical Software}, ## year = {2011}, ## volume = {40}, ## number = {1}, ## pages = {1--29}, ## url = {https://www.jstatsoft.org/v40/i01/}, ## } ## ## [[17]] ## To cite package &#39;tidyverse&#39; in publications use: ## ## Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn ## M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, ## Wilke C, Woo K, Yutani H (2019). &quot;Welcome to the tidyverse.&quot; _Journal of Open Source Software_, *4*(43), ## 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Article{, ## title = {Welcome to the {tidyverse}}, ## author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D&#39;Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani}, ## year = {2019}, ## journal = {Journal of Open Source Software}, ## volume = {4}, ## number = {43}, ## pages = {1686}, ## doi = {10.21105/joss.01686}, ## } ## ## [[18]] ## To cite package &#39;furrr&#39; in publications use: ## ## Vaughan D, Dancho M (2022). _furrr: Apply Mapping Functions in Parallel using Futures_. R package version ## 0.3.1, &lt;https://CRAN.R-project.org/package=furrr&gt;. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {furrr: Apply Mapping Functions in Parallel using Futures}, ## author = {Davis Vaughan and Matt Dancho}, ## year = {2022}, ## note = {R package version 0.3.1}, ## url = {https://CRAN.R-project.org/package=furrr}, ## } lapply(pkg, function(x) print(paste(x, &quot;version&quot;, packageVersion(x)))) ## [1] &quot;psych version 2.4.1&quot; ## [1] &quot;knitr version 1.45&quot; ## [1] &quot;kableExtra version 1.4.0&quot; ## [1] &quot;brms version 2.20.4&quot; ## [1] &quot;readxl version 1.4.3&quot; ## [1] &quot;haven version 2.5.4&quot; ## [1] &quot;estimatr version 1.0.2&quot; ## [1] &quot;lme4 version 1.1.35.1&quot; ## [1] &quot;broom.mixed version 0.2.9.4&quot; ## [1] &quot;bootpredictlme4 version 0.1&quot; ## [1] &quot;effectsize version 0.8.6&quot; ## [1] &quot;metafor version 4.4.0&quot; ## [1] &quot;rstan version 2.32.5&quot; ## [1] &quot;tidybayes version 3.0.6&quot; ## [1] &quot;cowplot version 1.1.3&quot; ## [1] &quot;plyr version 1.8.9&quot; ## [1] &quot;tidyverse version 2.0.0&quot; ## [1] &quot;furrr version 0.3.1&quot; ## [[1]] ## [1] &quot;psych version 2.4.1&quot; ## ## [[2]] ## [1] &quot;knitr version 1.45&quot; ## ## [[3]] ## [1] &quot;kableExtra version 1.4.0&quot; ## ## [[4]] ## [1] &quot;brms version 2.20.4&quot; ## ## [[5]] ## [1] &quot;readxl version 1.4.3&quot; ## ## [[6]] ## [1] &quot;haven version 2.5.4&quot; ## ## [[7]] ## [1] &quot;estimatr version 1.0.2&quot; ## ## [[8]] ## [1] &quot;lme4 version 1.1.35.1&quot; ## ## [[9]] ## [1] &quot;broom.mixed version 0.2.9.4&quot; ## ## [[10]] ## [1] &quot;bootpredictlme4 version 0.1&quot; ## ## [[11]] ## [1] &quot;effectsize version 0.8.6&quot; ## ## [[12]] ## [1] &quot;metafor version 4.4.0&quot; ## ## [[13]] ## [1] &quot;rstan version 2.32.5&quot; ## ## [[14]] ## [1] &quot;tidybayes version 3.0.6&quot; ## ## [[15]] ## [1] &quot;cowplot version 1.1.3&quot; ## ## [[16]] ## [1] &quot;plyr version 1.8.9&quot; ## ## [[17]] ## [1] &quot;tidyverse version 2.0.0&quot; ## ## [[18]] ## [1] &quot;furrr version 0.3.1&quot; 1.2 Directory Path # res_path &lt;- &quot;https://github.com/emoriebeck/big-five-prediction/blob/master&quot; data_path &lt;- &quot;/Volumes/Emorie/data&quot; res_path &lt;- &quot;https://github.com/emoriebeck/data-synthesis-tutorial/raw/main&quot; # local_path &lt;- &quot;/Volumes/Emorie/projects/data synthesis/crystallized&quot; local_path &lt;- &quot;~/Documents/projects/data synthesis/crystallized&quot; 1.3 Introduction A key part of the scientific enterprise involves establishing robust, replicable, and generalizable relationships among diverse phenomena. For the better part of a century, meta-analytic techniques, in which effect sizes of relationships among phenomena are pulled from the published or unpublished literature and statistically pooled, have been the cornerstone of testing the robustness and generalizability. However, as more data become publicly available, it is becoming increasingly easy and important to synthesize data sources, rather than just results of those sources. In response, a number of new techniques, including pooled analyses, individual participant meta-analyses, and coordinated analyses, have emerged to synthesize such diverse data sources. Despite the promises of each of these techniques, there has been little to no systematic review of the methods available or how to carry them out. As a result, many researchers are unaware of the wealth of methods available for data synthesis. But understanding what methods are available and how to best carry them out is critical for guiding future research using different data synthesis techniques. The present study aims to fill this gap. In addition, in recent years, the links between personality and cognitive ability and their links to aging have become increasingly popular as researchers look to use them to understand how aging processes unfold. However, less research has looked at links between personality and specific domains of cognitive functioning, particularly in a multi-study format, which is critical to understand how the interplay among personality, cognitive function, and aging unfold in a more nuanced manner. To demonstrate how to conduct a variety of data synthesis techniques, as well as their utility and challenges, the proposed study investigates whether the Big Five prospectively predicts crystallized / knowledge domain of cognitive ability in 13 longitudinal panel studies. Because of the many options available for synthesizing the data from these studies to test the association, we will detail five broad data synthesis methods: (1) pooled analysis of individual participant data (IPD), (2) pooled analysis of individual participant data (IPD) using dummy codes or random effects, (3) coordinated analyses followed by random effects meta-analysis, (4) coordinated analyses reported together, and (5) traditional meta-analysis of effect sizes from the published and unpublished literature. In addition, we will demonstrate how to carry out four of these five methods (excluding traditional meta-analyses). Each of these methods will be explained in more detail later, but key features and differences across methods are summarized in Table 1 below. url &lt;- &quot;https://github.com/emoriebeck/data-synthesis-tutorial/raw/main/codebooks/crystallized_tables.xlsx&quot; destfile &lt;- &quot;tables.xlsx&quot; curl::curl_download(url, destfile) tab1 &lt;- readxl::read_xlsx(destfile, sheet = &quot;Table 1&quot;) %&gt;% select(-ModNum) %&gt;% kable(. , &quot;html&quot; , align = c(&quot;r&quot;, &quot;c&quot;, &quot;l&quot;, &quot;l&quot;, &quot;c&quot;, &quot;l&quot;) , caption = &quot;&lt;strong&gt;Table 1&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Key Features of Five Levels of Data Synthesis&lt;/em&gt;&quot;) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% kableExtra::group_rows(&quot;Single Model&quot;, 1, 2) %&gt;% kableExtra::group_rows(&quot;Multiple Models&quot;, 3, 5) tab1 (#tab:data synth tables)Table 1Key Features of Five Levels of Data Synthesis Names Individual Participant Data Number of Models Study-Specific Estimates Degree of Harmonization Examples Single Model Pooled Analysis of Individual Participant Data (IPD) Yes One No High Jokela et al., 2013 Pooled Analysis of Individual Participant Data using Contrasts or Random Effects Yes One Yes, random effects or dummy variables High Beck &amp; Jackson, 2020; Paige et al., 2017 Multiple Models Coordinated Analyses Followed by Meta-Analysis Yes Number of studies + meta-analysis model Yes, original study effect sizes Moderate Graham et al., 2020; Wood et al., 2018 Coordinated Analyses Reported Together Yes Number of studies Yes, original study effect sizes Moderate Graham et al., 2017 Traditional Meta-Analyses No One (Meta-analysis model) Yes, original study effect sizes None Bogg &amp; Roberts, 2004 save_kable(tab1, file = sprintf(&quot;%s/results/tables/tab-1-taxonomy.html&quot;, local_path)) tab2 &lt;- readxl::read_xlsx(destfile, sheet = &quot;Sheet1&quot;) %&gt;% mutate_all(~str_replace_all(., &quot;\\\\r\\\\n&quot;, &quot;&lt;br&gt;&quot;)) %&gt;% kable(. , &quot;html&quot; , align = rep(&quot;c&quot;, 10) , caption = &quot;&lt;strong&gt;Table 2&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Sample characteristics and sample-level moderators&lt;/em&gt;&quot; , escape = F , col.names = c(&quot;Sample&quot;, &quot;Country (Continent)&quot;, &quot;Prediction Interval&quot;, &quot;Measure&quot;, &quot;Scale&quot;, &quot;Domains&quot;, &quot;Median Year (SD)&quot;, &quot;Baseline Age&quot;, &quot;Measure(s)&quot;,&quot;Median Year (SD)&quot;) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(c(&quot; &quot; = 3, &quot;&lt;strong&gt;Personality Characteristics&lt;/strong&gt;&quot; = 5, &quot;&lt;strong&gt;Crystallized / Knowledge Domain Cognitive Ability&lt;/strong&gt;&quot; = 2) , escape = F) %&gt;% footnote(&quot;E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness. NEO-FFI = 60 item NEO Five Factor Inventory (Costa &amp; McCrae, 1992); IPIP NEO = International Item Pool in Personality NEO (Johnson, 2014); BFI-S = Big Five Inventory, Short Form (German; Hahn et al., 2012); TDA-40 = Trait Descriptive Adjectives-40 (Saucier, 1994); MIDI = The Midlife Development Inventory (Lachman &amp; Weaver, 1997); DPQ = Dutch Personality Questionnaire (Barelds &amp; Luteijn, 2002); Eysenck = Eysenck Personality Questionnaire (Eysenck &amp; Eysenck, 1965). Prediction interval was calculated by taking each participants’ first personality measurement year from their last cognitive ability measurement year. Baseline age is the average participant age at their first personality assessment. &quot;) tab2 (#tab:tab 2)Table 2Sample characteristics and sample-level moderators Personality Characteristics Crystallized / Knowledge Domain Cognitive Ability Sample Country (Continent) Prediction Interval Measure Scale Domains Median Year (SD) Baseline Age Measure(s) Median Year (SD) BASE-I Germany (Europe) 8.56 (-3.51) NEO-FFI 1-5 E, N, O 1990(0) 78.23(6.66) VocabularySpot a Word 1997(3.51) EAS United States(North America) 2.15 (2.41) IPIP NEO 1-5 E, A, C, N, O 2011(3.18) 79.47(5.36) Boston Naming TestInformation 2014(3.09) GSOEP Germany (Europe) 7.00 (0) BFI-S 1-7 E, A, C, N, O 2005(0) 49.83(15.83) Vocabulary 2012(0) HILDA Australia(Australia) 7.00 (0) TDA-40 1-7 E, A, C, N, O 2005(0) 44.51(16.92) Vocabulary 2012(0) HRS United States(North America) 4.00 (0) MIDI 1-4 E, A, C, N, O 2006/8(0) 71.71(6.97) Vocabulary 2010(0) LASA The Netherlands(Europe) 8.39 (9.45) DPQ 1-3 N 1992(1.19) 61.46(15.71) Vocabulary 1995(9.09) MAP United States(North America) 6.75 (4.53) NEO-FFI 1-5 E, A, C, N 79.45(7.32) Boston Naming Test MARS United States(North America) 6.46 (3.86) NEO-FFI 1-5 N, O 73.60(2.66) Boston Naming Test OCTO-TWIN Sweden(Europe) 6.21 (2.82) Eysenck 0-1 E, N 1991(0) 82.99(2.66) Information 1997 ROS United States(North America) 9.53 (6.42) NEO-FFI 1-5 E, A, C, N, O 75.87(7.38) Boston Naming Test SATSA Sweden(Europe) 15.00 (0) Eysenck 1-5 E, A, C, N, O 1984(0) 54.77(9.84) Information 1999(0) Note: E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness. NEO-FFI = 60 item NEO Five Factor Inventory (Costa &amp; McCrae, 1992); IPIP NEO = International Item Pool in Personality NEO (Johnson, 2014); BFI-S = Big Five Inventory, Short Form (German; Hahn et al., 2012); TDA-40 = Trait Descriptive Adjectives-40 (Saucier, 1994); MIDI = The Midlife Development Inventory (Lachman &amp; Weaver, 1997); DPQ = Dutch Personality Questionnaire (Barelds &amp; Luteijn, 2002); Eysenck = Eysenck Personality Questionnaire (Eysenck &amp; Eysenck, 1965). Prediction interval was calculated by taking each participants’ first personality measurement year from their last cognitive ability measurement year. Baseline age is the average participant age at their first personality assessment. save_kable(tab2, file = sprintf(&quot;%s/results/tables/tab-2-samples.html&quot;, local_path)) 1.4 Codebook Each study has a separate codebook indexing matching, covariate, personality, and outcome variables. Moreover, these codebooks contain information about the original scale of the variable, any recoding of the variable (including binarizing outcomes, changing the scale, and removing missing data), reverse coding of scale variables, categories, etc. url &lt;- &quot;https://github.com/emoriebeck/data-synthesis-tutorial/raw/main/codebooks/crystallized_codebook_10.02.20.xlsx&quot; destfile2 &lt;- &quot;crystallized_codebook_10.02.20.xlsx&quot; curl::curl_download(url, destfile2) # list of all codebook sheets sheets &lt;- excel_sheets(destfile2) # function for reading in sheets read_fun &lt;- function(x){ print(x) read_xlsx(destfile2, sheet = x) } # read in sheets and index source codebook &lt;- tibble( study = sheets, codebook = map(study, read_fun) ) ## [1] &quot;Overview&quot; ## [1] &quot;Key&quot; ## [1] &quot;Datasets&quot; ## [1] &quot;Sample&quot; ## [1] &quot;BASE-I&quot; ## [1] &quot;CNLSY&quot; ## [1] &quot;EAS&quot; ## [1] &quot;GSOEP&quot; ## [1] &quot;HILDA&quot; ## [1] &quot;HRS&quot; ## [1] &quot;LASA&quot; ## [1] &quot;RADC-MAP&quot; ## [1] &quot;MARS&quot; ## [1] &quot;OCTO-TWIN&quot; ## [1] &quot;ROS&quot; ## [1] &quot;SATSA&quot; ## [1] &quot;SLS&quot; ## short and long versions of names of all categories for later use studies &lt;- c(&quot;BASE-I&quot;, &quot;CNLSY&quot;, &quot;EAS&quot;, &quot;GSOEP&quot;, &quot;HILDA&quot;, &quot;HRS&quot;, &quot;LASA&quot;, &quot;MAP&quot;, &quot;MARS&quot;, &quot;OCTO-TWIN&quot;, &quot;ROS&quot;, &quot;SATSA&quot;, &quot;SLS&quot;) studies_long &lt;- c(&quot;BASE&quot;, &quot;CNLSY&quot;, &quot;EAS&quot;, &quot;GSOEP&quot;, &quot;HILDA&quot;, &quot;HRS&quot;, &quot;LASA&quot;, &quot;MAP&quot;, &quot;MARS&quot;, &quot;OCTO-Twin&quot;, &quot;ROS&quot;, &quot;SATSA&quot;, &quot;SLS&quot;) studies_sp &lt;- c(&quot; BASE&quot;, &quot; CNLSY&quot;, &quot; EAS&quot;, &quot; GSOEP&quot;, &quot; HILDA&quot;, &quot; HRS&quot;, &quot; LASA&quot;, &quot; MAP&quot;, &quot; MARS&quot;, &quot;OCTO-Twin&quot;, &quot; ROS&quot;, &quot; SATSA&quot;, &quot; SLS&quot;) traits &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(long_name = Construct, short_name = name) outcomes &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(long_name = Construct, short_name = name) covars &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;moder&quot;) %&gt;% select(long_name = Construct, short_name = name, long_term = new_terms, short_term = old_terms) moders &lt;- covars %&gt;% mutate(long_name = mapvalues(long_name, &quot;Unadjusted&quot;, &quot;None&quot;)) stdyModers &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;metaMod&quot;) %&gt;% select(long_name = Construct, short_name = name, long_term = new_terms, medium_term = short_term, short_term = old_terms) mthds &lt;- codebook$codebook[[2]] %&gt;% filter(Category == &quot;Methods&quot;) %&gt;% select(long_name = Construct, short_name = name, old_name = old_terms) stdcolors &lt;- tibble( studies = c(&quot;Overall&quot;, studies_long) , std_text = str_remove_all(studies, &quot;[-]&quot;) , colors = c(&quot;black&quot;, &quot;#332288&quot;, &quot;#88ccee&quot;, &quot;#44aa99&quot;, &quot;#117733&quot;, &quot;#999933&quot;, &quot;#ddcc77&quot;, &quot;#cc6677&quot;, &quot;#332288&quot;, &quot;#88ccee&quot;, &quot;#44aa99&quot;, &quot;#117733&quot;, &quot;#999933&quot;, &quot;#ddcc77&quot;) , lt = c(rep(&quot;solid&quot;, 8), rep(&quot;dotted&quot;, 6))) # used personality waves p_waves &lt;- read_xlsx(destfile, sheet = &quot;Table 2&quot;) 1.5 Navigating This Tutorial This tutorial is meant to demonstrate how to accurately and efficiently carry out different methods of data synthesis. Therefore, each of the methods will be conducted separately in different chapters of this document and then the results of all will be pooled in the final chapter. Sometimes, this will result in redundant code. This is intentional such that should you want to conduct a one-stage pooled analysis of individual participant data using random effects, you would only need to follow the introduction, Chapter 1 on Data cleaning, and Chapter 3B on one-stage pooled analysis of individual participant data using random effects. Together, these would take you through every step from documenting your data to creating final tables and figures of your results without having to click through or find additional pieces in other chapters. At a later point, each of these may be separated into R scripts for each method to facilitate ease of use. "],["cleaning.html", "Chapter 2 Data Cleaning 2.1 Berlin Aging Study (BASE-I) 2.2 Einstein Aging Study (EAS) 2.3 German Socioeconomic Panel (GSOEP) 2.4 Household, Income, and Labour Dynamics in Australia (HILDA) 2.5 Health and Retirement Study (HRS) 2.6 Longitudinal Aging Study Amsterdam (LASA) 2.7 MAP 2.8 MARS 2.9 ROS 2.10 Origins of the Variances of the Oldest-Old: Octogenarian Twins (OCTO-TWIN) 2.11 Swedish Adoption Twin Study of Aging (SATSA) 2.12 Seattle Longitudinal Study (SLS) 2.13 Descriptives of All Studies", " Chapter 2 Data Cleaning Mode &lt;- function(x) { ux &lt;- unique(x) ux &lt;- ux[!is.na(ux)] ux[which.max(tabulate(match(x, ux)))] } The data preparation procedure across samples and methods was nearly identical, with the exception of whether data were pooled across samples (Methods 1A-2B) or kept separate (Methods 3 and 4). First, before preregistration, data preparation began by cataloging the available data in each sample in a comprehensive codebook, with the goal of compiling all of the information necessary for harmonizing across samples. For each sample, we compiled information on (1) the original variable name in the raw data, (2) the question text, (3) the scale (e.g., numeric, Likert-like scale points, labels for nominal variables), and (4) the available waves or years for each of the target variables. We also included information (5) categorizing the variable (e.g., personality, outcome), (6) a higher order variable name construct (e.g., Agreeableness, crystallized cognitive ability) that matched across samples, (7) a lower order variable name that indexed unique items (e.g., friendly, WAIS Information), (8) a note on whether an item was reverse scored along with its (9) minimum and (10) maximum, (11) a string of R code for recoding scales (e.g., recoding missing values as NA, changing levels of nominal variables to harmonize across samples), and two rules for how composites were to be created, either (12) within a wave (e.g., compositing a personality or cognitive scale) or (13) longitudinally across them (e.g., for covariates to index participants’ highest level of education prior to baseline). Second, once the codebook was created and all the data were received, the codebook and data files were sequentially loaded into R, and data were renamed, reverse-scored, and rescaled as documented in the codebook. Then, for each of the categories of data (covariates, personality, and cognitive ability), data were composited as documented in Table 2. Finally, these three sources of data were combined into a single data set within each sample separately. The full data cleaning procedure can be seen in Chapter 1 (Data Cleaning) in the online materials. Third, data from each sample was combined into a single data set with harmonized labels and scales for Methods 1 (A and B) and 2 (A and B). For methods that include sample-level moderators (Methods 1A, 2B, and 3), this also includes combining the personality, cognitive, and covariate data with sample-level data. In Methods 1A and 2B, this happens in the initial step, while in Method 3, these are added after estimating the models for each sample separately (see online materials). Fourth, we harmonized the continuous personality and cognitive ability measures using POMP scoring (range 0-10). Continuous variables with easily harmonized scales (i.e. age and years of education) were centered, with age centered at 60 and education centered at 12 years. Nominal variables were harmonized during the earlier data cleaning steps such that 0 = “male” and 1 = “female” for gender. 2.1 Berlin Aging Study (BASE-I) The Berlin Aging Study (I) is a longitudinal interdisciplinary study of aging that began in 1990. The data are available, by application, from https://www.base-berlin.mpg.de/en/system/files/media/pdf/a97295f241d06bf496b5eeae4251a34e/base-data-transfer_form_online.pdf. Participants included 516 individuals over 70, stratified on age and gender, recruited from a sample of the Berlin City Registry. To date, most participants are deceased, with most attrition from the study due to mortality or severe health complications. Since 1990, there have been seven follow-up measurement occasions (8 total). Sample sizes vary over time, from 516 (T1) to 23 (T8). To ensure adequate sample sizes, the present study will use data up to the fourth wave, which included 164 participants with full data. This provides 99% power to detect a correlation effect size of ~.32, two-tailed alpha at .05. 2.1.1 Load Data (basei_codebook &lt;- (codebook %&gt;% filter(study == &quot;BASE-I&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 138 × 17 ## study dataset category name itemname wave year stem orig_itemname description scale reverse_code recode mini maxi ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 base-i social covaria… educ… eduYears 1 1990 &lt;NA&gt; s1kon28 Years of E… &quot;int… &lt;NA&gt; ifels… NA NA ## 2 base-i social covaria… educ… eduYears 1 1990 &lt;NA&gt; z1e10 General ed… &quot;1 =… &lt;NA&gt; ifels… NA NA ## 3 base-i demograp… covaria… gend… sex 1 1990 esex z1esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 4 base-i demograp… covaria… gend… sex 2 1993 esex z2esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 5 base-i demograp… covaria… gend… sex 3 1995 esex z3esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 6 base-i demograp… covaria… gend… sex 4 1997 esex z4esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 7 base-i demograp… covaria… gend… sex 5 2000 esex z5esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 8 base-i demograp… covaria… gend… sex 6 2004 esex z6esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 9 base-i demograp… covaria… gend… sex 7 2005 esex z7esex Sex of par… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 10 base-i demograp… covaria… SRhe… SRhealth 1 1990 E13X… z1e13x1r How would … &quot;1 =… yes ifels… 1 5 ## # ℹ 128 more rows ## # ℹ 2 more variables: comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; basei &lt;- sprintf(&quot;%s/base-i/Beck_202010.sav&quot;, data_path) %&gt;% read_sav() %&gt;% full_join(sprintf(&quot;%s/base-i/Beck_202010_2.sav&quot;, data_path) %&gt;% read_sav()) 2.1.2 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ old.names &lt;- unique((basei_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- basei %&gt;% select(SID = id, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, na.rm=T) if(length(old.names) &gt; 1){ df %&gt;% left_join(cb %&gt;% select(itemname, wave, orig_itemname, reverse_code:long_rule)) } else { df %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule) %&gt;% distinct()) %&gt;% mutate(wave = &quot;0&quot;) } } ` # join data with recoding info basei_recode &lt;- basei_codebook %&gt;% select(category, name, itemname, wave, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } basei_recode &lt;- basei_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code basei_recode &lt;- basei_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.1.3 Covariates # composite WITHIN years basei_cov &lt;- basei_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave &lt;= 1) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years basei_cov &lt;- basei_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.1.4 Personality Variables basei_pers &lt;- basei_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(wave == 1 &amp; !is.na(value)) %&gt;% group_by(SID, wave, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s basei_alpha &lt;- basei_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, wave, SID, value) %&gt;% group_by(name, wave) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID), check.keys = T), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites basei_pers &lt;- basei_pers %&gt;% group_by(name, comp_rule, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.1.5 Outcome Variables basei_cog_waves &lt;- basei_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() # composite within years basei_out &lt;- basei_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% right_join(basei_cog_waves) %&gt;% filter(wave == o_year &amp; wave &gt; 1) %&gt;% group_by(name, wave, SID) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% ungroup() 2.1.6 Combine Data basei_combined &lt;- basei_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( basei_out %&gt;% rename(Outcome = name, o_value = value, o_year = wave) ) %&gt;% full_join(basei_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(basei_cov, basei_alpha, basei_pers, basei_out, basei_combined, file = sprintf(&quot;%s/data/clean/base-i_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;basei&quot;, ls())]) 2.2 Einstein Aging Study (EAS) The Einstein Aging Study is an ongoing longitudinal study of older adults in the United States that began in 1980. The data are available on a project-by-project basis by submitting a concept proposal at https://www.einstein.yu.edu/departments/neurology/clinical-research-program/eas/data-sharing.aspx. Since 1993, the EAS has systematically recruited a representative aging sample in the Bronx, New York. As of 2017, 2,600 participants were enrolled in the study. As of 2010, approximately 200 of the enrolled participants had autopsy data. More information on the study can be found at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/EAS/. Sample sizes vary over time, with ranges across waves not publicly available. However, we suspect approximately 2,000 participants to have basic personality and cognitive ability data. This yields 99% power to detect a zero-order correlation effect size of .10, two-tailed at alpha .05. 2.2.1 Load Data (eas_codebook &lt;- (codebook %&gt;% filter(study == &quot;EAS&quot;))$codebook[[1]]) ## # A tibble: 16 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini maxi comp_rule ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 EAS &lt;NA&gt; match education educati… base… Educyrs Education &lt;NA&gt; NA &lt;NA&gt; NA NA skip ## 2 EAS &lt;NA&gt; match gender gender annu… Gender Gender &lt;NA&gt; NA ifels… NA NA skip ## 3 EAS &lt;NA&gt; match SRhealth SRhealth annu… &lt;NA&gt; Self-rated… &lt;NA&gt; NA code … NA NA skip ## 4 EAS &lt;NA&gt; match age age long… AgeAtWave Raw age inte… NA ifels… NA NA skip ## 5 EAS &lt;NA&gt; outcome crystalli… BosNami… annu… BostonFree Word Fluen… inte… NA ifels… NA NA sum ## 6 EAS &lt;NA&gt; outcome crystalli… waisInfo annu… Infraw WAIS III: … inte… NA ifels… NA NA sum ## 7 EAS dataset pers A ipipApos 1 Agreeablenes… IPIP NEO A 5 to… NA ifels… NA NA average ## 8 EAS dataset pers C ipipCpos 1 Conscientiou… IPIP NEO C 5 to… NA ifels… NA NA average ## 9 EAS dataset pers E ipipEpos 1 Extraversion… IPIP NEO E 5 to… NA ifels… NA NA average ## 10 EAS dataset pers N ipipNpos 1 NeuroticismP… IPIP NEO N 5 to… NA ifels… NA NA average ## 11 EAS dataset pers O ipipOpos 1 OpenToExperi… IPIP NEO O 5 to… NA ifels… NA NA average ## 12 EAS dataset pers A ipipAneg 1 Agreeablenes… IPIP NEO A 5 to… NA ifels… NA NA average ## 13 EAS dataset pers C ipipCneg 1 Conscientiou… IPIP NEO C 5 to… NA ifels… NA NA average ## 14 EAS dataset pers E ipipEneg 1 Extraversion… IPIP NEO E 5 to… NA ifels… NA NA average ## 15 EAS dataset pers N ipipNneg 1 NeuroticismN… IPIP NEO N 5 to… NA ifels… NA NA average ## 16 EAS dataset pers O ipipOneg 1 OpenToExperi… IPIP NEO O 5 to… NA ifels… NA NA average ## # ℹ 1 more variable: long_rule &lt;chr&gt; # old.names1 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;jrp&quot;))$orig_itemname) # old.names2 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;dataset&quot;))$orig_itemname) old.names &lt;- unique(eas_codebook$orig_itemname) eas &lt;- sprintf(&quot;%s/eas/Behavior_with_Master_Data_2021_09_24.xlsx&quot;, data_path) %&gt;% read_excel(.) %&gt;% select(SID = Id, wave = Wave, year = BehaviorDate, one_of(old.names)) %&gt;% mutate(year = lubridate::year(year) , Gender = as.numeric(mapvalues(Gender, c(&quot;M&quot;, &quot;F&quot;), c(0,1)))) # full_join( # sprintf(&quot;%s/eas/dataset.xlsx&quot;, data_path) %&gt;% # read_excel(.) %&gt;% # select(SID = id, one_of(old.names2)) # ) eas_long &lt;- eas %&gt;% pivot_longer(values_to = &quot;value&quot; , names_to = &quot;orig_itemname&quot; , cols = c(-SID, -wave, -year) , values_drop_na = T) 2.2.2 Recoding &amp; Reverse Scoring # join data with recoding info eas_recode &lt;- eas_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;) &amp; !is.na(orig_itemname)) %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(eas_long))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } eas_recode &lt;- eas_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code eas_recode &lt;- eas_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } eas_waves &lt;- eas_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% select(SID, p_year = year) %&gt;% distinct() %&gt;% group_by(SID) %&gt;% filter(p_year == min(p_year)) %&gt;% ungroup() 2.2.3 Covariates # composite WITHIN years eas_cov &lt;- eas_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% left_join(eas_waves) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, year, p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) # summarize(value = fun_call(value, comp_rule)) %&gt;% # ungroup() %&gt;% # mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) )) comp_fun &lt;- function(d, rule, p_year){ print(paste(rule, p_year)) d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years eas_cov &lt;- eas_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% filter(year &lt;= p_year) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.2.4 Personality Variables eas_pers &lt;- eas_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% left_join(eas_waves) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s eas_alpha &lt;- eas_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites eas_pers &lt;- eas_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.2.5 Outcome Variables # composite within years eas_out &lt;- eas_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% filter(year == max(year)) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, year, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() 2.2.6 Combine Data eas_combined &lt;- eas_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(eas_out %&gt;% rename(Outcome = name, o_value = value, o_year = year)) %&gt;% full_join(eas_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(eas_cov, eas_alpha, eas_pers, eas_out, eas_combined, file = sprintf(&quot;%s/data/clean/eas_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;eas&quot;, ls())]) 2.3 German Socioeconomic Panel (GSOEP) The German Socioeconomic Panel Study (GSOEP; Socio-Economic Panel, 2017) is an ongoing longitudinal study of Germans collected by the German Institute of Economic Research (DIW Berlin). The data are freely available at https://www.diw.de/soep by application. Data have been collected annually since 1984 (the latest data release includes data up to 2017). Participants have been recruited from more than 11,000 households, which are nationally representative of private German households. 20,000 individuals are sampled each year, on average. It is critical to note that the GSOEP samples households, not individuals, and the households consist of individuals living in both the “old” and “new” federal states (the former West and East Germany), foreigners, and recent immigrants to Germany. Sample size varies by year, ranging from approximately 10,000 (1989) to 31,000 (2013). This provides 99% power to detect a zero-order correlation effect size of ~.06, two-tailed at alpha &lt; .05. 2.3.1 Load Data gsoep_read_fun &lt;- function(Year, WL){ old.names &lt;- (gsoep_codebook %&gt;% filter(year == Year | category == &quot;proc&quot;))$orig_itemname p &lt;- sprintf(&quot;%s/gsoep/%sp.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% full_join(sprintf(&quot;%s/gsoep/%skind.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spequiv.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spgen.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spkal.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% select(one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -persnr, -hhnr, na.rm = T) sprintf(&quot;%s/gsoep/%shbrutto.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% full_join(sprintf(&quot;%s/gsoep/%sh.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% select(one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -hhnr, na.rm = T) %&gt;% full_join(p %&gt;% select(persnr, hhnr) %&gt;% distinct()) %&gt;% full_join(p) } gsoep_codebook &lt;- (codebook %&gt;% filter(study == &quot;GSOEP&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname)) gsoep_codebook ## # A tibble: 250 × 17 ## study dataset category name itemname wave waveletter year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 gsoep apequiv covariates age age 1 a 1984 d1110184 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 2 gsoep bpequiv covariates age age 2 b 1985 d1110185 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 3 gsoep cpequiv covariates age age 3 c 1986 d1110186 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 4 gsoep dpequiv covariates age age 4 d 1987 d1110187 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 5 gsoep epequiv covariates age age 5 e 1988 d1110188 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 6 gsoep fpequiv covariates age age 6 f 1989 d1110189 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 7 gsoep gpequiv covariates age age 7 g 1990 d1110190 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 8 gsoep hpequiv covariates age age 8 h 1991 d1110191 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 9 gsoep ipequiv covariates age age 9 i 1992 d1110192 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## 10 gsoep jpequiv covariates age age 10 j 1993 d1110193 Age of Indiv… &lt;NA&gt; &lt;NA&gt; ifels… NA ## # ℹ 240 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; gsoep &lt;- gsoep_codebook %&gt;% select(wave, waveletter, year) %&gt;% filter(complete.cases(.)) %&gt;% distinct() %&gt;% arrange(year) %&gt;% filter(year != &quot;2018&quot;) %&gt;% mutate(data = map2(year, waveletter, gsoep_read_fun)) old.names &lt;- unique(gsoep_codebook$orig_itemname) gsoep_cog &lt;- sprintf(&quot;%s/gsoep/cognit.sav&quot;, data_path) %&gt;% haven::read_sav(.) %&gt;% select(persnr, hhnr, year = syear, one_of(old.names)) %&gt;% filter(year == 2012) %&gt;% haven::zap_labels(.) %&gt;% select(-hhnr) %&gt;% gather(key = orig_itemname, value = value, -persnr, -year, na.rm = T) gsoep_cog_subs &lt;- unique(gsoep_cog$persnr) gsoep_long &lt;- gsoep %&gt;% unnest(data) %&gt;% select(-hhnr) %&gt;% filter(persnr %in% gsoep_cog_subs) %&gt;% full_join(gsoep_cog) %&gt;% select(-wave, -waveletter) %&gt;% rename(SID = persnr) save(gsoep, file = sprintf(&quot;%s/data/clean/gsoep_raw.RData&quot;, local_path)) rm(gsoep) 2.3.2 Recoding &amp; Reverse Scoring gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info gsoep_recode &lt;- gsoep_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(gsoep_long))) # recode recode_fun &lt;- function(rule, y, year, p_year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } gsoep_recode &lt;- gsoep_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(p_year = 2005) %&gt;% group_by(recode, year, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code gsoep_recode &lt;- gsoep_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.3.3 Covariates # composite WITHIN years gsoep_cov &lt;- gsoep_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, year, p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) # summarize(value = fun_call(value, comp_rule)) %&gt;% # ungroup() %&gt;% # mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) )) comp_fun &lt;- function(d, rule, p_year){ print(paste(rule, p_year)) d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years gsoep_cov &lt;- gsoep_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% filter(year &lt;= p_year) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.3.4 Personality Variables gsoep_pers &lt;- gsoep_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == &quot;2005&quot; &amp; !is.na(value)) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s gsoep_alpha &lt;- gsoep_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites gsoep_pers &lt;- gsoep_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.3.5 Outcome Variables # composite within years gsoep_out &lt;- gsoep_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% group_by(name, year, SID) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% ungroup() 2.3.6 Combine Data gsoep_combined &lt;- gsoep_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(gsoep_out %&gt;% rename(Outcome = name, o_value = value, o_year = year)) %&gt;% full_join(gsoep_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(gsoep_cov, gsoep_alpha, gsoep_pers, gsoep_out, gsoep_combined, file = sprintf(&quot;%s/data/clean/gsoep_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;gsoep&quot;, ls())]) 2.4 Household, Income, and Labour Dynamics in Australia (HILDA) The Household Income and Labour Dynamics in Australia (HILDA; Wilkins, Laß, Butterworth, &amp; Vera-Toscano, 2019) study is an ongoing longitudinal study of Australian households. These data are available through application from https://melbourneinstitute.unimelb.edu.au/hilda/for-data-users. Participants were recruited from more than 17,000 individuals. Data have been collected annually since 2001. The latest data release includes 17 waves of data from 2001 to 2017. More documentation can be found in the HILDA data dictionary at https://www.online.fbe.unimelb.edu.au/HILDAodd/srchSubjectAreas.aspx. Sample sizes vary by year, ranging from 12,408 (2004) to 17,693 (2016). This provides 99% power to detect a zero-order correlation effect size of ~.03, two tailed at alpha .05. 2.4.1 Load Data hilda_read_fun &lt;- function(Year, WL){ old.names &lt;- (hilda_codebook %&gt;% filter(year == Year | year == 0))$orig_itemname sprintf(&quot;%s/hilda/Combined %s180c.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% select(one_of(old.names)) } hilda_codebook &lt;- (codebook %&gt;% filter(study == &quot;HILDA&quot;))$codebook[[1]] hilda_codebook ## # A tibble: 217 × 17 ## study dataset category name itemname wave_letter ...7 year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 hilda NA covariates educa… educati… A 01 2001 aedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 2 hilda NA covariates educa… educati… B 02 2002 bedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 3 hilda NA covariates educa… educati… C 03 2003 cedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 4 hilda NA covariates educa… educati… D 04 2004 dedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 5 hilda NA covariates educa… educati… E 05 2005 eedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 6 hilda NA covariates educa… educati… F 06 2006 fedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 7 hilda NA covariates educa… educati… G 07 2007 gedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 8 hilda NA covariates educa… educati… H 08 2008 hedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 9 hilda NA covariates educa… educati… I 09 2009 iedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## 10 hilda NA covariates educa… educati… J 10 2010 jedhigh1 Highest ed… 1=po… &lt;NA&gt; ifels… NA ## # ℹ 207 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; hilda &lt;- hilda_codebook %&gt;% select(year, wave_letter) %&gt;% filter(!is.na(wave_letter)) %&gt;% distinct() %&gt;% mutate(wave_letter = tolower(wave_letter), data = map2(year, wave_letter, hilda_read_fun)) save(hilda, file = sprintf(&quot;%s/data/clean/hilda_raw.RData&quot;, local_path)) 2.4.2 Recoding &amp; Reverse Scoring hilda_waves &lt;- p_waves %&gt;% filter(Study == &quot;HILDA&quot;) %&gt;% select(Used) %&gt;% distinct() rename_fun &lt;- function(df, Year){ df &lt;- df %&gt;% haven::zap_labels(.) %&gt;% gather(key = orig_itemname, value = value, -xwaveid, na.rm=T) %&gt;% mutate(value=as.numeric(value)) hilda_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(year == Year &amp; category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% full_join(df) } # join data with recoding info hilda_recode &lt;- hilda %&gt;% mutate(data = map2(data, year, rename_fun)) %&gt;% select(-year, -wave_letter) %&gt;% unnest(data) %&gt;% distinct() %&gt;% rename(SID = xwaveid) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() # recode recode_fun &lt;- function(rule, y, year, p_year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } hilda_recode &lt;- hilda_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(p_year = 2005) %&gt;% group_by(recode, year, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code hilda_recode &lt;- hilda_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.4.3 Covariates # composite WITHIN years hilda_cov &lt;- hilda_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, year, p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) # summarize(value = fun_call(value, comp_rule)) %&gt;% # ungroup() %&gt;% # mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) )) comp_fun &lt;- function(d, rule, p_year){ print(paste(rule, p_year)) d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years hilda_cov &lt;- hilda_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% filter(year &lt;= p_year) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.4.4 Personality Variables hilda_pers &lt;- hilda_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == &quot;2005&quot; &amp; !is.na(value)) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s hilda_alpha &lt;- hilda_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites hilda_pers &lt;- hilda_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.4.5 Outcome Variables # composite within years hilda_out &lt;- hilda_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% group_by(name, year, SID) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% ungroup() 2.4.6 Combine Data hilda_combined &lt;- hilda_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(hilda_out %&gt;% rename(Outcome = name, o_value = value, o_year = year)) %&gt;% full_join(hilda_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(hilda_cov, hilda_alpha, hilda_pers, hilda_out, hilda_combined, file = sprintf(&quot;%s/data/clean/hilda_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;hilda&quot;, ls())]) 2.5 Health and Retirement Study (HRS) The Health and Retirement Study [HRS; (juster1995overview?)] is an ongoing longitudinal study of households in the United States. These data are available at https://hrs.isr.umich.edu by creating a free account. Participants were recruited from more than 35,000 individuals from the financial households of individuals born between 1931 and 1941 in the US. Data have been collected biannually since 1992. The latest data release includes data up to 2016. On average, 10,000 individuals are sampled each wave More information on the HRS can be found at https://hrs.isr.umich.edu/documentation/survey-design, but, in short, the HRS is a nationally representative sample of adults over 50 in the US. It is critical to note that the HRS samples households of the original cohort and follows individuals and their spouses or partners until their death. Sample size varies by year, ranging from approximately 7,500 (2014) to 15,500 (1992). (https://hrs.isr.umich.edu/sites/default/files/biblio/ResponseRates_2017.pdf). This provides 99% power to detect a zero-order correlation effect size of ~.04, two-tailed at alpha .05. 2.5.1 Load Data hrs_read_fun &lt;- function(year) { read_da &lt;- function(da, dct, Year){ print(paste(da, dct, year, sep = &quot; &quot;)) data.file &lt;- sprintf(&quot;%s/hrs/%s/%s&quot;, data_path, Year, da) # Set path to the dictionary file &quot;*.DCT&quot; dict.file &lt;- sprintf(&quot;%s/hrs/%s/%s&quot;, data_path, Year, dct) # Read the dictionary file df.dict &lt;- read.table(dict.file, skip = 1, fill = TRUE, stringsAsFactors = FALSE) # Set column names for dictionary dataframe colnames(df.dict) &lt;- c(&quot;col.num&quot;,&quot;col.type&quot;,&quot;col.name&quot;,&quot;col.width&quot;,&quot;col.lbl&quot;) # Remove last row which only contains a closing } row &lt;- which(df.dict$col.name == &quot;HHID&quot;) df.dict &lt;- df.dict[-nrow(df.dict),] if(row == 2){df.dict &lt;- df.dict[-1,]} # Extract numeric value from column width field df.dict$col.width &lt;- as.integer(sapply(df.dict$col.width, gsub, pattern = &quot;[^0-9\\\\.]&quot;, replacement = &quot;&quot;)) # Convert column types to format to be used with read_fwf function df.dict$col.type &lt;- sapply(df.dict$col.type, function(x) ifelse(x %in% c(&quot;int&quot;,&quot;byte&quot;,&quot;long&quot;), &quot;i&quot;, ifelse(x == &quot;float&quot;, &quot;n&quot;, ifelse(x == &quot;double&quot;, &quot;d&quot;, &quot;c&quot;)))) # Read the data file into a dataframe df &lt;- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = &quot;&quot;)) # Add column labels to headers attributes(df)$variable.labels &lt;- df.dict$col.lbl old.names &lt;- (hrs_codebook %&gt;% filter(year == Year))$orig_itemname if(any(c(&quot;PN&quot;, &quot;HHID&quot;) %in% colnames(df)) &amp; any(old.names %in% colnames(df))){ # if(any(c(&quot;PN&quot;, &quot;HHID&quot;) %in% colnames(df))){ df &lt;- df %&gt;% mutate(hhidpn = 1000*as.numeric(HHID) + as.numeric(PN)) %&gt;% select(one_of(c(&quot;PN&quot;, &quot;HHID&quot;)), one_of(old.names)) %&gt;% distinct() # gather(key = item, value = value, -hhidpn) } else {df &lt;- NA} return(df) } # Set path to the data file &quot;*.DA&quot; files &lt;- list.files(sprintf(&quot;%s/hrs/%s&quot;, data_path, year)) df2 &lt;- tibble( da = files[grepl(&quot;.da&quot;, files) | grepl(&quot;.DA&quot;, files)], dct = files[grepl(&quot;.dct&quot;, files) | grepl(&quot;.DCT&quot;, files)] ) %&gt;% mutate(data = map2(da, dct, possibly(~read_da(.x, .y, year), NA_real_))) %&gt;% filter(!is.na(data)) %&gt;% select(-da, -dct) if(nrow(df2) != 0){df2$data %&gt;% reduce(full_join) %&gt;% distinct()} else {NA} } hrs_codebook &lt;- (codebook %&gt;% filter(study == &quot;HRS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_upper(orig_itemname)) %&gt;% mutate_at(vars(orig_itemname, name, itemname), ~str_remove_all(., &quot;[[:space:]]&quot;)) hrs_codebook ## # A tibble: 183 × 17 ## study dataset category name itemname wave waveletter year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 hrs Rand covariates educat… eduYears 1 NA 1992 RAEDYRS R Years of… &quot;.M=… &lt;NA&gt; ifels… NA ## 2 hrs Rand covariates gender demgend… 1 NA 1992 RAGENDER R Gender &quot;.M=… &lt;NA&gt; ifels… NA ## 3 hrs Rand covariates SRheal… rHlthSR 1 NA 1992 R1SHLT W1 Self-re… &quot;1.E… yes ifels… 1 ## 4 hrs Rand covariates SRheal… rHlthSR 2 NA 1994 R2SHLT W2 Self-re… &quot;1.E… yes ifels… 1 ## 5 hrs Rand covariates SRheal… rHlthSR 3 NA 1996 R3SHLT W3 Self-re… &quot;1.E… yes ifels… 1 ## 6 hrs Rand covariates SRheal… rHlthSR 4 NA 1998 R4SHLT W4 Self-re… &quot;1.E… yes ifels… 1 ## 7 hrs Rand covariates SRheal… rHlthSR 5 NA 2000 R5SHLT W5 Self-re… &quot;1.E… yes ifels… 1 ## 8 hrs Rand covariates SRheal… rHlthSR 6 NA 2002 R6SHLT W6 Self-re… &quot;1.E… yes ifels… 1 ## 9 hrs Rand covariates SRheal… rHlthSR 7 NA 2004 R7SHLT W7 Self-re… &quot;1.E… yes ifels… 1 ## 10 hrs Rand covariates SRheal… rHlthSR 8 NA 2006 R8SHLT W8 Self-re… &quot;1.E… yes ifels… 1 ## # ℹ 173 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; old.names &lt;- unique(hrs_codebook$orig_itemname) hrs.paq &lt;- tibble( year = sprintf(&quot;%s/hrs&quot;, data_path) %&gt;% list.files(., pattern = &quot;^[0-9]&quot;) , data = map(year, hrs_read_fun) , names = map(data, colnames) ) %&gt;% filter(!is.na(data)) old.names &lt;- unique((hrs_codebook %&gt;% filter(dataset == &quot;Rand&quot;))$orig_itemname) hrs.rand &lt;- sprintf(&quot;%s/hrs/randhrs1992_2016v1.sav&quot;, data_path) %&gt;% haven::read_sav(.) %&gt;% haven::zap_labels(.) %&gt;% select(SID = HHIDPN, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, na.rm = T) hrs_long &lt;- hrs.paq %&gt;% mutate(data = map(data, ~(.) %&gt;% gather(key = orig_itemname, value = value, -HHID, -PN))) %&gt;% select(-names, -year) %&gt;% unnest(data) %&gt;% mutate(SID = 1000*as.numeric(HHID) + as.numeric(PN)) %&gt;% select(-PN, -HHID) hrs.subs &lt;- unique(hrs_long$SID)[unique(hrs_long$SID) %in% unique(hrs.rand$SID)] hrs_long &lt;- hrs_long %&gt;% bind_rows(hrs.rand %&gt;% select(orig_itemname, value, SID)) %&gt;% filter(SID %in% hrs.subs) save(hrs.rand, hrs.paq, file = sprintf(&quot;%s/data/clean/hrs_raw.RData&quot;, local_path)) rm(list = c(&quot;hrs.paq&quot;, &quot;hrs.rand&quot;)) 2.5.2 Recoding &amp; Reverse Scoring hrs_waves &lt;- p_waves %&gt;% filter(Study == &quot;HRS&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info hrs_recode &lt;- hrs_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(hrs_long))) # recode recode_fun &lt;- function(rule, y, year, p_year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } hrs_recode &lt;- hrs_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(year = mapvalues(year, seq(2006, 2016, 2), rep(c(2006, 2010, 2014), each = 2)), p_year = 2006) %&gt;% group_by(recode, year, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code hrs_recode &lt;- hrs_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.5.3 Covariates # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # composite WITHIN years hrs_cov &lt;- hrs_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule, p_year){ d %&gt;% filter(year &lt;= p_year) %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years hrs_cov &lt;- hrs_cov %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.5.4 Personality Variables hrs_pers &lt;- hrs_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == &quot;2006&quot; &amp; !is.na(value)) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s hrs_alpha &lt;- hrs_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites hrs_pers &lt;- hrs_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.5.5 Outcome Variables # composite within years hrs_out &lt;- hrs_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% group_by(name, year, SID, long_rule) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% filter(year == 2010) %&gt;% ungroup() %&gt;% select(-long_rule) 2.5.6 Combine Data hrs_combined &lt;- hrs_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(hrs_out %&gt;% rename(Outcome = name, o_value = value, o_year = year)) %&gt;% full_join(hrs_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(hrs_cov, hrs_alpha, hrs_pers, hrs_out, hrs_combined, file = sprintf(&quot;%s/data/clean/hrs_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;hrs&quot;, ls())]) 2.6 Longitudinal Aging Study Amsterdam (LASA) The Longitudinal Aging Study Amsterdam is an ongoing longitudinal study that began in 1992. These data are available, through application at https://www.lasa-vu.nl/data/availability_data/availability_data.htm. Participants who were between 55 and 84 years at the start of the study were recruited from the NESTOR study on Living Arrangements and Social Networks of older adults, which was randomly selected from municipality registers in 1992, with an oversampling of the oldest old and men. Data are collected approximately every three years (1992, 1995, 1998, 2001, 2005, 2008, 2011, 2015, 2018). Additional cohorts are introduced every 10 years, with additional participants (Cohorts 2 and 3) recruited in 2002 and 2012. Additional information and documentation are available at https://www.lasa-vu.nl/index.htm. Sample sizes vary by year, ranging from 1522 (Wave H; 763 Cohort 1, 759 Cohort 2) to 3107 (Wave B, Cohort 1). This provides 99% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 2.6.1 Load Data lasa_read_fun &lt;- function(x){ d &lt;- sprintf(&quot;%s/lasa/%s&quot;, data_path, x) %&gt;% read_sav(.) %&gt;% select(one_of(lasa_sids), one_of(old.names), one_of(str_to_lower(old.names)), one_of(str_to_upper(old.names))) %&gt;% as_tibble() %&gt;% haven::zap_labels(.) colnames(d) &lt;- str_to_lower(colnames(d)) return(d) } lasa_codebook &lt;- (codebook %&gt;% filter(study == &quot;LASA&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = orig_itemname) lasa_codebook ## # A tibble: 105 × 17 ## study dataset category name itemname wave wave_letter year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 LASA LASAz004 covariates educ… eduYears NA b 1992 aedu education … &quot;no … &lt;NA&gt; ifels… NA ## 2 LASA LASAz004 covariates gend… sex NA b 1992 sex sex respon… &quot;mal… &lt;NA&gt; ifels… NA ## 3 LASA LASAb036 covariates SRhe… SRhealth NA b 1992 bsubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 4 LASA LASAc036 covariates SRhe… SRhealth NA c 1995 csubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 5 LASA LASAd036 covariates SRhe… SRhealth NA d 1998 dsubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 6 LASA LASAe036 covariates SRhe… SRhealth NA e 2001 esubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 7 LASA LASAf036 covariates SRhe… SRhealth NA f 2005 fsubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 8 LASA LASAg036 covariates SRhe… SRhealth NA g 2008 gsubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 9 LASA LASAh036 covariates SRhe… SRhealth NA h 2011 hsubhea1 Self-perce… &quot;na,… yes ifels… 1 ## 10 LASA LASAi036 covariates SRhe… SRhealth NA i 2015 isubhea1 Self-perce… &quot;na,… yes ifels… 1 ## # ℹ 95 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; lasa_sids &lt;- c(&quot;respnr&quot;, &quot;RESPNR&quot;, &quot;RespNr&quot;, &quot;Respnr&quot;) old.names &lt;- unique(lasa_codebook$orig_itemname) datasets &lt;- sprintf(&quot;%s/lasa&quot;, data_path) %&gt;% list.files(., pattern = &quot;SAV&quot;) lasa &lt;- tibble(datasets = datasets) %&gt;% mutate(data = map(datasets, lasa_read_fun), ncol = map_dbl(data, ncol)) %&gt;% filter(ncol &gt; 1) lasa &lt;- reduce(lasa$data, full_join) %&gt;% haven::zap_labels(.) lasa_long &lt;- lasa %&gt;% rename(SID = respnr) %&gt;% pivot_longer(-SID , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , values_drop_na = T) save(lasa, file = sprintf(&quot;%s/data/clean/lasa_raw.RData&quot;, local_path)) 2.6.2 Recoding &amp; Reverse Scoring # join data with recoding info lasa_recode &lt;- lasa_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname)) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(lasa_long))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } lasa_recode &lt;- lasa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code lasa_recode &lt;- lasa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } lasa_waves &lt;- lasa_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% group_by(SID) %&gt;% summarize(p_year = min(year)) %&gt;% ungroup() 2.6.3 Covariates # composite WITHIN years lasa_cov &lt;- lasa_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% left_join(lasa_waves) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, year, p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) )) comp_fun &lt;- function(d, rule, p_year){ print(paste(rule, p_year)) d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years lasa_cov &lt;- lasa_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% filter(year &lt;= p_year) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.6.4 Personality Variables lasa_pers &lt;- lasa_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% left_join(lasa_waves) %&gt;% filter(year == p_year) %&gt;% filter(!is.na(value)) %&gt;% group_by(SID, year, p_year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s lasa_alpha &lt;- lasa_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites lasa_pers &lt;- lasa_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.6.5 Outcome Variables lasa_cog_waves &lt;- lasa_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(name, SID) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() # composite within years lasa_out &lt;- lasa_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% right_join(lasa_cog_waves) %&gt;% filter(year == o_year) %&gt;% group_by(name, year, SID) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% ungroup() 2.6.6 Combine Data lasa_combined &lt;- lasa_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join( lasa_out %&gt;% rename(Outcome = name, o_value = value, o_year = year) ) %&gt;% full_join(lasa_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(lasa_cov, lasa_alpha, lasa_pers, lasa_out, lasa_combined, file = sprintf(&quot;%s/data/clean/lasa_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;lasa&quot;, ls())]) 2.7 MAP The RUSH Memory and Aging Project (MAP) is an ongoing longitudinal study that began in 1997 (a2012overview?). These data are available, through application from https://www.radc.rush.edu/requests.htm. Participants who were 65 and older were recruited from retirement communities and subsidized senior housing facilities throughout Chicagoland and northeastern Illinois beginning in 1997. Data are collected annually, and all participants are organ donors. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary by year, ranging from 52 (1997) to 2205 participants. This provides 99% power to detect a zero-order correlation effect size of ~.09, two-tailed at alpha .05. 2.7.1 Load Data (map_codebook &lt;- (codebook %&gt;% filter(study == &quot;RADC-MAP&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 7 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini maxi comp_rule ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 RADC-MAP NA outcome cryst… bosNami… long… cts_bname Boston nam… &lt;NA&gt; no ifels… NA NA sum ## 2 RADC-MAP NA covariates age ageBase… 0 age_bl The age at… &lt;NA&gt; no ifels… NA NA skip ## 3 RADC-MAP NA covariates educa… eduYears 0 educ The years … &lt;NA&gt; no ifels… NA NA skip ## 4 RADC-MAP NA covariates gender sex 0 msex Self-repor… &quot;1 =… no ifels… NA NA skip ## 5 RADC-MAP NA pers C C 0 conscientiou… The variab… &quot;Res… no ifels… NA NA average ## 6 RADC-MAP NA pers E E 0 extraversion… The variab… &quot;Res… no ifels… NA NA average ## 7 RADC-MAP NA pers N N 0 neuroticism_… The variab… &quot;Res… no ifels… NA NA average ## # ℹ 1 more variable: long_rule &lt;chr&gt; map &lt;- sprintf(&quot;%s/rush-radc/dataset_1034_long_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;MAP&quot;) 2.7.2 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ old.names &lt;- unique((map_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- map %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info map_recode &lt;- map_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } map_recode &lt;- map_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code map_recode &lt;- map_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.7.3 Covariates # composite WITHIN years map_cov &lt;- map_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years map_cov &lt;- map_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.7.4 Personality Variables map_pers &lt;- map_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) 2.7.5 Outcome Variables map_cog_waves &lt;- map_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() # composite within years map_out &lt;- map_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% right_join(map_cog_waves) %&gt;% filter(wave == o_year &amp; wave &gt; 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, wave, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() 2.7.6 Combine Data map_combined &lt;- map_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( map_out %&gt;% rename(Outcome = name, o_value = value, o_year = wave) ) %&gt;% full_join(map_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(map_cov, map_pers, map_out, map_combined, file = sprintf(&quot;%s/data/clean/map_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;map&quot;, ls())]) 2.8 MARS The RUSH Minority Aging Research Study (MARS) is an ongoing longitudinal study that began in 2004. These data are available, through application, from https://www.radc.rush.edu/requests.htm. Participants were Black individuals 65 and older who were recruited from community locations in the Chicago Metropolitan area and suburbs beginning in 2004. Data are collected annually. Additional participants are recruited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary by year, ranging from 80 (2004) to 790 (2020). This provides 99% power to detect a zero-order correlation effect size of ~.17, two-tailed at alpha .05. (mars_codebook &lt;- (codebook %&gt;% filter(study == &quot;MARS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 5 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini maxi comp_rule ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 MARS NA outcome crystall… bosNami… long… cts_bname Boston nam… &lt;NA&gt; no ifels… NA NA sum ## 2 MARS NA covariates age ageBase… base… age_bl The age at… &lt;NA&gt; no ifels… NA NA skip ## 3 MARS NA covariates education eduYears base… educ The years … &lt;NA&gt; no ifels… NA NA skip ## 4 MARS NA covariates gender sex base… msex Self-repor… &quot;1 =… no ifels… NA NA skip ## 5 MARS NA pers N N base… neuroticism_… The variab… &quot;Res… no ifels… NA NA average ## # ℹ 1 more variable: long_rule &lt;chr&gt; mars &lt;- sprintf(&quot;%s/rush-radc/dataset_1034_long_03-26-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-26-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;MARS&quot;) 2.8.1 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ old.names &lt;- unique((mars_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- mars %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info mars_recode &lt;- mars_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } mars_recode &lt;- mars_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code mars_recode &lt;- mars_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.8.2 Covariates # composite WITHIN years mars_cov &lt;- mars_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years mars_cov &lt;- mars_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.8.3 Personality Variables mars_pers &lt;- mars_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) 2.8.4 Outcome Variables mars_cog_waves &lt;- mars_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() # composite within years mars_out &lt;- mars_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% right_join(mars_cog_waves) %&gt;% filter(wave == o_year &amp; wave &gt; 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, wave, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() 2.8.5 Combine Data mars_combined &lt;- mars_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( mars_out %&gt;% rename(Outcome = name, o_value = value, o_year = wave) ) %&gt;% full_join(mars_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(mars_cov, mars_pers, mars_out, mars_combined, file = sprintf(&quot;%s/data/clean/mars_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;mars&quot;, ls())]) 2.9 ROS The RUSH Religious Orders Study (ROS) is an ongoing longitudinal study that began in 1994 (a2012overview?). These data are available, through application from https://www.radc.rush.edu/requests.htm. Older (65 and above) Catholic nuns, priests, and brothers with no prior dementia diagnosis and who agreed to annual evaluations and eventual organ donation were recruited from more than 40 groups across the United States. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary bt year from 353 participants (1994) to 1487 participants, including 797 deceased participants with autopsy data (2019, 2020). This provides 99% power to detect a zero-order correlation effect size of ~.11, two-tailed at alpha .05. 2.9.1 Load Data (ros_codebook &lt;- (codebook %&gt;% filter(study == &quot;ROS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 9 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini maxi comp_rule ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 ROS NA outcome crystall… bosNami… long… cts_bname Boston nam… &lt;NA&gt; no ifels… NA NA sum ## 2 ROS NA covariates age ageBase… base… age_bl The age at… &lt;NA&gt; no ifels… NA NA skip ## 3 ROS NA covariates education eduYears base… educ The years … &lt;NA&gt; no ifels… NA NA skip ## 4 ROS NA covariates gender sex base… msex Self-repor… &quot;1 =… no ifels… NA NA skip ## 5 ROS NA pers A A base… agreeableness The variab… &quot;Res… no ifels… NA NA average ## 6 ROS NA pers C C base… conscientiou… The variab… &quot;Res… no ifels… NA NA average ## 7 ROS NA pers E E base… extraversion… The variab… &quot;Res… no ifels… NA NA average ## 8 ROS NA pers N N base… neuroticism_… The variab… &quot;Res… no ifels… NA NA average ## 9 ROS NA pers O O base… openness The variab… &quot;Res… no ifels… NA NA average ## # ℹ 1 more variable: long_rule &lt;chr&gt; ros &lt;- sprintf(&quot;%s/rush-radc/dataset_1034_long_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;ROS&quot;) 2.9.2 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ old.names &lt;- unique((ros_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- ros %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info ros_recode &lt;- ros_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } ros_recode &lt;- ros_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code ros_recode &lt;- ros_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.9.3 Covariates # composite WITHIN years ros_cov &lt;- ros_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years ros_cov &lt;- ros_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.9.4 Personality Variables ros_pers &lt;- ros_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) 2.9.5 Outcome Variables ros_cog_waves &lt;- ros_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() # composite within years ros_out &lt;- ros_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% right_join(ros_cog_waves) %&gt;% filter(wave == o_year &amp; wave &gt; 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, wave, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() 2.9.6 Combine Data ros_combined &lt;- ros_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( ros_out %&gt;% rename(Outcome = name, o_value = value, o_year = wave) ) %&gt;% full_join(ros_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(ros_cov, ros_pers, ros_out, ros_combined, file = sprintf(&quot;%s/data/clean/ros_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;ros&quot;, ls())]) 2.10 Origins of the Variances of the Oldest-Old: Octogenarian Twins (OCTO-TWIN) The Origins of the Variances of the Oldest-Old: Octogenarian Twins (OCTO-TWIN) study was a longitudinal study of twin-pairs in Sweden born before 1913 that began in 1991. Data are available, by application, from the study leaders at the Karolinska Institute. Twin-pairs from the Swedish Twin registry who were born before 1913 were invited to be part of the study in 1991. Additional follow-ups were collected in 1993, 1995, 1997, and 1999 on all surviving twins. The initial sample included 351 twin pairs (149 monozygotic and 202 same-sex dizygotic pairs). More information on the study can be found at https://webcache.googleusercontent.com/search?q=cache:HcheF2l9zc0J:https://psy.gu.se/digitalAssets/1469/1469717_octo-twin-brief-presentation.pdf+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us&amp;client=safari. Sample sizes vary by year, from 222 (wave 5; 43 pairs) to 702 (wave 1; 351 pairs), which yields 99% power to detect a correlation effect size of ~.19, two-tailed at alpha .05. 2.10.1 Load Data (octotwin_codebook &lt;- (codebook %&gt;% filter(study == &quot;OCTO-TWIN&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 99 × 16 ## study dataset category name itemname wave year orig_itemname description scale reverse_code recode mini maxi ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 octo-twin OCTO_Wave1 covariates educ… eduYears 1 1991 v130 years scho… &quot;int… &lt;NA&gt; ifels… NA NA ## 2 octo-twin OCTO_Wave1 covariates gend… sex 1 1991 sex Respondent… &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 3 octo-twin OCTO_Wave1 covariates gend… sex2 1 1991 medrec_sex Sex &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 4 octo-twin OCTO_Wave2 covariates gend… sex2 2 1993 medrec_sex Sex &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 5 octo-twin OCTO_Wave3 covariates gend… sex2 3 1995 medrec_sex Sex &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 6 octo-twin OCTO_Wave4 covariates gend… sex2 4 1997 medrec_sex Sex &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 7 octo-twin OCTO_Wave5 covariates gend… sex2 5 2000 medrec_sex Sex &lt;NA&gt; &lt;NA&gt; ifels… NA NA ## 8 octo-twin OCTO_Wave1 covariates SRhe… overall… 1 1991 v201 overall he… &quot;Nam… yes ifels… 1 3 ## 9 octo-twin OCTO_Wave2 covariates SRhe… overall… 2 1993 b201 overall he… &quot;Nam… yes ifels… 1 3 ## 10 octo-twin OCTO_Wave3 covariates SRhe… overall… 3 1995 c201 overall he… &quot;Nam… yes ifels… 1 3 ## # ℹ 89 more rows ## # ℹ 2 more variables: comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; octotwin &lt;- sprintf(&quot;%s/octo-twin/OCTO_Twin_Emorie.sav&quot;, data_path) %&gt;% read_sav() %&gt;% haven::zap_labels(.) 2.10.2 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ old.names &lt;- unique((octotwin_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- octotwin %&gt;% mutate(SID = paste0(v1, v2)) %&gt;% select(SID, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, na.rm=T) if(length(old.names) &gt; 1){ df %&gt;% left_join(cb %&gt;% select(itemname, wave, orig_itemname, reverse_code:long_rule)) } else { df %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule) %&gt;% distinct()) %&gt;% mutate(wave = &quot;0&quot;) } } ` # join data with recoding info octotwin_recode &lt;- octotwin_codebook %&gt;% select(category, name, itemname, wave, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, possibly(rename_fun, NA_real_))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } octotwin_recode &lt;- octotwin_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code octotwin_recode &lt;- octotwin_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.10.3 Covariates # composite WITHIN years octotwin_cov &lt;- octotwin_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave &lt;= 1) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years octotwin_cov &lt;- octotwin_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.10.4 Personality Variables octotwin_pers &lt;- octotwin_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(wave == 1 &amp; !is.na(value)) %&gt;% group_by(SID, wave, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s octotwin_alpha &lt;- octotwin_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, wave, SID, value) %&gt;% group_by(name, wave) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID), check.keys = T), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites octotwin_pers &lt;- octotwin_pers %&gt;% group_by(name, comp_rule, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.10.5 Outcome Variables octotwin_cog_waves &lt;- octotwin_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() # composite within years octotwin_out &lt;- octotwin_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% right_join(octotwin_cog_waves) %&gt;% filter(wave == o_year &amp; wave &gt; 1) %&gt;% group_by(name, wave, SID) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% ungroup() 2.10.6 Combine Data octotwin_combined &lt;- octotwin_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( octotwin_out %&gt;% rename(Outcome = name, o_value = value, o_year = wave) ) %&gt;% full_join(octotwin_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(octotwin_cov, octotwin_alpha, octotwin_pers, octotwin_out, octotwin_combined, file = sprintf(&quot;%s/data/clean/octo-twin_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;octotwin&quot;, ls())]) 2.11 Swedish Adoption Twin Study of Aging (SATSA) The Swedish Adoption Twin Study of Aging (SATSA) is a longitudinal study of twin pairs from the Swedish Twin Registry that began in 1984. Data are available through the ICPSR database at https://www.icpsr.umich.edu/web/ICPSR/studies/3843. All twin-pairs on the Swedish Twin Registry who were separated at an early age were invited to be a part of the study in 1984. A control sample of twins reared together were also included. Additional waves of all participants were collected in 1987, 1990, 1993, 2004, 2007, 2010, 2012, and 2014. More information, including codebooks, scales, and variable search functions can be found at https://www.maelstrom-research.org/mica/individual-study/satsa/#. Sample sizes vary by wave, ranging from 2018 participants at baseline (1984) to 379 participants (IPT7). Given that the target measures were collected at baseline, this provides 99% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 2.11.1 Load Data loadRData &lt;- function(fileName){ #loads an RData file, and returns it load(fileName) get(ls()[ls() != &quot;fileName&quot;]) } satsa_read_fun &lt;- function(x){ # prob_vars &lt;- c(&quot;FHEART&quot;, &quot;FPARKIN&quot;, &quot;FSTROKE&quot;) y &lt;- sprintf(&quot;%s/satsa/%s&quot;, data_path, x) %&gt;% loadRData(.) %&gt;% select(SID = TWINNR, one_of(old.names)) %&gt;% as_tibble() # if(any(prob_vars %in% colnames(y))){ # y &lt;- y %&gt;% mutate_at(vars(one_of(prob_vars)), ~as.numeric(as.character(.))) # } return(y) } satsa_codebook &lt;- (codebook %&gt;% filter(study == &quot;SATSA&quot;))$codebook[[1]] %&gt;% mutate_at(vars(orig_itemname), str_to_upper) satsa_codebook ## # A tibble: 302 × 18 ## study dataset category name itemname wave wave_letter year item_stem orig_itemname description scale reverse_code ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 satsa SATSA_Q1 covariates educa… educati… NA &lt;NA&gt; 1984 EDUC EDUC Education &quot;1\\t… &lt;NA&gt; ## 2 satsa SATSA_Q1 covariates gender sex NA &lt;NA&gt; 1984 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 3 satsa SATSA_IPT1 covariates gender sex NA &lt;NA&gt; 1985 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 4 satsa SATSA_Q2 covariates gender sex NA &lt;NA&gt; 1987 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 5 satsa SATSA_IPT2 covariates gender sex NA &lt;NA&gt; 1989 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 6 satsa SATSA_Q3 covariates gender sex NA &lt;NA&gt; 1990 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 7 satsa SATSA_IPT3 covariates gender sex NA &lt;NA&gt; 1992 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 8 satsa SATSA_Q4 covariates gender sex NA &lt;NA&gt; 1993 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 9 satsa SATSA_IPT4 covariates gender sex NA &lt;NA&gt; 1995 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## 10 satsa SATSA_IPT5 covariates gender sex NA &lt;NA&gt; 1999 &lt;NA&gt; SEX SEX &quot;1 =… &lt;NA&gt; ## # ℹ 292 more rows ## # ℹ 5 more variables: recode &lt;chr&gt;, mini &lt;dbl&gt;, maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; old.names &lt;- unique(satsa_codebook$orig_itemname) %&gt;% str_to_upper datasets &lt;- sprintf(&quot;%s/satsa&quot;, data_path) %&gt;% list.files(., pattern = &quot;.rda&quot;) satsa &lt;- tibble(datasets = datasets) %&gt;% mutate(data = map(datasets, satsa_read_fun), ncol = map_dbl(data, ncol)) %&gt;% filter(ncol != 0) satsa &lt;- reduce(satsa$data, full_join) %&gt;% haven::zap_labels(.) satsa &lt;- satsa %&gt;% mutate_if(is.factor, ~as.numeric(sub(&quot;^\\\\(0*([0-9]+)\\\\).+$&quot;, &quot;\\\\1&quot;, .))) satsa_long &lt;- satsa %&gt;% gather(key = orig_itemname, value = value, -SID, na.rm = T) save(satsa, file = sprintf(&quot;%s/data/clean/satsa_raw.RData&quot;, local_path)) 2.11.2 Recoding &amp; Reverse Scoring satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info satsa_recode &lt;- satsa_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(satsa_long))) # recode recode_fun &lt;- function(rule, y, year, p_year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } satsa_recode &lt;- satsa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(p_year = 1984) %&gt;% group_by(recode, year, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code satsa_recode &lt;- satsa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.11.3 Covariates # composite WITHIN years satsa_cov &lt;- satsa_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, year, p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) )) comp_fun &lt;- function(d, rule, p_year){ print(paste(rule, p_year)) d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years satsa_cov &lt;- satsa_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% filter(year &lt;= p_year) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) 2.11.4 Personality Variables satsa_pers &lt;- satsa_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == 1984 &amp; !is.na(value)) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s satsa_alpha &lt;- satsa_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites satsa_pers &lt;- satsa_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) 2.11.5 Outcome Variables # composite within years satsa_out &lt;- satsa_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == 1999) %&gt;% group_by(name, year, SID) %&gt;% summarize(value = sum(value, na.rm = T)) %&gt;% ungroup() 2.11.6 Combine Data satsa_combined &lt;- satsa_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(satsa_out %&gt;% rename(Outcome = name, o_value = value, o_year = year)) %&gt;% full_join(satsa_cov) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) save(satsa_cov, satsa_alpha, satsa_pers, satsa_out, satsa_combined, file = sprintf(&quot;%s/data/clean/satsa_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;satsa&quot;, ls())]) 2.12 Seattle Longitudinal Study (SLS) The Seattle Longitudinal Study is an ongoing longitudinal study of adult Seattle residents that began in 1956. Data are available, by request from https://sls.psychiatry.uw.edu/researchers/public-access-data-sets/. The first cohort of participants were recruited from HMO plan members of the Group Health Cooperative of Puget Sound in Seattle. Seven years later, the first cohort and a new cohort of similarly aged participants were solicited again. Over the next half century, this procedure was repeated every seven years and is ongoing. More information on the measures collected can be found at https://sls.psychiatry.uw.edu/researchers/measures/. Sample sizes vary by year, from 302 (1956) to 421 (2005). This provides 99% power to detect correlation effect sizes of ~.23, two-tailed alpha at .05. 2.13 Descriptives of All Studies loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) load(path) get(ls()[grepl(type, ls())]) } ipd_data &lt;- tibble( study = studies[!studies %in% c(&quot;CNLSY&quot;, &quot;SLS&quot;)] , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID))) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% mutate(age = ifelse(is.na(age), p_year - yearBrth, age)) ipd_data &lt;- ipd_data %&gt;% group_by(study, Trait, SID) %&gt;% filter(p_year == min(p_year)) %&gt;% ungroup() %&gt;% select(-p_year, -o_year, -Outcome) %&gt;% rename(crystallized = o_value) %&gt;% distinct() %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(wide_data = map(data, ~(.) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;p_value&quot;))) cln &lt;- c(&quot;Study&quot;, &quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;, &quot;Crystallized / Knowledge&quot;, &quot;Age (Years)&quot;, &quot;Education (Years)&quot;, &quot;% Women&quot;, &quot;Valid N (Range)&quot;) desc_tab &lt;- ipd_data %&gt;% select(-p_year, -o_year, -yearBrth, -SRhealth, -gender) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, o_value), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %&gt;% pivot_wider(names_from = Trait, values_from = p_value, values_fn = mean) %&gt;% pivot_longer(cols = c(education:C), values_to = &quot;value&quot;, names_to = &quot;item&quot;, values_drop_na = T) %&gt;% group_by(study, item) %&gt;% summarize(est = sprintf(&quot;%.2f (%.2f)&quot;, mean(value, na.rm = T), sd(value, na.rm = T))) %&gt;% ungroup() %&gt;% pivot_wider(names_from = item, values_from = est) %&gt;% full_join( ipd_data %&gt;% select(study, Trait, p_value, Outcome, SID, o_value) %&gt;% distinct() %&gt;% group_by(study, Trait) %&gt;% tally() %&gt;% group_by(study) %&gt;% summarize(n = sprintf(&quot;%i - %i&quot;, min(n), max(n))) ) %&gt;% full_join( ipd_data %&gt;% select(study, SID, gender) %&gt;% distinct() %&gt;% group_by(study) %&gt;% summarize(gender = mean(gender, na.rm = T)*100) %&gt;% ungroup() ) %&gt;% select(study, E, A, C, N, O, crystallized, age, education, gender, n) %&gt;% kable(., &quot;html&quot; , digits = 2 , col.names = cln , caption = &quot;&lt;strong&gt;Table 3&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Descriptive Statistics of All Harmonized Measures Across Samples&quot; , align = c(&quot;l&quot;, rep(&quot;c&quot;,9))) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;Personality Characteristics&quot; = 5, &quot; &quot; = 5)) %&gt;% add_footnote(notation = &quot;none&quot;, label = &quot;&lt;em&gt;Note.&lt;/em&gt; E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness; Age, education, and gender were assessed at the first baseline personality assessment. Valid N (Range) indicates the range of valid observations with complete personality trait and outcome data across different trait measures.&quot;, escape = F) desc_tab save_kable(desc_tab, file = sprintf(&quot;%s/results/tables/tab-3-desc.html&quot;, local_path)) r_fun &lt;- function(d, study){ cols &lt;- c(&quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;, &quot;crystallized&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) cols_long &lt;- mapvalues(cols, c(traits$short_name, outcomes$short_name, covars$short_name) , c(traits$long_name, outcomes$long_name, covars$long_name)) colns &lt;- paste(1:length(cols), &quot;. &quot;, cols_long, sep = &quot;&quot;) r &lt;- d %&gt;% select(all_of(cols)) %&gt;% cor(., use = &quot;pairwise&quot;) r &lt;- apply(r, c(1,2), function(x) ifelse(is.na(x), &quot;&quot;, ifelse(x == 1, &quot;--&quot;, sprintf(&quot;%.2f&quot;, x)))) r[upper.tri(r)] &lt;- &quot;&quot; diag(r) &lt;- &quot;--&quot; rownames(r) &lt;- colns; colnames(r) &lt;- seq(1,length(cols)) tab &lt;- r %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot; &quot;) %&gt;% kable(. , &quot;html&quot; , escape = F , align = c(&quot;l&quot;, rep(&quot;c&quot;, length(cols))) , caption = sprintf(&quot;&lt;strong&gt;Table SX&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Zero-Order Correlations Between All Study Variables in %s&lt;/em&gt;&quot;, study) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) save_kable(tab, file = sprintf(&quot;%s/results/tables/zero-order-cors/%s.html&quot;, local_path, study)) return(tab) } loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) print(path) load(path) get(ls()[grepl(type, ls())]) } ipd3_meta_data &lt;- tibble( study = studies[!studies %in% c(&quot;CNLSY&quot;, &quot;SLS&quot;)] , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID))) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% mutate(age = ifelse(is.na(age), p_year - yearBrth, age)) ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/base-i_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/eas_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/gsoep_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/hilda_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/hrs_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/lasa_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/map_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/mars_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/octo-twin_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/ros_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/satsa_cleaned.RData&quot; ipd3_meta_data ## # A tibble: 119,597 × 13 ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 3.83 1990 10004 crystallized 2.17 2000 17 0 4 1918 72 ## 2 BASE E 3.83 1990 10010 crystallized 3.08 1995 11 0 2 1911 79 ## 3 BASE E 2.5 1990 10033 crystallized 0.909 1997 8 1 5 1910 80 ## 4 BASE E 3 1990 10034 crystallized 6.54 1995 10 0 5 1914 76 ## 5 BASE E 2.5 1990 10111 crystallized 6.54 1995 13 1 4 1901 89 ## 6 BASE E 3.17 1990 10115 crystallized 10 1995 11 0 2 1918 72 ## 7 BASE E 3 1990 10116 crystallized 3.85 1995 10 0 4 1917 73 ## 8 BASE E 3 1990 10145 crystallized 6.36 1997 10 1 5 1897 93 ## 9 BASE E 3.33 1990 10175 crystallized 2.31 1995 8 1 3 1911 79 ## 10 BASE E 3.33 1990 10188 crystallized 5.77 2004 10 1 2 1903 87 ## # ℹ 119,587 more rows ipd_cors &lt;- ipd3_meta_data %&gt;% select(-p_year, -o_year, -yearBrth, -SRhealth) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, o_value), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %&gt;% pivot_wider(names_from = Trait, values_from = p_value, values_fn = mean) %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(rtab = map2(data, study, r_fun)) "],["runmodels.html", "Chapter 3 Method 1: Pooled One Stage Models without Study-Specific Effects 3.1 Step 1: Combine Data 3.2 Step 2: Run Models and Extract Results", " Chapter 3 Method 1: Pooled One Stage Models without Study-Specific Effects Method 1 is a fully pooled procedure in which a single estimate of a prospective Big Five personality characteristic-crystallized ability association is estimated across samples. In other words, there are no sample-specific estimates of the associations. 3.1 Step 1: Combine Data loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) load(path) get(ls()[grepl(type, ls())]) } ipd_reg_data &lt;- tibble( study = studies[!studies %in% c(&quot;CNLSY&quot;, &quot;SLS&quot;)] , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID))) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% mutate(age = ifelse(is.na(age), p_year - yearBrth, age)) ipd_reg_data ## # A tibble: 119,597 × 13 ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 3.83 1990 10004 crystallized 2.17 2000 17 0 4 1918 72 ## 2 BASE E 3.83 1990 10010 crystallized 3.08 1995 11 0 2 1911 79 ## 3 BASE E 2.5 1990 10033 crystallized 0.909 1997 8 1 5 1910 80 ## 4 BASE E 3 1990 10034 crystallized 6.54 1995 10 0 5 1914 76 ## 5 BASE E 2.5 1990 10111 crystallized 6.54 1995 13 1 4 1901 89 ## 6 BASE E 3.17 1990 10115 crystallized 10 1995 11 0 2 1918 72 ## 7 BASE E 3 1990 10116 crystallized 3.85 1995 10 0 4 1917 73 ## 8 BASE E 3 1990 10145 crystallized 6.36 1997 10 1 5 1897 93 ## 9 BASE E 3.33 1990 10175 crystallized 2.31 1995 8 1 3 1911 79 ## 10 BASE E 3.33 1990 10188 crystallized 5.77 2004 10 1 2 1903 87 ## # ℹ 119,587 more rows 3.1.1 Study-Level Moderators First, we need to bring in a few study-level moderators from Table 4, which includes information about the continent and country of origin, and the type of personality scale. Then we’ll join those data with cleaned data from each study in order to calculate the average age at baseline, the average baseline year, and the average interval between personality and cogntiive measurements. Because these vary within studies across personality traits and outcomes, we calculate baseline age, year, and prediction interval for all combinations of these separately. ipd_reg_data &lt;- sprintf(&quot;%s/codebooks/crystallized_tables.xlsx&quot;, local_path) %&gt;% read_xlsx(., sheet = &quot;Table 4&quot;) %&gt;% select(-Category, -Construct, -category) %&gt;% pivot_longer(cols = c(&quot;BASE-I&quot;:&quot;SATSA&quot;) , names_to = &quot;study&quot; , values_to = &quot;value&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) %&gt;% mutate(continent = relevel(factor(continent), ref = &quot;North America&quot;) , country = relevel(factor(country), ref = &quot;United States&quot;) , scale = relevel(factor(scale), ref = &quot;NEO-FFI&quot;)) %&gt;% # mutate(p_year = as.numeric(p_year)) %&gt;% right_join(ipd_reg_data) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate(baseAge = mean(age, na.rm = T) - 60, # center at age 60 predInt = mean(o_year - p_year) - 5, # center at 5 years baseYear = ifelse(study %in% c(&quot;MARS&quot;, &quot;MAP&quot;, &quot;ROS&quot;), mean(p_year), mean(p_year) - 2000)) %&gt;% # center at 2000 ungroup() ipd_reg_data ## # A tibble: 119,597 × 19 ## study continent country scale baseAge baseYear predInt Trait p_value p_year SID Outcome o_value o_year education gender ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 3.7 2006 8024 crysta… 6.68 2006 10 0 ## 2 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 3.6 2006 8265 crysta… 6.36 2011 12 0 ## 3 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 5 2006 8296 crysta… 5.23 2006 14 0 ## 4 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4.4 2006 8375 crysta… 4.77 2010 12 1 ## 5 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 3.2 2006 8597 crysta… 7.73 2009 14 0 ## 6 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4 2006 8622 crysta… 9.5 2011 19 1 ## 7 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4.2 2006 8634 crysta… 4.09 2007 12 0 ## 8 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4.2 2006 8637 crysta… 1.41 2006 8 1 ## 9 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4.5 2006 8674 crysta… 2.32 2006 14 1 ## 10 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4.1 2006 8675 crysta… 6.09 2006 15 0 ## # ℹ 119,587 more rows ## # ℹ 3 more variables: SRhealth &lt;dbl&gt;, yearBrth &lt;dbl&gt;, age &lt;dbl&gt; 3.1.2 Harmonize Data Next, we need to harmonize the data across studies. As we preregistered, continuous variables (personality, cognition, and self-rated health) will be calclulated as percentages of maximum possible separately for each study, Trait and outcome. Unlike standardization procedures, that have a mean of zero and unit variance and can be misleading when data are skewed, POMP does not rescale sample variance based on the observed data, which overly relies on deviations from the mean. Instead, POMP relies on the ratio between the difference between a score and the minimum and the maximum and minimum, or POMP = \\(\\frac{observed-minimum}{maximum-minimum}\\)*10. In addition, gender will be dummy coded with male as the reference group, education will be centered at 12 years of education, and age will be grand mean-centered in each study (also for each trait and outcome combination). ipd_reg_data &lt;- ipd_reg_data %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, o_value), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate(gender = factor(gender, levels = c(0,1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), education = education - 12, # center at 12 years of education age = age - mean(age, na.rm = T)) %&gt;% # center ungroup() %&gt;% select(-yearBrth) ipd_reg_data ## # A tibble: 119,597 × 18 ## study continent country scale baseAge baseYear predInt Trait p_value p_year SID Outcome o_value o_year education gender ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 5.81 2006 8024 crysta… 6.68 2006 -2 Male ## 2 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 5.48 2006 8265 crysta… 6.36 2011 0 Male ## 3 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 10 2006 8296 crysta… 5.23 2006 2 Male ## 4 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 8.06 2006 8375 crysta… 4.77 2010 0 Female ## 5 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 4.19 2006 8597 crysta… 7.73 2009 2 Male ## 6 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 6.77 2006 8622 crysta… 9.5 2011 7 Female ## 7 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 7.42 2006 8634 crysta… 4.09 2007 0 Male ## 8 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 7.42 2006 8637 crysta… 1.41 2006 -4 Female ## 9 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 8.39 2006 8674 crysta… 2.32 2006 2 Female ## 10 EAS North Ame… United… IPIP… 19.5 11.0 -2.85 A 7.10 2006 8675 crysta… 6.09 2006 3 Male ## # ℹ 119,587 more rows ## # ℹ 2 more variables: SRhealth &lt;dbl&gt;, age &lt;dbl&gt; 3.1.3 Save Data Files Now, we’ll save these data files into separate data files for each trait, outcome combination. This makes it easier to track each data set that will be used in subsequent analyses. save_fun &lt;- function(d, trait, outcome){ save(d, file = sprintf(&quot;%s/data/one_stage/%s_%s.RData&quot;, local_path, trait, outcome)) } ipd_reg_data %&gt;% group_by(Trait, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, Trait, Outcome), save_fun)) ## # A tibble: 5 × 3 ## Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 A crystallized &lt;NULL&gt; ## 2 C crystallized &lt;NULL&gt; ## 3 E crystallized &lt;NULL&gt; ## 4 N crystallized &lt;NULL&gt; ## 5 O crystallized &lt;NULL&gt; 3.2 Step 2: Run Models and Extract Results Once the data are prepped, we are ready to begin running models! For Method 1: Pooled One Stage Models without Study-Specific Effects, we will run two variants. The first is a simple linear regression that does not account for nesting / clustering in the data (specifically individuals within studies). The second is a simple linear regression with cluster-robust standard errors. The latter is of particular interest and benefit when study-specific effects are not of interest and one wants the best estimate of an aggregate, fixed effect. 3.2.1 Method 1A: Linear Regression 3.2.1.1 Analytic Plan In the present study, we aimed to examine associations between personality traits and crystallized cognitive abilities using fully pooled, single-stage regression models with individual participant data. Below, we detail each stage of the analysis. 3.2.1.1.1 Statistical Modeling A single regression model tests the relationship between personality and crystallized cognitive ability across all samples. Using the R programming language, we created a series of functions to (1) set up and run the model and extract model coefficients and (2) extract simple-effects predictions for moderator models (i.e. predicted values across levels of the moderator values). The basic, unadjusted form of the model is as follows: \\(Y_{ij} = b_0 + b_1 \\ast predictor_{ij} + \\epsilon_{ij}\\) \\(\\varepsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\) where \\(b_1\\) represents the overall effect of personality predicting the outcome. For moderator models, we add two additional terms, \\(b_2\\), which captures the prospective association between a moderator and cognitive ability, adjusting for personality, and b_3, which captures how cognitive ability varies as a function of both personality and the moderator (e.g., does the association differ for males and females). Models were tested using the lm() function from base R and the tidy() function from the broom package (version 1.0.1; D. Robinson et al., 2022) to extract model coefficients and confidence intervals (CI). Inferences were made based on the 95% confidence intervals. Simple-effects predictions were calculated by providing the full range of personality (0-10) and average levels of the covariates from the data used to estimate the model as the “newdata” argument in the base R predict() function. 3.2.1.2 Model Function The first thing we need is a function that will bring in the data, create a formula in the model based on input on the type (Frequentist or Bayesian), moderators (none, age, gender, SRhealth, and education), and combinations of covariates (single or fully adjusted based on age, gender, SRhealth, and education). Then we run the model, extract its fixed effect estimates, and save both for later. By saving the results, it will make it easier and faster for us to extract the necessary model results later while still retaining all information from the original model. ipd1a_mod_fun &lt;- function(trait, outcome, type, mod, cov){ ## load the data load(sprintf(&quot;%s/data/one_stage/%s_%s.RData&quot;, local_path, trait, outcome)) ## model formula if (cov == &quot;all&quot;) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if (!cov %in% c(&quot;all&quot;, &quot;none&quot;)) cv &lt;- cov rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;none&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;){rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;))} rhs &lt;- paste(rhs, collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## compiled Bayesian model to speed up processing and avoid crashing if(type == &quot;Bayesian&quot;) load(sprintf(&quot;%s/results/1a_ipd_reg/bayes_sample_mod.RData&quot;, local_path)) ## run the models &amp; save m &lt;- if(type == &quot;Frequentist&quot;){do.call(&quot;lm&quot;, list(formula = f, data = quote(d)))} else {update(m, formula = f, nelocal_pathata = d, cores = 4)} save(m, file = sprintf(&quot;%s/results/1a_ipd_reg/%s/models/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) save(fx, file = sprintf(&quot;%s/results/1a_ipd_reg/%s/summary/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) ## get simple effects for moderator tests if(mod != &quot;none&quot;){ pred.fx &lt;- ipd1a_simpeff_fun(m, mod, type) save(pred.fx, file = sprintf(&quot;%s/results/1a_ipd_reg/%s/predicted/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;rhs&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;cv&quot;)) gc() } 3.2.1.3 Simple Effects Function ipd1a_simpeff_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { unique(fct_lev[,moder][[1]]) } mod_frame &lt;- expand.grid( p_value = seq(0,10,.5) , modvalue = md_levs , stringsAsFactors = F ) %&gt;% setNames(c(&quot;p_value&quot;, moder)) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)[1])) } } pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m, newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, predict(m, newdata = mod_frame, interval = &quot;confidence&quot;) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$model)), pred = fit, lower = lwr, upper = upr) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 3.2.1.4 Run Models and Summaries The code below generates all possible preregistrered combinations of traits, outcomes, types, moderators, and covariates. Then these combinations are fed serially to the model function written previously, which will run and save the results. load(sprintf(&quot;%s/data/one_stage/E_crystallized.RData&quot;, local_path)) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = F)))) %&gt;% unnest(data) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- bf(o_value ~ p_value + age + gender + education) m &lt;- brm(formula = f , data = d , prior = Prior , iter = Iter , warmup = Warmup , cores = 4) save(m, file = sprintf(&quot;%s/results/1a_ipd_reg/bayes_sample_mod.RData&quot;, local_path)) rm(list = c(&quot;d&quot;, &quot;Prior&quot;, &quot;Iter&quot;, &quot;Warmup&quot;, &quot;treedepth&quot;, &quot;f&quot;, &quot;m&quot;)) plan(multisession(workers = 10L)) nested_ipd1a_reg &lt;- ## moderator combinations crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) , Covariate = c(&quot;none&quot;, &quot;all&quot;) ) %&gt;% full_join( # undmoderator combinations crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;none&quot;, stdyModers$short_name) , Covariate = c(&quot;none&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;all&quot;) ) ) %&gt;% mutate(run = # pmap(list(Trait, Outcome, type, Moderator, Covariate) future_pmap(list(Trait, Outcome, type, Moderator, Covariate) , possibly(ipd1a_mod_fun, &quot;uh-oh&quot;) , .progress = T , .options = furrr_options( globals = c(&quot;ipd1a_mod_fun&quot; , &quot;ipd1a_simpeff_fun&quot; , &quot;read_path&quot; , &quot;local_path&quot; , &quot;res_path&quot; , &quot;codebook&quot; , &quot;covars&quot; , &quot;moders&quot; , &quot;outcomes&quot; , &quot;studies&quot; , &quot;stdyModers&quot; , &quot;traits&quot; , &quot;data_path&quot;) , packages = c(&quot;lme4&quot; , &quot;broom&quot; , &quot;psych&quot; , &quot;knitr&quot; , &quot;broom.mixed&quot; , &quot;brms&quot; #, &quot;tidybayes&quot; #, &quot;bootpredictlme4&quot; , &quot;rstan&quot; , &quot;estimatr&quot; #, &quot;merTools&quot; , &quot;plyr&quot; , &quot;tidyverse&quot;)) ) ) closeAllConnections() 3.2.1.5 Compile Results Once all the models are run, we are ready to compile all their results. By saving the fixed effects results previously, we are able to simply load those results and ignore the models. However, because we also saved the models, we can also recall and extract information from them if and when needed. loadRData &lt;- function(fileName, type, obj, folder){ # loads an RData file, and returns it # path &lt;- sprintf(&quot;%s/results/1a_ipd_reg/%s/%s/%s&quot;, res_path, type, folder, fileName) path &lt;- sprintf(&quot;%s/results/1a_ipd_reg/%s/%s/%s&quot;, local_path, type, folder, fileName) # load(url(path)) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd1a_reg &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/1a_ipd_reg/%s/summary&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), fx = map2(file, type, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;))) %&gt;% select(-file) nested_ipd1a_reg ## # A tibble: 410 × 6 ## type Outcome Trait Moderator Covariate fx ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 Frequentist crystallized A age all &lt;tibble [7 × 4]&gt; ## 2 Frequentist crystallized A age none &lt;tibble [4 × 4]&gt; ## 3 Frequentist crystallized A baseAge age &lt;tibble [5 × 4]&gt; ## 4 Frequentist crystallized A baseAge all &lt;tibble [8 × 4]&gt; ## 5 Frequentist crystallized A baseAge education &lt;tibble [5 × 4]&gt; ## 6 Frequentist crystallized A baseAge gender &lt;tibble [5 × 4]&gt; ## 7 Frequentist crystallized A baseAge none &lt;tibble [4 × 4]&gt; ## 8 Frequentist crystallized A baseYear age &lt;tibble [5 × 4]&gt; ## 9 Frequentist crystallized A baseYear all &lt;tibble [8 × 4]&gt; ## 10 Frequentist crystallized A baseYear education &lt;tibble [5 × 4]&gt; ## # ℹ 400 more rows As can be seen above, the resulting data frame is nested, but it can be easily unnested using the unnest() function. nested_ipd1a_reg %&gt;% unnest(fx) ## # A tibble: 2,993 × 9 ## type Outcome Trait Moderator Covariate term estimate conf.low conf.high ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Frequentist crystallized A age all (Intercept) 5.86 5.70 6.01 ## 2 Frequentist crystallized A age all p_value -0.0456 -0.0642 -0.0269 ## 3 Frequentist crystallized A age all age 0.0157 0.00510 0.0262 ## 4 Frequentist crystallized A age all genderFemale 0.165 0.103 0.228 ## 5 Frequentist crystallized A age all SRhealth -0.00315 -0.0203 0.0140 ## 6 Frequentist crystallized A age all education 0.260 0.249 0.270 ## 7 Frequentist crystallized A age all p_value:age -0.00136 -0.00275 0.0000259 ## 8 Frequentist crystallized A age none (Intercept) 7.20 7.07 7.34 ## 9 Frequentist crystallized A age none p_value -0.141 -0.158 -0.124 ## 10 Frequentist crystallized A age none age 0.00858 -0.00218 0.0193 ## # ℹ 2,983 more rows 3.2.1.5.1 Tables 3.2.1.5.1.1 Fixed Effects Next, we want to format the study results in APA table format. In this case, we are interested in the fixed effects of personality predicting cognitive ability when there were no moderators, and the personality x moderator interaction when there was a moderator. ## format results ipd1a_reg_tab &lt;- nested_ipd1a_reg %&gt;% unnest(fx) %&gt;% # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = ifelse(Moderator != &quot;None&quot; &amp; Covariate == &quot;None&quot;, Moderator, Covariate), Covariate = factor(Covariate, moders$short_name, str_wrap(moders$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, c(&quot;scaleBFIMS&quot;, &quot;scaleIPIPNEO&quot;, &quot;scaleTDAM40&quot;, &quot;countryTheNetherlands&quot;) , c(&quot;scaleBFI-S&quot;, &quot;scaleIPIP NEO&quot;, &quot;scaleTDA-40&quot;, &quot;countryThe Netherlands&quot;)), term2 = factor(term, c(moders$short_term, stdyModers$short_term), c(moders$long_term, stdyModers$long_term))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig, -term) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd1a_reg_tab ## # A tibble: 172 × 10 ## type Outcome Moderator Covariate term2 E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bayesian Crystallized Ability None None Personality &lt;strong&gt;-0.08&lt;br&gt;[-… &lt;str… 0.00… -0.1… &lt;str… ## 2 Bayesian Crystallized Ability None Age Personality &lt;strong&gt;-0.09&lt;br&gt;[-… &lt;str… 0.00… 0.09… &lt;str… ## 3 Bayesian Crystallized Ability None Gender Personality &lt;strong&gt;-0.08&lt;br&gt;[-… &lt;str… 0.02… -0.0… &lt;str… ## 4 Bayesian Crystallized Ability None Education Personality &lt;strong&gt;-0.07&lt;br&gt;[-… &lt;str… -0.0… -0.1… &lt;str… ## 5 Bayesian Crystallized Ability None Fully Adjusted Personality &lt;strong&gt;-0.07&lt;br&gt;[-… &lt;str… -0.0… -0.0… &lt;str… ## 6 Bayesian Crystallized Ability Age None Age 0.000&lt;br&gt;[-0.001, 0… -0.0… &lt;str… 0.02… -0.0… ## 7 Bayesian Crystallized Ability Age Fully Adjusted Age 0.000&lt;br&gt;[-0.001, 0… -0.0… -0.0… -0.0… &lt;str… ## 8 Bayesian Crystallized Ability Gender None Gender (Male v Female) &lt;strong&gt;0.07&lt;br&gt;[0.… &lt;str… 0.00… -0.1… -0.0… ## 9 Bayesian Crystallized Ability Gender Fully Adjusted Gender (Male v Female) &lt;strong&gt;0.05&lt;br&gt;[0.… &lt;str… 0.03… -0.0… -0.0… ## 10 Bayesian Crystallized Ability Education None Education (Years) &lt;strong&gt;0.004&lt;br&gt;[0… -0.0… &lt;str… 0.19… 0.00… ## # ℹ 162 more rows Now that we’ve formatted the values, we can group by moderators and save results as separate tables. Even though additional information could be included given that we have one outcome, we’ll stick with this split because it will make it easier for those using this tutorial who multiple traits, outcomes, covariates, and moderators. ## table function ipd1a_tab_fun &lt;- function(d, type, moder){ # long outcome name md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- if(length(unique(d$term2)) &gt; 1) c(2, rep(1,5)) else rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- if(length(unique(d$term2)) == 1) c(&quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term2)) == 1) { d &lt;- d %&gt;% select(-term2); dubs &lt;- F } # caption cap &lt;- if(md == &quot;none&quot;) &quot;1A Pooled Analysis of Individual Participant Data: Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;1A Pooled Analysis of Individual Participant Data: Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) # kable the table tab &lt;- d %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/1a_ipd_reg/%s/tables/overall/%s.html&quot; , local_path, type, md)) return(tab) # return the html table } ipd1a_fx_tab &lt;- ipd1a_reg_tab %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd1a_tab_fun)) ipd1a_reg_tab ## # A tibble: 172 × 10 ## type Outcome Moderator Covariate term2 E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bayesian Crystallized Ability None None Personality &lt;strong&gt;-0.08&lt;br&gt;[-… &lt;str… 0.00… -0.1… &lt;str… ## 2 Bayesian Crystallized Ability None Age Personality &lt;strong&gt;-0.09&lt;br&gt;[-… &lt;str… 0.00… 0.09… &lt;str… ## 3 Bayesian Crystallized Ability None Gender Personality &lt;strong&gt;-0.08&lt;br&gt;[-… &lt;str… 0.02… -0.0… &lt;str… ## 4 Bayesian Crystallized Ability None Education Personality &lt;strong&gt;-0.07&lt;br&gt;[-… &lt;str… -0.0… -0.1… &lt;str… ## 5 Bayesian Crystallized Ability None Fully Adjusted Personality &lt;strong&gt;-0.07&lt;br&gt;[-… &lt;str… -0.0… -0.0… &lt;str… ## 6 Bayesian Crystallized Ability Age None Age 0.000&lt;br&gt;[-0.001, 0… -0.0… &lt;str… 0.02… -0.0… ## 7 Bayesian Crystallized Ability Age Fully Adjusted Age 0.000&lt;br&gt;[-0.001, 0… -0.0… -0.0… -0.0… &lt;str… ## 8 Bayesian Crystallized Ability Gender None Gender (Male v Female) &lt;strong&gt;0.07&lt;br&gt;[0.… &lt;str… 0.00… -0.1… -0.0… ## 9 Bayesian Crystallized Ability Gender Fully Adjusted Gender (Male v Female) &lt;strong&gt;0.05&lt;br&gt;[0.… &lt;str… 0.03… -0.0… -0.0… ## 10 Bayesian Crystallized Ability Education None Education (Years) &lt;strong&gt;0.004&lt;br&gt;[0… -0.0… &lt;str… 0.19… 0.00… ## # ℹ 162 more rows ## Frequentist, no moderator (ipd1a_fx_tab %&gt;% filter(type == &quot;Frequentist&quot; &amp; Moderator == &quot;None&quot;))$tab[[1]] (#tab:ipd1a table saving)1A Pooled Analysis of Individual Participant Data: Fixed Effect Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Covariate b [CI] b [CI] b [CI] b [CI] b [CI] None -0.08[-0.10, -0.07] -0.14[-0.16, -0.12] 0.007[-0.01, 0.02] -0.003[-0.02, 0.01] 0.20[0.19, 0.22] Age -0.09[-0.10, -0.07] -0.14[-0.16, -0.12] 0.007[-0.01, 0.02] 0.002[-0.01, 0.02] 0.19[0.18, 0.21] Gender -0.08[-0.09, -0.06] -0.14[-0.15, -0.12] 0.02[-0.001, 0.03] 0.007[-0.007, 0.02] 0.19[0.17, 0.21] Education -0.07[-0.09, -0.06] -0.06[-0.08, -0.05] -0.01[-0.03, 0.005] -0.03[-0.04, -0.01] 0.10[0.09, 0.12] Fully Adjusted -0.03[-0.05, -0.02] -0.05[-0.06, -0.03] 0.03[0.02, 0.05] -0.03[-0.04, -0.01] 0.13[0.11, 0.14] ## bayesian (ipd1a_fx_tab %&gt;% filter(type == &quot;Bayesian&quot; &amp; Moderator == &quot;None&quot;))$tab[[1]] (#tab:ipd1a table saving)1A Pooled Analysis of Individual Participant Data: Fixed Effect Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Covariate b [CI] b [CI] b [CI] b [CI] b [CI] None -0.08[-0.10, -0.07] -0.14[-0.16, -0.12] 0.007[-0.010, 0.02] -0.18[-0.59, 0.18] 0.20[0.19, 0.22] Age -0.09[-0.10, -0.07] -0.14[-0.16, -0.12] 0.007[-0.01, 0.02] 0.09[-0.21, 0.47] 0.19[0.18, 0.21] Gender -0.08[-0.09, -0.06] -0.14[-0.15, -0.12] 0.02[-0.000, 0.03] -0.08[-0.68, 0.41] 0.19[0.17, 0.20] Education -0.07[-0.09, -0.06] -0.06[-0.08, -0.05] -0.01[-0.03, 0.006] -0.11[-0.72, 0.19] 0.10[0.09, 0.12] Fully Adjusted -0.07[-0.08, -0.05] -0.07[-0.09, -0.06] -0.01[-0.03, 0.006] -0.05[-0.33, 0.29] 0.11[0.09, 0.12] ipd1a_tab_fun &lt;- function(d, type, cov){ # long outcome name covar &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cv &lt;- if (cov == &quot;None&quot;) &quot;Unadjusted&quot; else cov cap &lt;- sprintf(&quot;1A Pooled Analysis of Individual Participant Data: Fixed Effect Estimates of %s Personality-Crystallized Domain Associations&quot;, cv) # kable the table tab &lt;- d %&gt;% select(-Moderator) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/1a_ipd_reg/%s/tables/key terms/%s.html&quot; , local_path, type, covar)) return(tab) # return the html table } ipd1a_fx_tab2 &lt;- ipd1a_reg_tab %&gt;% arrange(Outcome, Moderator, term2) %&gt;% filter(Covariate %in% c(&quot;None&quot;, &quot;Fully Adjusted&quot;)) %&gt;% group_by(Outcome, type, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Covariate), ipd1a_tab_fun)) ## Frequentist, no moderator (ipd1a_fx_tab2 %&gt;% filter(type == &quot;Frequentist&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] (#tab:ipd1a key term tab)1A Pooled Analysis of Individual Participant Data: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality -0.03[-0.05, -0.02] -0.05[-0.06, -0.03] 0.03[0.02, 0.05] -0.03[-0.04, -0.01] 0.13[0.11, 0.14] Age Age -0.000[-0.002, 0.001] -0.001[-0.003, 0.000] 0.001[-0.001, 0.002] 0.002[0.001, 0.003] -0.003[-0.005, -0.002] Gender Gender (Male v Female) 0.05[0.02, 0.08] 0.03[-0.01, 0.06] 0.01[-0.02, 0.05] -0.01[-0.04, 0.01] -0.02[-0.06, 0.009] Education Education (Years) 0.007[0.002, 0.01] -0.001[-0.007, 0.005] -0.007[-0.01, -0.001] -0.002[-0.006, 0.001] 0.005[-0.000, 0.01] Continent Continent (North America v Europe) 0.15[0.10, 0.20] -0.03[-0.09, 0.04] -0.04[-0.10, 0.01] 0.06[0.03, 0.09] 0.04[-0.01, 0.10] Continent (North America v Australia) 0.06[0.02, 0.09] 0.002[-0.04, 0.04] -0.04[-0.08, -0.008] -0.13[-0.17, -0.10] 0.11[0.08, 0.14] Country Country (United States v Germany) 0.20[0.12, 0.27] 0.005[-0.08, 0.09] -0.06[-0.15, 0.04] 0.10[0.03, 0.17] 0.02[-0.04, 0.09] Country (United States v Sweden) 0.08[0.02, 0.15] -0.22[-0.33, -0.11] -0.21[-0.30, -0.11] 0.03[-0.03, 0.09] 0.23[0.09, 0.36] Country (United States v The Netherlands) -0.02[-0.07, 0.03] Country (United States v Australia) 0.06[0.02, 0.09] 0.001[-0.04, 0.04] -0.05[-0.08, -0.01] -0.13[-0.17, -0.10] 0.11[0.08, 0.14] Personality Scale Scale (NEO-FFI v DPQ) 0.11[0.06, 0.17] Scale (NEO-FFI v Eysenck) 0.02[-0.15, 0.20] -0.23[-0.36, -0.09] -0.15[-0.28, -0.02] 0.21[0.14, 0.27] -0.06[-0.25, 0.13] Scale (NEO-FFI v MIDI) -0.06[-0.22, 0.11] -0.005[-0.09, 0.08] 0.06[-0.04, 0.15] 0.14[0.10, 0.18] -0.28[-0.42, -0.14] Scale (NEO-FFI v BFI-S) 0.07[-0.11, 0.25] 0.14[0.05, 0.22] -0.32[-0.47, -0.16] Scale (NEO-FFI v IPIP NEO) 0.10[0.01, 0.19] Scale (NEO-FFI v TDA-40) -0.003[-0.17, 0.16] -0.004[-0.09, 0.08] 0.01[-0.08, 0.10] 0.02[-0.02, 0.07] -0.17[-0.31, -0.03] Baseline Age Study Baseline Age -0.004[-0.005, -0.003] -0.001[-0.002, 0.001] -0.000[-0.002, 0.001] -0.000[-0.001, 0.001] -0.004[-0.005, -0.003] Baseline Year Study Baseline Year -0.003[-0.006, 0.001] 0.007[0.002, 0.01] 0.007[0.003, 0.01] 0.002[0.000, 0.005] -0.010[-0.01, -0.004] Prediction Interval Prediction Interval 0.002[-0.005, 0.009] -0.03[-0.04, -0.03] -0.03[-0.03, -0.02] -0.006[-0.01, -0.000] 0.02[0.01, 0.03] ## bayesian (ipd1a_fx_tab2 %&gt;% filter(type == &quot;Bayesian&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] (#tab:ipd1a key term tab)1A Pooled Analysis of Individual Participant Data: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality -0.07[-0.08, -0.05] -0.07[-0.09, -0.06] -0.01[-0.03, 0.006] -0.05[-0.33, 0.29] 0.11[0.09, 0.12] Age Age 0.000[-0.001, 0.002] -0.000[-0.002, 0.001] -0.001[-0.002, 0.001] -0.009[-0.09, 0.12] -0.003[-0.004, -0.002] Gender Gender (Male v Female) 0.05[0.02, 0.08] 0.04[0.005, 0.07] 0.03[-0.005, 0.06] -0.09[-0.91, 0.44] -0.02[-0.05, 0.01] Education Education (Years) 0.005[0.000, 0.009] -0.003[-0.008, 0.001] -0.006[-0.01, -0.002] 0.10[-0.11, 0.39] 0.001[-0.004, 0.006] Continent Continent (North America v Europe) 0.26[0.21, 0.31] 0.08[0.02, 0.14] 0.11[0.05, 0.17] -0.009[-0.58, 0.26] 0.08[0.01, 0.14] Continent (North America v Australia) 0.18[0.15, 0.21] 0.08[0.05, 0.12] 0.09[0.06, 0.13] -0.13[-0.58, 0.36] 0.13[0.10, 0.16] Country Country (United States v Germany) 0.32[0.24, 0.39] 0.09[0.001, 0.18] 0.08[-0.01, 0.18] 0.25[-0.81, 1.61] 0.05[-0.02, 0.12] Country (United States v Sweden) 0.19[0.12, 0.26] -0.14[-0.25, -0.03] -0.07[-0.17, 0.04] -0.23[-1.40, 0.61] 0.24[0.09, 0.39] Country (United States v The Netherlands) 1.00[0.37, 1.69] Country (United States v Australia) 0.18[0.15, 0.21] 0.09[0.05, 0.12] 0.09[0.06, 0.13] -0.01[-0.56, 0.59] 0.13[0.10, 0.16] Personality Scale Scale (NEO-FFI v DPQ) -0.11[-1.65, 0.76] Scale (NEO-FFI v Eysenck) -0.006[-0.08, 0.07] -0.24[-0.36, -0.10] -0.28[-0.39, -0.18] 0.67[0.34, 0.91] 0.25[0.09, 0.40] Scale (NEO-FFI v MIDI) -0.07[-0.11, -0.02] -0.007[-0.08, 0.07] -0.05[-0.11, 0.007] 0.16[-0.26, 0.54] 0.04[-0.03, 0.11] Scale (NEO-FFI v BFI-S) 0.05[-0.04, 0.14] -0.01[-0.13, 0.10] -0.14[-0.24, -0.03] 0.20[-1.47, 1.79] -0.007[-0.10, 0.09] Scale (NEO-FFI v IPIP NEO) 0.04[-0.06, 0.14] 0.01[-0.10, 0.12] -0.18[-0.28, -0.09] -0.02[-1.12, 1.58] 0.12[0.02, 0.23] Scale (NEO-FFI v TDA-40) -0.02[-0.07, 0.03] -0.01[-0.09, 0.07] -0.11[-0.17, -0.05] -0.06[-0.81, 0.63] 0.13[0.06, 0.21] Baseline Age Study Baseline Age -0.006[-0.007, -0.005] -0.003[-0.004, -0.002] -0.005[-0.007, -0.004] -0.06[-0.19, 0.000] -0.005[-0.006, -0.004] Baseline Year Study Baseline Year -0.005[-0.008, -0.002] 0.01[0.007, 0.02] -0.003[-0.007, 0.001] -0.07[-0.16, 0.009] 0.001[-0.004, 0.006] Prediction Interval Prediction Interval 0.009[0.003, 0.02] -0.03[-0.03, -0.02] -0.01[-0.02, -0.006] -0.05[-0.29, 0.92] 0.003[-0.005, 0.01] # save(ipd1a_fx_tab, ipd1a_fx_tab2, ipd1a_res, file = sprintf(&quot;%s/manuscript/results/ipd1a_fx_tab.RData&quot;, local_path)) 3.2.1.5.1.2 Study-Specific Effects This header is here to simply emphasize that this method does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.1.5.1.3 Heterogeneity Estimates This header is here to simply emphasize that this method does not provide heterogeneity estimates because it does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.1.5.1.4 All Model Terms ipd1a_mod_tab &lt;- nested_ipd1a_reg %&gt;% unnest(fx) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)),#ifelse(Moderator != &quot;None&quot; &amp; Covariate == &quot;none&quot;, Moderator, Covariate), ) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd1a_mod_tab_fun &lt;- function(d, type, out, moder, cov){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- if(md == &quot;none&quot;) &quot;1A Pooled Analysis of Individual Participant Data: All Model Estimates of Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;1A Pooled Analysis of Individual Participant Data: All Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) # kable the table tab &lt;- d %&gt;% arrange(term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/1a_ipd_reg/%s/tables/all terms/%s-%s-%s.html&quot; , local_path, type, o, md, cv)) return(tab) # return the html table } ipd1a_mod_tab &lt;- ipd1a_mod_tab %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ipd1a_mod_tab_fun)) 3.2.1.5.2 Figures 3.2.1.5.2.1 Overall Forest ipd1a_fx_plot_fun &lt;- function(df, mod, type, cov){ m &lt;- mapvalues(mod, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) dl &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-dl-(dl/2.5), 0+dl+(dl/2.5)) brk &lt;- if(dl &gt; .01) round(c(0-dl-(dl/5), 0, 0+dl+(dl/5)),2) else round(c(0-dl-(dl/5), 0, 0+dl+(dl/5)),3) # lim_high &lt;- lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;)#str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, m)} titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cv, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cv, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- df %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high)) %&gt;% ggplot(aes(x = Outcome, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(2, 1.5)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;blue&quot;, &quot;black&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .5, linetype = &quot;dashed&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL , y = &quot;Estimate (POMP)&quot; , title = titl , subtitle = &quot;Method 1A: Pooled Simple Linear Regression&quot; , term = &quot;Term&quot; ) + guides(color = &quot;none&quot;, size = &quot;none&quot;) + facet_grid(~Trait, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5), plot.subtitle = element_text(hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(df$Outcome)); ht2 &lt;- length(unique(df$term)) wdt &lt;- length(unique(df$Trait)) ggsave(file = sprintf(&quot;%s/results/1a_ipd_reg/%s/figures/overall forest/%s_%s_fixed.png&quot;, local_path, type, mod, cov), width = wdt*2, height = ht + ht2) # save(p, file = sprintf(&quot;%s/results/ipd1a_reg/%s/figures/overall forest/rdata/%s_fixed.RData&quot;, type, local_path, mod)) rm(p) gc() return(T) } # x1 = 1, x2 = 1, y = 2 # x1 = 1, x2 = 2, y = 3 ipd1a_fp &lt;- nested_ipd1a_reg %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), sig = factor(sig, levels = c(&quot;sig&quot;,&quot;ns&quot;)), Trait = factor(Trait, levels = traits$short_name), Outcome = factor(Outcome, levels = outcomes$short_name, labels = str_wrap(outcomes$long_name, 15)), Outcome = forcats::fct_rev(Outcome)) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(pmap(list(data, Moderator, type, Covariate), ipd1a_fx_plot_fun)) 3.2.1.5.2.2 Study-Specific Forest Plots This header is here to simply emphasize that this method does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.1.5.2.3 Overall Simple Effects Plots loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/1a_ipd_reg/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd1a_simp &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/1a_ipd_reg/%s/predicted&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), pred = map2(file, type, ~loadRData(.x, .y, &quot;pred.fx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) nested_ipd1a_simp ## # A tibble: 360 × 6 ## type Outcome Trait Moderator Covariate pred ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 Frequentist crystallized A age all &lt;tibble [63 × 8]&gt; ## 2 Frequentist crystallized A age none &lt;df [63 × 5]&gt; ## 3 Frequentist crystallized A baseAge age &lt;tibble [63 × 6]&gt; ## 4 Frequentist crystallized A baseAge all &lt;tibble [63 × 9]&gt; ## 5 Frequentist crystallized A baseAge education &lt;tibble [63 × 6]&gt; ## 6 Frequentist crystallized A baseAge gender &lt;tibble [63 × 6]&gt; ## 7 Frequentist crystallized A baseAge none &lt;df [63 × 5]&gt; ## 8 Frequentist crystallized A baseYear age &lt;tibble [63 × 6]&gt; ## 9 Frequentist crystallized A baseYear all &lt;tibble [63 × 9]&gt; ## 10 Frequentist crystallized A baseYear education &lt;tibble [63 × 6]&gt; ## # ℹ 350 more rows 3.2.1.5.2.4 Study-Specific Simple Effects Plots This header is here to simply emphasize that this method does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. simp_eff_fun &lt;- function(df, outcome, mod, type, cov){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) lim &lt;- c(mini, maxi) brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; df &lt;- df %&gt;% unclass %&gt;% data.frame df$mod_value &lt;- df[,mod] df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(df$mod_value) == &quot;factor&quot;){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} else{df &lt;- df %&gt;% group_by(Trait) %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() } lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;, &quot;dotdash&quot;, &quot;longdash&quot;, &quot;twodash&quot;)[1:length(unique(df$mod_fac))] df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), lower = ifelse(lower &lt; 4, 4, lower), upper = ifelse(upper &gt; 10, 10, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = mod_fac)) + scale_y_continuous(limits = c(4,10) , breaks = c(4, 6, 8, 10) , labels = c(4, 6, 8, 10)) + scale_linetype_manual(values = lt) + geom_ribbon(aes(ymin = lower , ymax = upper , fill = mod_fac) , alpha = .25) + geom_line(aes(linetype = mod_fac)) + labs(x = &quot;Personality (POMP)&quot; , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = m , fill = m , subtitle = &quot;Method 1A: Pooled Simple Linear Regression&quot;) + facet_wrap(~Trait, nrow = 3) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/1a_ipd_reg/%s/figures/overall simple effects/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov), width = 6, height = 6) } ipd1a_se_plot &lt;- nested_ipd1a_simp %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred)), plot = pmap(list(data, Outcome, Moderator, type, Covariate), simp_eff_fun)) ## [1] &quot;crystallized age&quot; ## [1] &quot;crystallized age&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized education&quot; ## [1] &quot;crystallized education&quot; ## [1] &quot;crystallized gender&quot; ## [1] &quot;crystallized gender&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized age&quot; ## [1] &quot;crystallized age&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseAge&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized baseYear&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized continent&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized country&quot; ## [1] &quot;crystallized education&quot; ## [1] &quot;crystallized education&quot; ## [1] &quot;crystallized gender&quot; ## [1] &quot;crystallized gender&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized predInt&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; ## [1] &quot;crystallized scale&quot; # Extraversion continent load(&quot;~/Documents/projects/data synthesis/crystallized/results/1a_ipd_reg/Frequentist/models/crystallized_E_continent_all.RData&quot;) coef(m) ## (Intercept) p_value age genderFemale ## 5.549134520 -0.046145461 0.004171313 0.141786850 ## SRhealth education continentAustralia continentEurope ## 0.019022604 0.308632325 -0.485469914 1.179707965 ## p_value:continentAustralia p_value:continentEurope ## 0.057715148 0.150113337 cntrm &lt;- c( &quot;p_value = 0&quot; # North America , &quot;p_value + p_value:continentAustralia = 0&quot; # Australia , &quot;p_value + p_value:continentEurope = 0&quot; # Europe ); names(cntrm) &lt;- c(&quot;North America&quot;, &quot;Australia&quot;, &quot;Europe&quot;) (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = mapvalues(cntr, str_remove(cntrm, &quot; = 0&quot;), names(cntrm))) %&gt;% select(-cntr) %&gt;% mutate(est = sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr)) ## Estimate lwr upr term est ## 1 -0.04614546 -0.06939046 -0.02290047 North America b = -0.05, 95% CI [-0.07, -0.02] ## 2 0.01156969 -0.01240456 0.03554393 Australia b = 0.01, 95% CI [-0.01, 0.04] ## 3 0.10396788 0.05998319 0.14795256 Europe b = 0.10, 95% CI [0.06, 0.15] # Neuroticism continent load(&quot;~/Documents/projects/data synthesis/crystallized/results/1a_ipd_reg/Frequentist/models/crystallized_N_continent_all.RData&quot;) coef(m) ## (Intercept) p_value age genderFemale ## 5.9846147217 -0.0019269944 -0.0003912502 -0.1545757888 ## education continentAustralia continentEurope p_value:continentAustralia ## 0.3065055260 -0.1803310763 1.1872866354 -0.1332956492 ## p_value:continentEurope ## 0.0611509497 cntrm &lt;- c( &quot;p_value = 0&quot; # North America , &quot;p_value + p_value:continentAustralia = 0&quot; # Australia , &quot;p_value + p_value:continentEurope = 0&quot; # Europe ); names(cntrm) &lt;- c(&quot;North America&quot;, &quot;Australia&quot;, &quot;Europe&quot;) (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = mapvalues(cntr, str_remove(cntrm, &quot; = 0&quot;), names(cntrm))) %&gt;% select(-cntr) %&gt;% mutate(est = sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr)) ## Estimate lwr upr term est ## 1 -0.001926994 -0.02067998 0.01682599 North America b = -0.00, 95% CI [-0.02, 0.02] ## 2 -0.135222644 -0.16119743 -0.10924786 Australia b = -0.14, 95% CI [-0.16, -0.11] ## 3 0.059223955 0.03262787 0.08582004 Europe b = 0.06, 95% CI [0.03, 0.09] # Neuroticism continent load(&quot;~/Documents/projects/data synthesis/crystallized/results/1a_ipd_reg/Frequentist/models/crystallized_O_scale_all.RData&quot;) coef(m) ## (Intercept) p_value age genderFemale SRhealth ## 3.339901072 0.368662547 0.006242933 0.160535249 0.037314257 ## education scaleBFI-S scaleEysenck scaleMIDI scaleTDA-40 ## 0.271069104 4.327067799 2.644895382 1.206799564 0.684281664 ## p_value:scaleBFI-S p_value:scaleEysenck p_value:scaleMIDI p_value:scaleTDA-40 ## -0.316552453 -0.059001287 -0.281742471 -0.172583588 cntrm &lt;- rbind( c(0,1,rep(0,12)) # NEO-FFI , c(0,1,rep(0,8),1,rep(0,3)) # BFI-S , c(0,1,rep(0,9),1,rep(0,2)) # Eysenck , c(0,1,rep(0,10),1,0) # MIDI , c(0,1,rep(0,11),1) # TDA-40 ); rownames(cntrm) &lt;- c(&quot;NEO-FFI&quot;, &quot;BFI-S&quot;, &quot;Eysenck&quot;, &quot;MIDI&quot;, &quot;TDA-40&quot;) (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = rownames(cntrm)) %&gt;% select(-cntr) %&gt;% mutate(est = sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr)) ## Estimate lwr upr term est ## 1 0.36866255 0.22956598 0.5077591 NEO-FFI b = 0.37, 95% CI [0.23, 0.51] ## 2 0.05211009 -0.01683090 0.1210511 BFI-S b = 0.05, 95% CI [-0.02, 0.12] ## 3 0.30966126 0.17573543 0.4435871 Eysenck b = 0.31, 95% CI [0.18, 0.44] ## 4 0.08692008 0.06461337 0.1092268 MIDI b = 0.09, 95% CI [0.06, 0.11] ## 5 0.19607896 0.17193054 0.2202274 TDA-40 b = 0.20, 95% CI [0.17, 0.22] 3.2.1.6 Sample Results Section We examined estimates of overall prospective associations between Big Five personality characteristics and crystallized abilities as well as participant and sample-level moderators of those associations using fully pooled, one-stage regression models with individual participant data in 11 studies. Table S1 presents the fully adjusted (age, gender, education) pooled estimates of the key terms from all unmoderated estimates as well as participant- and sample-level moderators. Across the 20 (5 unmoderated, 15 participant-level moderators) key participant-level terms, 10 (50%) were significant. For unmoderated personality-cognition associations, extraversion (-), agreeableness (-), conscientiousness (+), neuroticism (-), and openness (+) were significantly associated with later crystallized abilities. Forest plots of the overall point estimates are available in the online materials and web app, as are tables with all model terms (e.g., intercepts, covariate-cognitive ability associations). (#tab:ipd1a key term tab)1A Pooled Analysis of Individual Participant Data: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality -0.03[-0.05, -0.02] -0.05[-0.06, -0.03] 0.03[0.02, 0.05] -0.03[-0.04, -0.01] 0.13[0.11, 0.14] Age Age -0.000[-0.002, 0.001] -0.001[-0.003, 0.000] 0.001[-0.001, 0.002] 0.002[0.001, 0.003] -0.003[-0.005, -0.002] Gender Gender (Male v Female) 0.05[0.02, 0.08] 0.03[-0.01, 0.06] 0.01[-0.02, 0.05] -0.01[-0.04, 0.01] -0.02[-0.06, 0.009] Education Education (Years) 0.007[0.002, 0.01] -0.001[-0.007, 0.005] -0.007[-0.01, -0.001] -0.002[-0.006, 0.001] 0.005[-0.000, 0.01] Continent Continent (North America v Europe) 0.15[0.10, 0.20] -0.03[-0.09, 0.04] -0.04[-0.10, 0.01] 0.06[0.03, 0.09] 0.04[-0.01, 0.10] Continent (North America v Australia) 0.06[0.02, 0.09] 0.002[-0.04, 0.04] -0.04[-0.08, -0.008] -0.13[-0.17, -0.10] 0.11[0.08, 0.14] Country Country (United States v Germany) 0.20[0.12, 0.27] 0.005[-0.08, 0.09] -0.06[-0.15, 0.04] 0.10[0.03, 0.17] 0.02[-0.04, 0.09] Country (United States v Sweden) 0.08[0.02, 0.15] -0.22[-0.33, -0.11] -0.21[-0.30, -0.11] 0.03[-0.03, 0.09] 0.23[0.09, 0.36] Country (United States v The Netherlands) -0.02[-0.07, 0.03] Country (United States v Australia) 0.06[0.02, 0.09] 0.001[-0.04, 0.04] -0.05[-0.08, -0.01] -0.13[-0.17, -0.10] 0.11[0.08, 0.14] Personality Scale Scale (NEO-FFI v DPQ) 0.11[0.06, 0.17] Scale (NEO-FFI v Eysenck) 0.02[-0.15, 0.20] -0.23[-0.36, -0.09] -0.15[-0.28, -0.02] 0.21[0.14, 0.27] -0.06[-0.25, 0.13] Scale (NEO-FFI v MIDI) -0.06[-0.22, 0.11] -0.005[-0.09, 0.08] 0.06[-0.04, 0.15] 0.14[0.10, 0.18] -0.28[-0.42, -0.14] Scale (NEO-FFI v BFI-S) 0.07[-0.11, 0.25] 0.14[0.05, 0.22] -0.32[-0.47, -0.16] Scale (NEO-FFI v IPIP NEO) 0.10[0.01, 0.19] Scale (NEO-FFI v TDA-40) -0.003[-0.17, 0.16] -0.004[-0.09, 0.08] 0.01[-0.08, 0.10] 0.02[-0.02, 0.07] -0.17[-0.31, -0.03] Baseline Age Study Baseline Age -0.004[-0.005, -0.003] -0.001[-0.002, 0.001] -0.000[-0.002, 0.001] -0.000[-0.001, 0.001] -0.004[-0.005, -0.003] Baseline Year Study Baseline Year -0.003[-0.006, 0.001] 0.007[0.002, 0.01] 0.007[0.003, 0.01] 0.002[0.000, 0.005] -0.010[-0.01, -0.004] Prediction Interval Prediction Interval 0.002[-0.005, 0.009] -0.03[-0.04, -0.03] -0.03[-0.03, -0.02] -0.006[-0.01, -0.000] 0.02[0.01, 0.03] In addition, gender (b = 0.05, 95% CI [0.02, 0.08]) moderated the prospective association between extraversion and crystallized abilities. To better understand how gender moderates the relationships, Figure S1 displays the fully adjusted (age, gender, education) predicted crystallized abilities levels at different levels of the Big Five for males and females. As is clear in the first column (Method 1A) and first row (extraversion) of the figure, the overall prospective association between personality-crystallized ability association was negative for males (b = -0.06, 95% CI [-0.08, -0.04]) and null for females (b = -0.01, 95% CI [-0.03, 0.006]). Moreover, education moderated the association between extraversion (b = 0.007, 95% CI [0.002, 0.01]) and conscientiousness (b = -0.007, 95% [-0.01, -0.001]) and later crystallized abilities. For extraversion, this indicated that less educated individuals who were higher in extraversion tended to have lower crystallized ability scores at later time points than those with more education and high in extraversion. For conscientiousness, less educated individuals who were lower in conscientiousness had worse crystallized ability at later time points than more educated individuals who were lower in conscientiousness. Finally, age moderated the relationship between both neuroticism (b = 0.002, 95% CI [0.001, 0.003]) and openness (b = -0.003, 95% CI [-0.005, -0.002]) and crystallized abilities. Older individuals who were higher in neuroticism had higher crystallized ability scores than younger individuals. Older individuals who were lower in openness had higher crystallized ability scores than younger individuals who were low in openness. All other simple effects of participant-level moderators are available in the online materials and in the web app. Figure 3.1: Figure S1. Simple effects of the prospective association between Big Five personality characteristics (rows) and crystallized abilities across gender (male, female) using all methods of data synthesis (columns). The x-axis captures personality in percentage of maximum possible (POMP) units, the y-axis captures crystallized abilities in POMP, and different panels represent each of the Big Five characteristics. Different lines indicate the predicted levels of cognitive ability for males (dotted line) and females (solid line). Additionally, we examined sample-level moderators. These moderators are those that are the same across the individuals in the sample and speak more to similarities and differences in the samples as a whole. Specifically, we examined how the continent and country of origin of each sample, the personality scale used, the average baseline age of the sample, the average baseline year of assessment of personality, and the average interval between personality and cognitive assessment may predict the estimated personality-cognitive ability association. Estimates of the sample-level moderators of Big Five personality characteristic-crystallized / knowledge domain cognitive ability associations across methods can be seen in Table S1. Of these 55 tested associations, 36 (65.45%) were significant. For example, the associations between both extraversion and neuroticism and crystallized / knowledge domain associations were more positive for European and Australian samples than for North American samples. Although North American samples (b = -0.05, 95% CI [-0.07, -0.02]) demonstrated negative associations between extraversion and cognitive ability, European samples (b = 0.06, 95% CI [0.06, 0.15]) demonstrated positive associations, and Australian samples (b = 0.01, 95% CI [-0.01, 0.04]) null associations. For neuroticism, North American samples (b = -0.01, 95% CI [-0.02, 0.02]) demonstrated null associations with cognitive ability, while European (b = 0.06, 95% CI [0.03, 0.09]) samples demonstrated a positive association and Australian samples (b = -0.14, 95% CI [-0.16, -0.11]) demonstrated a negative association. For personality scales, NEO-FFI measures of openness (b = 0.37, 95% CI [0.23, 0.51]) tended to be differently associated with crystallized / knowledge domain cognitive ability than other personality scales, including the MIDI (HRS, b = 0.09, 95% CI [0.06, 0.11]), the BFI-S (GSOEP, b = 0.05, 95% CI [-0.02, 0.12]), and the TDA-40 (HILDA, b = 0.20, 95% CI [0.17, 0.22]). rm(list = ls()[grepl(&quot;ipd1a&quot;, ls())]) 3.2.2 Part 1B: Pooled Linear Regression with Cluster Robust Standard Errors 3.2.2.1 Analytic Plan In the present study, we aimed to examine associations between personality traits and crystallized cognitive abilities using fully pooled, single-stage regression models with cluster robust standard errors (Gaure, 2013; Pustejovsky &amp; Tipton, 2018) and individual participant data. Correcting for dependencies without explicitly modeling cross-sample heterogeneity is sometimes called nuisance clustering (Fitzmaurice &amp; Laird, 1995). Below, we detail each stage of the analysis. 3.2.2.1.1 Statistical Modeling A single regression model tests the relationship between personality and crystallized cognitive ability across all samples. Using the R programming language, we created two functions to (1) set up and run the model and extract model coefficients and (2) extract simple-effects predictions for moderator models (i.e. predicted values across levels of the moderator values). The basic form of the model is as follows: \\(Y_{ij}=b_0+b_1\\ast predictor_{ij}+\\epsilon_{ij}\\) \\(\\varepsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\), with sample as a cluster, where \\(b_1\\) represents the overall effect of personality predicting the outcome. For moderator models, we add two additional terms, \\(b_2\\), which captures the prospective association between a moderator and cognitive ability, adjusting for personality, and b_3, which captures how cognitive ability varies as a function of both personality and the moderator (e.g., does the association differ for males and females). Models will be tested using the lm_robust() function from the estimatr package in R, with cluster=study and se_type=\"CR0\". The tidy() function from the broom package was used to extract model coefficients and confidence intervals (CI). Inferences will be based on the 95% confidence intervals. Simple-effects predictions were calculated by providing the full range of personality (0-10) and average levels of the covariates from the data used to estimate the model as the “newdata” argument in the predict() function. 3.2.2.2 Model Function The first thing we need is a function that will bring in the data, create a formula in the model based on input on the type (Frequentist or Bayesian), moderators (none, age, gender, and education), and combinations of covariates (single or fully adjusted based on age, gender, and education). Then we run the model, which in this case uses the lm_robust() function from the estimatr pacakge, extract its fixed effect estimates, and save both for later. By saving the results, it will make it easier and faster for us to extract the necessary model results later while still retaining all information from the original model. ipd1b_mod_fun &lt;- function(trait, outcome, type, mod, cov){ ## load the data load(sprintf(&quot;%s/data/one_stage/%s_%s.RData&quot;, local_path, trait, outcome)) ## model formula if (cov == &quot;all&quot;) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if (!cov %in% c(&quot;all&quot;, &quot;none&quot;)) cv &lt;- cov rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;none&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;){rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;))} rhs &lt;- paste(rhs, collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## compiled Bayesian model to speed up processing and avoid crashing if(type == &quot;Bayesian&quot;) load(sprintf(&quot;%s/results/1a_ipd_reg/bayes_sample_mod.RData&quot;, local_path)) ## run the models &amp; save m &lt;- if(type == &quot;Frequentist&quot;){lm_robust(formula(f), data = d, clusters = study, se_type = &quot;CR0&quot;)} else {update(m, formula = f, newdata = d)} save(m, file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/models/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) save(fx, file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/summary/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) ## get simple effects for moderator tests if(mod != &quot;none&quot;){ pred.fx &lt;- ipd1b_simpeff_fun(m, mod, type, d) save(pred.fx, file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/predicted/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;rhs&quot;, &quot;m&quot;, &quot;fx&quot;)) gc() } 3.2.2.3 Simple Effects Function ipd1b_simpeff_fun &lt;- function(m, moder, type, d){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else d %&gt;% select(o_value, one_of(rownames(attr(m$terms, &quot;factors&quot;)))) %&gt;% filter(complete.cases(.)) %&gt;% data.frame() d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd), na.rm = T) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { unique(fct_lev[,moder][[1]]) } mod_frame &lt;- crossing( p_value = seq(0,10,.5) , modvalue = md_levs ) %&gt;% setNames(c(&quot;p_value&quot;, moder)) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)[1])) } } pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m, newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, predict(m, newdata = mod_frame, interval = &quot;confidence&quot;)$fit %&gt;% data.frame ) %&gt;% select(one_of(rownames(attr(m$terms, &quot;factors&quot;))), pred = fit, lower = lwr, upper = upr) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 3.2.2.4 Run Models and Summaries The code below generates all possible preregistrered combinations of traits, outcomes, types, moderators, and covariates. Then these combinations are fed serially to the model function written previously, which will run and save the results. plan(multisession(workers = 12L)) nested_ipd1b_fixef &lt;- # moderator combinations crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;) , Moderator = c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) , Covariate = c(&quot;none&quot;, &quot;all&quot;) ) %&gt;% full_join( # unmoderated combinations crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;) , Moderator = c(&quot;none&quot;) , Covariate = c(&quot;none&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;all&quot;) ) ) %&gt;% # filter(Trait == &quot;N&quot;) %&gt;% mutate(run = future_pmap( list(Trait, Outcome, type, Moderator, Covariate) , ipd1b_mod_fun , .progress = T , .options = furrr_options( globals = c(&quot;res_path&quot;, &quot;local_path&quot;, &quot;ipd1b_simpeff_fun&quot;, &quot;traits&quot;, &quot;studies&quot;, &quot;outcomes&quot;, &quot;covars&quot;, &quot;moders&quot;) , packages = c(&quot;plyr&quot;, &quot;tidyverse&quot;, &quot;broom.mixed&quot;, &quot;broom&quot;, &quot;estimatr&quot;) ) )) closeAllConnections() # nested_ipd1b_fixef %&gt;% # # select(-done) %&gt;% # write.table(. # , file = sprintf(&quot;%s/scripts/cluster/args/frequentist/ipd1b_frequentist.txt&quot;, local_path) # , row.names = F) 3.2.2.5 Compile Results Once all the models are run, we are ready to compile all their results. By saving the fixed effects results previously, we are able to simply load those results and ignore the models. However, because we also saved the models, we can also recall and extract information from them if and when needed. loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/1b_ipd_fixef/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd1b_fixef &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/1b_ipd_fixef/%s/summary&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), fx = map2(file, type, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;))) %&gt;% select(-file) 3.2.2.5.1 Tables Next, we want to format the study results in APA table format. In this case, we are interested in the fixed effects of personality predicting cognitive ability when there were no moderators, and the personality x moderator interaction when there was a moderator. 3.2.2.5.1.1 Fixed Effects ## format results ipd1b_fixef_tab &lt;- nested_ipd1b_fixef %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = ifelse(Moderator != &quot;None&quot; &amp; Covariate == &quot;None&quot;, Moderator, Covariate), Covariate = factor(Covariate, moders$short_name, str_wrap(moders$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, c(&quot;scaleBFIMS&quot;, &quot;scaleIPIPNEO&quot;, &quot;scaleTDAM40&quot;, &quot;countryTheNetherlands&quot;) , c(&quot;scaleBFI-S&quot;, &quot;scaleIPIP NEO&quot;, &quot;scaleTDA-40&quot;, &quot;countryThe Netherlands&quot;)), term2 = factor(term, c(moders$short_term, stdyModers$short_term), c(moders$long_term, stdyModers$long_term))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .001, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% select(-estimate, -conf.low, -conf.high, -sig, -term) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd1b_fixef_tab ## # A tibble: 98 × 10 ## type Outcome Moderator Covariate term2 E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bayesian Crystallized Ability None None Personality &lt;strong&gt;-0.05&lt;br&gt;[-… &lt;str… &lt;str… &lt;str… &lt;str… ## 2 Bayesian Crystallized Ability None Age Personality &lt;strong&gt;-0.05&lt;br&gt;[-… &lt;str… &lt;str… &lt;str… &lt;str… ## 3 Bayesian Crystallized Ability None Gender Personality &lt;strong&gt;-0.06&lt;br&gt;[-… &lt;str… &lt;str… &lt;str… &lt;str… ## 4 Bayesian Crystallized Ability None Education Personality &lt;strong&gt;-0.06&lt;br&gt;[-… -0.0… &lt;str… &lt;str… &lt;str… ## 5 Bayesian Crystallized Ability None Fully Adjusted Personality &lt;strong&gt;-0.08&lt;br&gt;[-… &lt;str… 0.01… &lt;str… &lt;str… ## 6 Bayesian Crystallized Ability Age None Age &lt;strong&gt;-0.00&lt;br&gt;[-… &lt;str… -0.0… &lt;str… &lt;str… ## 7 Bayesian Crystallized Ability Age Fully Adjusted Age &lt;strong&gt;-0.00&lt;br&gt;[-… &lt;str… -0.0… &lt;str… &lt;str… ## 8 Bayesian Crystallized Ability Gender None Gender (Male v Female) &lt;strong&gt;0.09&lt;br&gt;[0.… 0.03… -0.0… -0.0… -0.0… ## 9 Bayesian Crystallized Ability Gender Fully Adjusted Gender (Male v Female) &lt;strong&gt;0.09&lt;br&gt;[0.… 0.03… 0.00… -0.0… -0.0… ## 10 Bayesian Crystallized Ability Education None Education (Years) -0.001&lt;br&gt;[-0.01, 0… &lt;str… &lt;str… &lt;str… -0.0… ## # ℹ 88 more rows ipd1b_res &lt;- nested_ipd1b_fixef %&gt;% unnest(fx) %&gt;% # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;\\\\textit{b} = %s, 95\\\\%% CI [%s, %s]&quot;, estimate, conf.low, conf.high)) Now that we’ve formatted the values, we can group by moderators and save results as separate tables. Even though additional information could be included given that we have one outcome, we’ll stick with this split because it will make it easier for those using this tutorial who multiple traits, outcomes, covariates, and moderators. ## table function ipd1b_tab_fun &lt;- function(d, type, moder){ # long outcome name md &lt;- mapvalues(moder, c(&quot;None&quot;, moders$long_name, stdyModers$long_name), c(&quot;none&quot;, moders$short_name, stdyModers$short_name), warn_missing = F) d &lt;- d %&gt;% arrange(Outcome, Covariate, term2) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term2)) &gt; 1) c(2, rep(1,5)) else rep(1,6) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot; &quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- if(length(unique(d$term2)) == 1) c(&quot; &quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- if(length(unique(d$term2)) == 1) c(&quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term2)) == 1) { d &lt;- d %&gt;% select(-term2); dubs &lt;- F } cap &lt;- if(md == &quot;none&quot;) &quot;1B Pooled Analysis of Individual Participant Data: Cluster Robust Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;1B Pooled Analysis of Individual Participant Data: Cluster Robust Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% collapse_rows(1, &quot;top&quot;) %&gt;% add_header_above(cs, escape = F) for (i in nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/tables/overall/%s.html&quot; , local_path, type, md)) return(tab) } ipd1b_fx_tab &lt;- ipd1b_fixef_tab %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd1b_tab_fun)) ipd1b_fx_tab ## # A tibble: 14 × 4 ## type Moderator data tab ## &lt;chr&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 Bayesian None &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 2 Bayesian Age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 3 Bayesian Gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 4 Bayesian Education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 5 Frequentist None &lt;tibble [6 × 8]&gt; &lt;kablExtr [1]&gt; ## 6 Frequentist Age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 7 Frequentist Gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 8 Frequentist Education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 9 Frequentist Continent &lt;tibble [10 × 8]&gt; &lt;kablExtr [1]&gt; ## 10 Frequentist Country &lt;tibble [20 × 8]&gt; &lt;kablExtr [1]&gt; ## 11 Frequentist Personality Scale &lt;tibble [30 × 8]&gt; &lt;kablExtr [1]&gt; ## 12 Frequentist Baseline Age &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 13 Frequentist Baseline Year &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 14 Frequentist Prediction Interval &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; # save(ipd1b_fixef_tab, ipd1b_res, file = sprintf(&quot;%s/manuscript/results/ipd1b_fx_tab.RData&quot;, local_path)) ## Frequentist (ipd1b_fx_tab %&gt;% filter(type == &quot;Frequentist&quot; &amp; Moderator == &quot;None&quot;))$tab[[1]] Table 3.1: 1B Pooled Analysis of Individual Participant Data: Cluster Robust Fixed Effect Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability None -0.08[-0.27, 0.10] -0.14[-0.36, 0.08] 0.01[-0.17, 0.18] -0.00[-0.15, 0.14] 0.20[0.06, 0.34] Age -0.09[-0.28, 0.11] -0.14[-0.38, 0.10] 0.01[-0.17, 0.19] 0.00[-0.15, 0.15] 0.19[0.04, 0.34] Gender -0.08[-0.26, 0.11] -0.14[-0.37, 0.10] 0.02[-0.16, 0.19] 0.01[-0.14, 0.16] 0.19[0.06, 0.32] Self-Rated Physical Health 0.01[-0.35, 0.36] Education -0.07[-0.22, 0.08] -0.06[-0.23, 0.10] -0.01[-0.15, 0.13] -0.03[-0.13, 0.08] 0.10[-0.03, 0.24] -0.07[-0.22, 0.08] -0.07[-0.23, 0.08] -0.01[-0.14, 0.12] -0.03[-0.13, 0.08] 0.11[-0.03, 0.25] ## bayesian (ipd1b_fx_tab %&gt;% filter(type == &quot;Bayesian&quot; &amp; Moderator == &quot;None&quot;))$tab[[1]] Table 3.1: 1B Pooled Analysis of Individual Participant Data: Cluster Robust Fixed Effect Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability None -0.05[-0.07, -0.04] -0.03[-0.05, -0.01] 0.04[0.02, 0.06] 0.11[0.10, 0.13] 0.16[0.14, 0.18] -0.05[-0.07, -0.04] -0.03[-0.05, -0.01] 0.04[0.02, 0.06] 0.11[0.10, 0.13] 0.16[0.14, 0.18] Gender -0.06[-0.07, -0.04] -0.03[-0.05, -0.01] 0.04[0.02, 0.06] 0.12[0.10, 0.13] 0.16[0.14, 0.18] Education -0.06[-0.08, -0.05] -0.02[-0.04, 0.000] 0.02[0.00, 0.03] 0.07[0.06, 0.08] 0.08[0.06, 0.10] Fully Adjusted -0.08[-0.10, -0.07] -0.05[-0.07, -0.03] 0.01[-0.01, 0.03] 0.15[0.13, 0.16] 0.14[0.13, 0.16] ipd1b_tab_fun &lt;- function(d, type, cov){ # long outcome name covar &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cv &lt;- if (cov == &quot;None&quot;) &quot;Unadjusted&quot; else cov cap &lt;- sprintf(&quot;1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: Fixed Effect Estimates of %s Personality-Crystallized Domain Associations&quot;, cv) # kable the table tab &lt;- d %&gt;% select(-Moderator) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/tables/key terms/%s.html&quot; , local_path, type, covar)) return(tab) # return the html table } ipd1b_fx_tab2 &lt;- ipd1b_fixef_tab %&gt;% filter(!Moderator %in% stdyModers$long_name) %&gt;% arrange(Moderator, term2) %&gt;% filter(Covariate %in% c(&quot;None&quot;, &quot;Fully Adjusted&quot;)) %&gt;% group_by(Outcome, type, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Covariate), ipd1b_tab_fun)) ## Frequentist, no moderator (ipd1b_fx_tab2 %&gt;% filter(type == &quot;Frequentist&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] Table 3.2: 1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality -0.07[-0.22, 0.08] -0.07[-0.23, 0.08] -0.01[-0.14, 0.12] -0.03[-0.13, 0.08] 0.11[-0.03, 0.25] Age Age 0.000[-0.00, 0.00] -0.000[-0.00, 0.00] -0.001[-0.00, 0.00] 0.00[-0.00, 0.00] -0.00[-0.01, 0.001] Gender Gender (Male v Female) 0.05[0.001, 0.10] 0.04[-0.00, 0.08] 0.03[-0.07, 0.13] -0.01[-0.08, 0.05] -0.02[-0.08, 0.04] Education Education (Years) 0.00[-0.01, 0.02] -0.00[-0.03, 0.02] -0.01[-0.03, 0.02] -0.00[-0.02, 0.01] 0.00[-0.01, 0.01] ## bayesian (ipd1b_fx_tab2 %&gt;% filter(type == &quot;Bayesian&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] Table 3.2: 1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality -0.08[-0.10, -0.07] -0.05[-0.07, -0.03] 0.01[-0.01, 0.03] 0.15[0.13, 0.16] 0.14[0.13, 0.16] Age Age -0.00[-0.00, -0.000] -0.00[-0.00, -0.000] -0.000[-0.00, 0.00] 0.00[0.00, 0.00] -0.00[-0.00, -0.000] Gender Gender (Male v Female) 0.09[0.05, 0.12] 0.03[-0.01, 0.08] 0.000[-0.04, 0.04] -0.02[-0.04, 0.01] -0.03[-0.07, 0.00] Education Education (Years) -0.01[-0.01, -0.000] -0.02[-0.03, -0.01] -0.02[-0.02, -0.01] 0.01[0.01, 0.01] -0.00[-0.01, 0.00] # save(ipd1a_fx_tab, ipd1a_fx_tab2, ipd1a_res, file = sprintf(&quot;%s/manuscript/results/ipd1b_fx_tab.RData&quot;, local_path)) 3.2.2.5.1.2 Study-Specific Effects This header is here to simply emphasize that this method does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.2.5.1.3 Heterogeneity Estimates This header is here to simply emphasize that this method does not provide heterogeneity estimates because it does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.2.5.1.4 All Model Terms ipd1b_mod_tab &lt;- nested_ipd1b_fixef %&gt;% unnest(fx) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd1a_mod_tab_fun &lt;- function(d, type, out, moder, cov){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- if(md == &quot;none&quot;) &quot;1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: All Model Estimates of Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: All Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) # kable the table tab &lt;- d %&gt;% arrange(term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs, escape = F) # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/tables/all terms/%s-%s-%s.html&quot; , local_path, type, o, md, cv)) return(tab) # return the html table } ipd1b_mod_tab &lt;- ipd1b_mod_tab %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ipd1a_mod_tab_fun)) 3.2.2.5.2 Figures 3.2.2.5.2.1 Overall Forest ipd1b_fx_plot_fun &lt;- function(df, mod, type, cov){ m &lt;- mapvalues(mod, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- if(d &gt; .01) round(c(0-d-(d/5), 0, 0+d+(d/5)),2) else round(c(0-d-(d/5), 0, 0+d+(d/5)),3) # lim_high &lt;- lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;)#str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, m)} titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cv, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cv, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- df %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high)) %&gt;% ggplot(aes(x = Outcome, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(1.4, 1.8)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;black&quot;, &quot;blue&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .25, color = &quot;gray50&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL , y = &quot;Estimate (POMP)&quot; , title = titl , subtitle = &quot;Method 1B: Pooled Linear Regression with Cluster-Corrected Standard Errors&quot; ) + guides(color = &quot;none&quot;, size = &quot;none&quot;) + facet_grid(~Trait, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5), plot.subtitle = element_text(hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(df$Outcome)); ht2 &lt;- length(unique(df$term)) wdt &lt;- length(unique(df$Trait)) ggsave(file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/figures/overall forest/%s_%s_fixed.png&quot;, local_path, type, mod, cov), width = wdt*2, height = ht+ht2) rm(p) gc() return(T) } nested_ipd1b_fixef %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), sig = factor(sig, levels = c(&quot;sig&quot;,&quot;ns&quot;)), Trait = factor(Trait, levels = traits$short_name), Outcome = factor(Outcome, levels = outcomes$short_name, labels = str_wrap(outcomes$long_name, 15)), Outcome = forcats::fct_rev(Outcome)) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(pmap(list(data, Moderator, type, Covariate), ipd1b_fx_plot_fun)) 3.2.2.5.2.2 Study-Specific Forest Plots This header is here to simply emphasize that this method does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.2.5.2.3 Overall Simple Effects Plots loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/1b_ipd_fixef/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd1b_simp &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/1b_ipd_fixef/%s/predicted&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), pred = map2(file, type, ~loadRData(.x, .y, &quot;pred.fx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) nested_ipd1a_simp simp_eff_fun &lt;- function(df, outcome, mod, type, cov){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) lim &lt;- c(mini, maxi) brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; df &lt;- df %&gt;% unclass %&gt;% data.frame df$mod_value &lt;- df[,mod] df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(df$mod_value) == &quot;factor&quot;){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} else{df &lt;- df %&gt;% group_by(Trait) %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() } lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;, &quot;dotdash&quot;, &quot;longdash&quot;, &quot;twodash&quot;)[1:length(unique(df$mod_fac))] df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), lower = ifelse(lower &lt; 4, 4, lower), upper = ifelse(upper &gt; 10, 10, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = mod_fac)) + scale_y_continuous(limits = c(4,10) , breaks = c(4, 6, 8, 10) , labels = c(4, 6, 8, 10)) + scale_linetype_manual(values = lt) + geom_ribbon(aes(ymin = lower , ymax = upper , fill = mod_fac) , alpha = .25) + geom_line(aes(linetype = mod_fac)) + labs(x = &quot;Personality (POMP)&quot; , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = m , fill = m , subtitle = &quot;Method 1B: Pooled Linear Regression with Cluster-Corrected Standard Errors&quot;) + facet_wrap(~Trait, nrow = 3) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/1b_ipd_fixef/%s/figures/overall simple effects/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov), width = 6, height = 6) } ipd1b_se_plot &lt;- nested_ipd1b_simp %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred)), plot = pmap(list(data, Outcome, Moderator, type, Covariate), simp_eff_fun)) 3.2.2.5.2.4 Study-Specific Simple Effects Plots This header is here to simply emphasize that this method does not provide study-specific estimates, unlike Methods 2ab, 3, and 4. 3.2.2.6 Sample Results Section We examined estimates of overall prospective associations between Big Five personality characteristics and crystallized abilities as well as participant-level moderators of those associations using fully pooled, one-stage regression models with cluster-corrected standard errors using individual participant data in 11 studies. This allowed us to correct for clustering of data within studies without estimating sample-specific estimates. Table S2 presents the estimates of the key terms from all unmoderated and participant and sample-level moderators estimates from fully adjusted models. Across the 20 participant-level personality-cognitive ability associations and moderators of those associations, none were significant, including unmoderated associations between personality and crystallized abilities. Table 3.2: 1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality -0.07[-0.22, 0.08] -0.07[-0.23, 0.08] -0.01[-0.14, 0.12] -0.03[-0.13, 0.08] 0.11[-0.03, 0.25] Age Age 0.000[-0.00, 0.00] -0.000[-0.00, 0.00] -0.001[-0.00, 0.00] 0.00[-0.00, 0.00] -0.00[-0.01, 0.001] Gender Gender (Male v Female) 0.05[0.001, 0.10] 0.04[-0.00, 0.08] 0.03[-0.07, 0.13] -0.01[-0.08, 0.05] -0.02[-0.08, 0.04] Education Education (Years) 0.00[-0.01, 0.02] -0.00[-0.03, 0.02] -0.01[-0.03, 0.02] -0.00[-0.02, 0.01] 0.00[-0.01, 0.01] The simple effects plots shown in Figure S2 provide a visualization to help better understand the moderators. The figure displays the predicted crystallized ability levels at different levels of the Big Five for males and females. Gender moderated the relationship between extraversion and later crystallized abilities (b = 0.06, 95% CI [0.001, 0.12]). The overall association between personality traits and later crystallized ability was null for extraversion for men (b = -0.01, 95% CI [-0.06, 0.03]) but positive for women (b = 0.05, 95% CI [0.004, 0.09]), such that women who were higher in extraversion tended to score higher on crystallized domain tasks. All other simple effects are available in the online materials and in the web app. Figure 3.2: Figure S2. Simple effects of the prospective association between Big Five personality characteristics (rows) and crystallized abilities across gender (male, female) using all methods of data synthesis (columns). The x-axis captures personality in percentage of maximum possible (POMP) units, the y-axis captures crystallized abilities in POMP, and different panels represent each of the Big Five characteristics. Different lines indicate the predicted levels of cognitive ability for males (dotted line) and females (solid line). rm(list = ls()[grepl(&quot;ipd1b&quot;, ls())]) "],["method-2-pooled-one-stage-models-with-study-specific-effects.html", "Chapter 4 Method 2: Pooled One Stage Models with Study-Specific Effects 4.1 Step 1: Combine Data 4.2 Step 2: Run Models and Extract Results", " Chapter 4 Method 2: Pooled One Stage Models with Study-Specific Effects The structure of the data for models with and without study-specific effects is identical, so we can directly proceed to step 2 and run the models. However, for the purposes of making each chapter somewhat standalone, the code from Method 1, Step 1 setup will be duplicated below. 4.1 Step 1: Combine Data loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) load(path) get(ls()[grepl(type, ls())]) } ipd_reg_data &lt;- tibble( study = studies[!studies %in% c(&quot;CNLSY&quot;, &quot;SLS&quot;)] , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID))) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% mutate(age = ifelse(is.na(age), p_year - yearBrth, age)) ipd_reg_data ## # A tibble: 119,597 × 13 ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 3.83 1990 10004 crystallized 2.17 2000 17 0 4 1918 72 ## 2 BASE E 3.83 1990 10010 crystallized 3.08 1995 11 0 2 1911 79 ## 3 BASE E 2.5 1990 10033 crystallized 0.909 1997 8 1 5 1910 80 ## 4 BASE E 3 1990 10034 crystallized 6.54 1995 10 0 5 1914 76 ## 5 BASE E 2.5 1990 10111 crystallized 6.54 1995 13 1 4 1901 89 ## 6 BASE E 3.17 1990 10115 crystallized 10 1995 11 0 2 1918 72 ## 7 BASE E 3 1990 10116 crystallized 3.85 1995 10 0 4 1917 73 ## 8 BASE E 3 1990 10145 crystallized 6.36 1997 10 1 5 1897 93 ## 9 BASE E 3.33 1990 10175 crystallized 2.31 1995 8 1 3 1911 79 ## 10 BASE E 3.33 1990 10188 crystallized 5.77 2004 10 1 2 1903 87 ## # ℹ 119,587 more rows 4.1.1 Study-Level Moderators First, we need to bring in a few study-level moderators from Table 4, which includes information about the continent and country of origin, and the type of personality scale. Then we’ll join those data with cleaned data from each study in order to calculate the average age at baseline, the average baseline year, and the average interval between personality and cogntiive measurements. Because these vary within studies across personality traits and outcomes, we calculate baseline age, year, and prediction interval for all combinations of these separately. url &lt;- &quot;https://github.com/emoriebeck/data-synthesis-tutorial/raw/main/codebooks/crystallized_tables.xlsx&quot; destfile &lt;- &quot;tables.xlsx&quot; curl::curl_download(url, destfile) ipd_reg_data &lt;- readxl::read_xlsx(destfile, sheet = &quot;Table 4&quot;) %&gt;% select(-Category, -Construct, -category) %&gt;% pivot_longer(cols = c(&quot;BASE-I&quot;:&quot;SATSA&quot;) , names_to = &quot;study&quot; , values_to = &quot;value&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) %&gt;% mutate(continent = relevel(factor(continent), ref = &quot;North America&quot;) , country = relevel(factor(country), ref = &quot;United States&quot;) , scale = relevel(factor(scale), ref = &quot;NEO-FFI&quot;)) %&gt;% # mutate(p_year = as.numeric(p_year)) %&gt;% right_join(ipd_reg_data) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate(baseAge = mean(age, na.rm = T) - 60, # center at age 60 predInt = mean(o_year - p_year) - 5, # center at 5 years baseYear = mean(p_year) - 2000) %&gt;% # center at 2000 ungroup() 4.1.2 Harmonize Data Next, we need to harmonize the data across studies. As we preregistered, continuous variables (personality, cognition, and self-rated health) will be calclulated as percentages of maximum possible separately for each study, Trait and outcome. Unlike standardization procedures, that have a mean of zero and unit variance and can be misleading when data are skewed, POMP does not rescale sample variance based on the observed data, which overly relies on deviations from the mean. Instead, POMP relies on the ratio between the difference between a score and the minimum and the maximum and minimum, or POMP = \\(\\frac{observed-minimum}{maximum-minimum}\\)*10. In addition, gender will be dummy coded with male as the reference group, education will be centered at 12 years of education, and age will be grand mean-centered in each study (also for each trait and outcome combination). ipd_reg_data &lt;- ipd_reg_data %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, o_value), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate(gender = factor(gender, levels = c(0,1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), education = education - 12, # center at 12 years of education age = age - mean(age, na.rm = T)) %&gt;% # center ungroup() %&gt;% select(-yearBrth) 4.1.3 Save Data Files Now, we’ll save these data files into separate data files for each trait, outcome combination. This makes it easier to track each data set that will be used in subsequent analyses. save_fun &lt;- function(d, trait, outcome){ save(d, file = sprintf(&quot;%s/data/one_stage/%s_%s.RData&quot;, local_path, trait, outcome)) } ipd_reg_data %&gt;% group_by(Trait, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, Trait, Outcome), save_fun)) ## # A tibble: 5 × 3 ## Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 A crystallized &lt;NULL&gt; ## 2 C crystallized &lt;NULL&gt; ## 3 E crystallized &lt;NULL&gt; ## 4 N crystallized &lt;NULL&gt; ## 5 O crystallized &lt;NULL&gt; 4.2 Step 2: Run Models and Extract Results Once the data are prepped, we are ready to begin running models! For Method 2: Pooled One Stage Models with Study-Specific Effects, we will run two variants. The first mimics a dummy coding procedure often seen in the economics literature where study-specific effects are captured by including studies as fixed effects. The second is a multilevel model in which particiants are nested within studies, and studies are treated as random effects, rather than fixed effects, as in Method 2A. Both of of use when study-specific effects are of interest, but Method 2B is of particular use when wanting to mimic heterogeneity estimates and meta regression techniques of traditional meta analyses. 4.2.1 Method 2A: Pooled One Stage Models with Dummy Codes 4.2.1.1 Analytic Plan In the present study, we estimate associations between the Big Five personality traits and crystallized cognitive abilities using a one-stage, fully pooled regression approach with effects coded contrasts for study and individual participant data. The procedure is as follows: To estimate sample-specific effects using regression contrasts, there are a variety of coding procedures that could be used. We used effects codes, which result in a term that captures the overall estimated effect and k-1 terms capturing sample-specific deviations from the overall estimate (all sample estimates can then be recovered via linear combinations). Using effects codes allows us to statistically test whether each sample (minus one) differs from the overall effect. Although dummy codes are most frequently used in regression-based approaches, effects code are the means by which regression is linked to analysis of variance in order to estimate marginal means. For example, if there were only three samples under investigation the matrix of effect codes would look like: \\[ \\begin{array}{rr} d_1 &amp; d_2 \\\\ .5 &amp; 0 \\\\ 0 &amp; .5 \\\\ -.5 &amp; -.5 \\end{array} \\], where each column \\(j\\) is an indicator in the model and each row \\(k\\) represents a different sample. The first coefficient would capture the difference between the first sample and the overall estimate, while the second coefficient would capture the difference between the second sample and the overall estimate. By additionally adding an interaction between the effects coded terms and the key term (i.e. personality traits in the present study), we can additionally test for sample-specific estimates of key associations in the regression. 2. Statistical Modeling. Models were run separately for each personality characteristic, outcome, covariate, and moderator (10; 3 participant-level) combination. Using the R programming language, we created a series of functions to (1) set up and run the model and extract model coefficients and (2) extract overall simple-effects predictions for participant-level moderator models (i.e. predicted values across levels of the moderator values). In addition, to estimate sample-specific effects using effects codes, we created additional functions to (3) set up the effects codes and ensure interpretable variable labels, (4) set up and run a series of linear combinations of the effect-coded terms to get personality-crystallized abilities associations or moderators of their association for each sample, and (5) extract sample-specific simple-effects prediction for the participant-level moderators. Each of these functions were designed to flexibly handle different classes of covariates and moderators (e.g., nominal, numeric) and to wrangle the results into easily combined and understandable data frames. The functions and more detail on them can be found in the online materials. The basic form of the model is as follows: \\[Y_{ij} = b_0 + b_1\\ast predictor_{ij}+b2\\ast study{\\ 1}_{ij}+\\ldots+b_k\\ast study{k}_{ij}+ b_{k+1}\\ast predictor_{ij}\\ast study\\ 1_{ij}+\\ldots+b_{2\\ast k}\\ast predictor_{ij}\\ast study{k}_{ij}+\\epsilon_{ij}\\] \\(\\varepsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\), where \\(k\\) indicates the number of samples - 1. Of interest are two key sets of terms. \\(b_1\\) indicates the average personality-cognition relationship, and \\(b_{k+1}\\) to \\(b_{2k}\\) represent effect coded sample-specific differences in outcome associations (i.e. the estimate for a sample is \\(b_1+b_{2k}\\)). All other terms capture sample-specific differences in overall cognitive ability levels, if any. There is no measure of cross-sample heterogeneity, and residuals are assumed to be homogeneous. Models were tested using the base R lm() function in R, and the tidy() function from the broom package to extract model coefficients and confidence intervals (CI). Inferences were made based on the 95% confidence intervals. Overall simple-effects predictions were calculated by providing the full range of personality (0-10) and average levels of the covariates from the data used to estimate the model as the “newdata” argument in the base R predict() function. For sample-specific effects, effects coded linear combinations for each sample were provided to the glht() function from the multcomp package (version 1.4.20; Hothorn et al., 2008). 4.2.1.2 Model Function The first thing we need is a function that will bring in the data, create a formula in the model based on input on the type (Frequentist or Bayesian), moderators (none, age, gender, SRhealth, and education), and combinations of covariates (single or fully adjusted based on age, gender, SRhealth, and education). This case is slightly complicated given that we are using dummy codes for each study. We want to get an overall estimate as well as study-specific estimates. So we’ll have to build contrasts that give us these. Then we run the model, extract its fixed and study-specific effect estimates, and save both for later. By saving the results, it will make it easier and faster for us to extract the necessary model results later while still retaining all information from the original model. ipd2a_mod_fun &lt;- function(trait, outcome, type, mod, cov){ ## load the data load(sprintf(&quot;%s/data/one_stage/%s_%s.RData&quot;, local_path, trait, outcome)) ## Applt effects codes d &lt;- contr_fun(d) ## compiled Bayesian model to speed up processing and avoid crashing if(type == &quot;Bayesian&quot;) load(sprintf(&quot;%s/results/2a_ipd_dc/bayes_sample_mod.RData&quot;, local_path)) # get the model formula ## model formula if (cov == &quot;all&quot;) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if (!cov %in% c(&quot;all&quot;, &quot;none&quot;)) cv &lt;- cov rhs &lt;- c(&quot;p_value&quot;, &quot;study&quot;, &quot;p_value:study&quot;) rhs &lt;- if(cov != &quot;none&quot;) c(rhs, cv) else rhs if(!mod %in% c(&quot;none&quot;, stdyModers$short_name)){rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, &quot;study&quot;, sep = &quot;*&quot;))} if(mod %in% stdyModers$short_name){rhs &lt;- c(rhs, mod, paste(&quot;p_value&quot;, mod, sep = &quot;:&quot;))} rhs &lt;- paste(rhs, collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## run the models &amp; save m &lt;- if(type == &quot;Frequentist&quot;){do.call(&quot;lm&quot;, list(formula = f, data = quote(d)))} else {update(m, formula = f, newdata = d, iter = 2000 , warmup = 1000)} closeAllConnections() save(m, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/models/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) rx &lt;- if(mod != stdyModers$short_name) std_eff_fun(m, type, mod) else NA save(fx, rx, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/summary/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) if(mod != &quot;none&quot;){ load(sprintf(&quot;%s/results/2a_ipd_dc/%s/models/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) pred.fx &lt;- ipd2a_simpeff_fun(m, mod, type) pred.rx &lt;- if(mod %in% stdyModers$short_name) NULL else ipd2a_rx_pred_fun(m, mod, type) save(pred.fx, pred.rx, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/predicted/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;rhs&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;rx&quot;)) gc() } 4.2.1.3 Contrasts Function One function we will call in the modeling function for Method 2A is one that creates the contrasts that we’ll use for the models we’ll run. Because the contrasts necessary to get study-specific estimates and an overall estimate are not orthogonal, we will necessarily have to use two steps to get all these estimates. As a result, the method we use for contrasts doesn’t matter that much. We’ll use effects coding, as we pre-registered, because it will give us the overall estimate in the main model, as well as estimates of how S - 1 studies differ from that overall estimate. Basically, teh function below will: 1. Get names of all those studies. 2. Use the contr.sum() function to create effects codes (i.e. a S-1 x S matrix of codes) 3. Set the row and column names to the studies we are examining 4. Save that contrast matrix to the study column of teh data frame contr_fun &lt;- function(d){ ## effect code the data d &lt;- d %&gt;% mutate(study = str_remove_all(study, &quot;-&quot;) , study = factor(study)) std &lt;- rownames(contrasts(d$study)) cntr &lt;- contr.sum(length(std)); rownames(cntr) &lt;- std; colnames(cntr) &lt;- std[1:(length(std)-1)] contrasts(d$study) &lt;- cntr return(d) } 4.2.1.4 Study-Specific Effects Function As noted previously, once we run the model, we will have to use a second step to get the study-specific estimates for all studies. To make this flexible for both Frequentist and Bayesian estimates, overall personality-outcome associations, and moderator associations is somewhat complicated. So we’ll start by getting names of the terms from the model. Then we’ll find the key term (either personality-outcome association or moderator effect) and the studies linked to these terms. For those studies, then getting the contrast formula is straightforward (overall effect + study effect). For the study without a model term, the formula is more complicated (overall effect - (S-1 study effects)). Once we have these, they can easily be fed to the glht() function in the multcomp package (frequentist) or the hypothesis() function in the brms package (bayesian) to get all study-specific estimates and confidence / certainty intervals. Before we do this, though, let’s try to better understand where these terms come from. Consider the case of four samples used to estimate an effect. This would require 3 effects coded contrast terms (\\(d_1\\) to \\(d_3\\))in the model coded as follows: \\[ \\begin{array}{rr} d_1 &amp; d_2 &amp; d_3 \\\\ 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1\\\\ -1 &amp; -1 &amp; -1 \\end{array} \\], where \\(d_1\\) to \\(d_{k-1}\\) indicates the difference between samples 1 to \\(k-1\\) and the grand mean. Thus, to recover the study-specific estimates, we can return to the equation for the model for the four sample case: \\(Y_{ij}= b_0 + b_1*predictor_{ij} + b2*study1_{ij} + b3*study2_{ij} + b4*study3_{ij} + b_{5}*predictor_{ij}*study1_{ij} + b_{6}*predictor_{ij}*study2_{ij} + b_{7}*predictor_{ij}*study3_{ij} + \\epsilon_{ij}\\), where \\(b_5\\) to b_7 indicates the difference in the persoanlity-cognitive ability association between the average association across studies and samples 1-3, respectively. Then, to recover the estimate for samples 1-3, we simply need to sum the term for the overall association with the term for the difference in the association between that and samples 1-3, or: Sample 1: \\(b_1 + b_5\\) Sample 2: \\(b_1 + b_6\\) Sample 3: \\(b_1 + b_7\\) Lastly, to recover the estiamte for sample 4, we must subtract the estimates of differences for samples 1-3 from the grand mean, or: Sample 4: \\(b_1 - b_5 - b_6 - b_7\\) The function below extracts each of these and saves the estimates and their confidence intervals according to study names for easy combination and understanding. std_eff_fun &lt;- function(m, type, mod){ if(type == &quot;Bayesian&quot;){ std &lt;- as.character(unique(m$data$study)) # vector of studies nc &lt;- nrow(fixef(m)); nr &lt;- length(std) # number of rows and columns trms &lt;- rownames(fixef(m)) } else{ std &lt;- as.character(unique(m$model$study)) # vector of studies nc &lt;- length(coef(m)); nr &lt;- length(std) # number of rows and columns trms &lt;- names(coef(m)) } modtrm &lt;- if(mod %in% c(&quot;none&quot;, stdyModers$short_name)) &quot;p_value&quot; else trms[grepl(paste0(&quot;p_value:&quot;, mod), trms)] stdtrms &lt;- trms[grepl(&quot;p_value:study&quot;, trms)] stdtrms &lt;- if (mod %in% c(&quot;none&quot;, stdyModers$short_name)) stdtrms else stdtrms[grepl(mod, stdtrms)] # create character contrasts cntrm &lt;- paste(stdtrms, &quot;+&quot;, modtrm, &quot; = 0&quot;) cntrm &lt;- c(cntrm, paste0(&quot; - &quot;, stdtrms, collapse = &quot;&quot;) %&gt;% paste(modtrm, ., collapse = &quot;&quot;) %&gt;% paste(., &quot;= 0&quot;, collapse = &quot;&quot;)) names(cntrm) &lt;- std # Run the contrasts and rename to match overall model coefficient tables h &lt;- if(type == &quot;Bayesian&quot;) { hypothesis(m, cntrm)$hypothesis %&gt;% # brms hypothesis function select(study = Hypothesis, estimate = Estimate, conf.low = CI.Lower, conf.high = CI.Upper) %&gt;% mutate(term = modtrm) %&gt;% as_tibble() } else { (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% mutate(study = std, term = modtrm) %&gt;% rename(estimate = Estimate, conf.low = lwr, conf.high = upr) %&gt;% as_tibble() } return(h) } 4.2.1.5 Simple Effects Function 4.2.1.5.1 Overall Effects fx_lm_pred_fun &lt;- function(m, newdata){ tt &lt;- terms(m) Terms &lt;- delete.response(tt) mf &lt;- model.frame(Terms, newdata, xlev = m$xlevels) X &lt;- model.matrix(Terms, mf, contrasts.arg = m$contrasts) X[,grepl(&quot;study&quot;, colnames(X))] &lt;- 0 p &lt;- m$rank p1 &lt;- seq_len(p) piv &lt;- m$qr$pivot[p1] beta &lt;- m$coefficients predictor &lt;- drop(X[, piv, drop = FALSE] %*% beta[piv]) w &lt;- m$weights res.var &lt;- { r &lt;- m$residuals rss &lt;- sum(r^2) df &lt;- m$df.residual rss/df } XRinv &lt;- X[, piv] %*% qr.solve(qr.R(m$qr)[p1, p1]) ip &lt;- drop(XRinv^2 %*% rep(res.var, p)) tfrac &lt;- qt((.05)/2, df) hwid &lt;- tfrac * sqrt(ip) predictor &lt;- cbind(predictor, predictor + hwid %o% c(1, -1)) colnames(predictor) &lt;- c(&quot;fit&quot;, &quot;lwr&quot;, &quot;upr&quot;) return(predictor) } fx_bayes_pred_fun &lt;- function(m, newdata){ ps &lt;- posterior_samples(m, &quot;^b&quot;, as.matrix = T) X &lt;- prepare_predictions( m, newdata %&gt;% mutate(o_value = 1) )$dpars$mu$fe$X[,1:ncol(ps), drop = FALSE] X[,grepl(&quot;study&quot;, colnames(X))] &lt;- 0 predictor &lt;- X %*% t(ps) predictor &lt;- posterior_summary(t(predictor)) return(predictor) } ipd2a_simpeff_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model std_lev &lt;- rev(levels(d$study))[1] d &lt;- d %&gt;% select(-o_value, -p_value, -study) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { unique(fct_lev[,moder][[1]]) } mod_frame &lt;- crossing( p_value = seq(0,10,.5) , modvalue = md_levs ) %&gt;% setNames(c(&quot;p_value&quot;, moder)) %&gt;% mutate(study = std_lev) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)[1])) } } pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame %&gt;% select(-study), fx_bayes_pred_fun(m, newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame %&gt;% select(-study), fx_lm_pred_fun(m, newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$model)), pred = fit, lower = lwr, upper = upr) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 4.2.1.5.2 Study-Specific Effects # short function to get crossings of continuous personality and moderator levels # crossing_fun &lt;- function(df, mod, mod_lev){ # pred.rx &lt;- crossing( # p_value = seq(0,10,.5), # mod_value = mod_lev # ) %&gt;% # setNames(c(&quot;p_value&quot;, mod)) # return(pred.rx) # } ipd2a_rx_pred_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% pivot_longer(-study , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(study, item) %&gt;% summarize_at(vars(value), lst(mean, sd), na.rm = T) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) %&gt;% ungroup() %&gt;% data.frame() } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { unique(fct_lev[,moder][[1]]) } mod_frame &lt;- if(md_cl == &quot;numeric&quot;) { crossing( p_value = seq(0,10,.5), modvalue = md_levs, study = unique(d$study) ) %&gt;% setNames(c(&quot;p_value&quot;, moder, &quot;study&quot;))#%&gt;% full_join( # msd %&gt;% # filter(item == moder) %&gt;% # mutate(lower = mean - sd, upper = mean + sd) %&gt;% # select(-sd) %&gt;% # pivot_longer(cols = c(mean, lower, upper) # , names_to = &quot;meas&quot; # , values_to = &quot;modvalue&quot;) %&gt;% # pivot_wider(names_from = &quot;item&quot;, values_from = &quot;modvalue&quot;) %&gt;% # select(study, one_of(moder)) # ) } else { crossing( p_value = seq(0,10,.5) , mod_value = md_levs#unique(fct_lev[,moder][[1]]) , study = unique(d$study) ) %&gt;% setNames(c(&quot;p_value&quot;, moder, &quot;study&quot;)) } if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean, na.rm = T) %&gt;% ungroup() %&gt;% full_join(mod_frame) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)) %&gt;% ungroup() %&gt;% full_join(mod_frame) } } pred.rx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m , newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, predict(m, newdata = mod_frame, interval = &quot;confidence&quot;) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$model)), pred = fit, lower = lwr, upper = upr) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.rx) } 4.2.1.6 Run Models and Summaries The code below generates all possible preregistrered combinations of traits, outcomes, types, moderators, and covariates. Then these combinations are fed serially to the model function written previously, which will run and save the results. load(sprintf(&quot;%s/data/one_stage/E_crystallized.RData&quot;, local_path)) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = F)))) %&gt;% unnest(data) d &lt;- contr_fun(d) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) rhs &lt;- c(&quot;p_value&quot;, &quot;study&quot;, &quot;p_value:study&quot;) rhs &lt;- c(rhs, cv) rhs &lt;- paste(rhs, collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- bf(f) m &lt;- brm(formula = f , data = d , prior = Prior , iter = Iter , warmup = Warmup , cores = 4) save(m, file = sprintf(&quot;%s/results/2a_ipd_dc/bayes_sample_mod.RData&quot;, local_path)) rm(list = c(&quot;d&quot;, &quot;Prior&quot;, &quot;Iter&quot;, &quot;Warmup&quot;, &quot;treedepth&quot;, &quot;f&quot;, &quot;m&quot;, &quot;rhs&quot;, &quot;cv&quot;)) # plan(multisession(workers = 8L)) nested_ipd2a_reg &lt;- # moderator result combinations crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) , Covariate = c(&quot;none&quot;, &quot;all&quot;) ) %&gt;% full_join( # personality-outcome association results across covariates crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;none&quot;, unique(stdyModers$short_name)) , Covariate = c(&quot;none&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;all&quot;) ) ) %&gt;% # full_join(done) %&gt;% filter(is.na(done)) %&gt;% # filter(Trait == &quot;N&quot;) %&gt;% filter(type == &quot;Bayesian&quot;) %&gt;% mutate(run = # future_pmap(list(Trait, Outcome, type, Moderator, Covariate) pmap(list(Trait, Outcome, type, Moderator, Covariate) , possibly(ipd2a_mod_fun, &quot;uh oh&quot;) # , .progress = T # , .options = furrr_options( # globals = c(&quot;ipd2a_mod_fun&quot; # , &quot;std_eff_fun&quot; # , &quot;fx_lm_pred_fun&quot; # , &quot;fx_bayes_pred_fun&quot; # , &quot;ipd2a_simpeff_fun&quot; # , &quot;crossing_fun&quot; # , &quot;contr_fun&quot; # , &quot;ipd2a_rx_pred_fun&quot; # , &quot;read_path&quot; # , &quot;local_path&quot; # , &quot;res_path&quot; # , &quot;codebook&quot; # , &quot;covars&quot; # , &quot;moders&quot; # , &quot;outcomes&quot; # , &quot;studies&quot; # , &quot;stdyModers&quot; # , &quot;traits&quot; # , &quot;data_path&quot;) # , packages = c(&quot;lme4&quot; # , &quot;broom&quot; # , &quot;psych&quot; # , &quot;knitr&quot; # , &quot;broom.mixed&quot; # , &quot;brms&quot; # #, &quot;tidybayes&quot; # #, &quot;bootpredictlme4&quot; # , &quot;rstan&quot; # , &quot;estimatr&quot; # #, &quot;merTools&quot; # , &quot;plyr&quot; # , &quot;tidyverse&quot;)) )) closeAllConnections() nested_ipd2a_reg %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% write.table(. , file = sprintf(&quot;%s/scripts/cluster/args/bayesian/ipd2a_bayesian.txt&quot;, local_path) , row.names = F) 4.2.1.7 Compile Results Once all the models are run, we are ready to compile all their results. By saving the fixed and study-level effects results previously, we are able to simply load those results and ignore the models. However, because we also saved the models, we can also recall and extract information from them if and when needed. loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/2a_ipd_dc/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } n_fun &lt;- function(fileName, type){ m &lt;- loadRData(fileName, type, &quot;^m&quot;, &quot;models&quot;) d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model n &lt;- d %&gt;% group_by(study) %&gt;% tally() %&gt;% ungroup() return(n) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd2a_reg &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/2a_ipd_dc/%s/models&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), fx = map2(file, type, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;)), rx = map2(file, type, ~loadRData(.x, .y, &quot;rx&quot;, &quot;summary&quot;)), n = map2(file, type, n_fun)) %&gt;% select(-file) 4.2.1.7.1 Tables Next, we want to format the study results in APA table format. In this case, we are interested in the fixed and study-specific effects of personality predicting cognitive ability when there were no moderators, and the personality x moderator interaction when there was a moderator. We’ll anticipate a need to present both just fixed effects as well as fixed and study-specific effects by creating tables for each. First, let’s format the data. ipd2a_reg_tab &lt;- ### fixed effects nested_ipd2a_reg %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% # unnesting # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term))) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ### study specific effects full_join( nested_ipd2a_reg %&gt;% select(-fx, -n) %&gt;% unnest(rx) %&gt;% # unnesting filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term))) %&gt;% mutate( ) ) %&gt;% filter(!is.na(term)) %&gt;% # reformatting: mark significance, prettify Trait, covariate, and moderator names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, c(&quot;scaleBFIMS&quot;, &quot;scaleIPIPNEO&quot;, &quot;scaleTDAM40&quot;, &quot;countryTheNetherlands&quot;) , c(&quot;scaleBFI-S&quot;, &quot;scaleIPIP NEO&quot;, &quot;scaleTDA-40&quot;, &quot;countryThe Netherlands&quot;)), term2 = factor(term, c(moders$short_term, stdyModers$short_term), c(moders$long_term, stdyModers$long_term))) %&gt;% # prettify the number format mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .001, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% # combine the effects, bold significance, factor and label study-specfic effects mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est), study = factor(study, levels = c(studies_long, &quot;Overall&quot;), labels = c(studies_long, &quot;Overall&quot;))) %&gt;% # reshaping: remove extra columns, arrange by key variables, and make wide select(type, Outcome, Trait, Moderator, Covariate, study, term2, est) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate, study, term2) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) # filter(row_number() %in% c(9, 10)) # spread(Trait, est) ipd2a_reg_tab ## # A tibble: 242 × 11 ## type Outcome Moderator Covariate study term2 E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 Bayesian Crystallized Ability None Unadjusted EAS Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 2 Bayesian Crystallized Ability None Unadjusted GSOEP Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 3 Bayesian Crystallized Ability None Unadjusted HILDA Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 4 Bayesian Crystallized Ability None Unadjusted HRS Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 5 Bayesian Crystallized Ability None Unadjusted MAP Personality &lt;chr [1]&gt; &lt;NULL&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;NULL&gt; ## 6 Bayesian Crystallized Ability None Unadjusted ROS Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 7 Bayesian Crystallized Ability None Unadjusted SATSA Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 8 Bayesian Crystallized Ability None Unadjusted Overall Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## 9 Bayesian Crystallized Ability None Unadjusted &lt;NA&gt; Personality &lt;chr [2]&gt; &lt;NULL&gt; &lt;NULL&gt; &lt;chr [2]&gt; &lt;chr [1]&gt; ## 10 Bayesian Crystallized Ability None Age EAS Personality &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; &lt;chr [1]&gt; ## # ℹ 232 more rows ipd2a_res &lt;- nested_ipd2a_reg %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% # unnesting # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term))) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;\\\\textit{b} = %s, 95\\\\%% CI [%s, %s]&quot;, estimate, conf.low, conf.high)) Now that we’ve formatted the values, we can group by moderators and save results as separate tables. Even though additional information could be included given that we have one outcome, we’ll stick with this split because it will make it easier for those using this tutorial who multiple traits, outcomes, covariates, and moderators. 4.2.1.7.1.1 Fixed Effects ## table function ipd2a_fx_tab_fun &lt;- function(d, type, moder){ md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term2)) == 1) rep(1,6) else c(2, rep(1,5)) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariates&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariates&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) al &lt;- if(length(unique(d$term2)) == 1) c(&quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term2)) == 1) d &lt;- d %&gt;% select(-term2) cap &lt;- if(md == &quot;none&quot;) &quot;2A Pooled One Stage Models with Dummy Codes: Overall Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;2A Pooled One Stage Models with Dummy Codes: Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% arrange(Outcome) %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs, escape = F) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/tables/overall/%s.html&quot; , local_path, type, md)) return(tab) } ipd2a_fx_tab &lt;- ipd2a_reg_tab %&gt;% filter(study == &quot;Overall&quot; &amp; !Moderator %in% stdyModers$long_name) %&gt;% select(-study) %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd2a_fx_tab_fun)) ipd2a_fx_tab ## # A tibble: 8 × 4 ## type Moderator data tab ## &lt;chr&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 Bayesian None &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 2 Bayesian Age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 3 Bayesian Gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 4 Bayesian Education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 5 Frequentist None &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 6 Frequentist Age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 7 Frequentist Gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 8 Frequentist Education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; # save(ipd2a_fx_tab, ipd2a_res, file = sprintf(&quot;%s/manuscript/results/ipd2a_fx_tab.RData&quot;, res_path)) ## Frequentist (ipd2a_fx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Frequentist&quot;))$tab[[1]] Table 4.1: 2A Pooled One Stage Models with Dummy Codes: Overall Effects of Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Covariates b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted 0.05[0.02, 0.08] -0.00[-0.03, 0.03] 0.04[0.02, 0.07] -0.13[-0.15, -0.11] 0.29[0.25, 0.32] Age 0.05[0.02, 0.08] 0.01[-0.02, 0.04] 0.04[0.01, 0.07] -0.13[-0.16, -0.11] 0.30[0.26, 0.33] Gender 0.05[0.02, 0.08] 0.01[-0.02, 0.04] 0.04[0.01, 0.07] -0.13[-0.15, -0.11] 0.29[0.26, 0.33] Education 0.02[-0.01, 0.05] -0.001[-0.03, 0.03] 0.01[-0.02, 0.04] -0.07[-0.09, -0.04] 0.17[0.14, 0.21] Fully Adjusted 0.02[-0.01, 0.05] -0.01[-0.04, 0.02] 0.01[-0.02, 0.04] -0.07[-0.09, -0.05] 0.17[0.14, 0.21] ## bayesian (ipd2a_fx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Bayesian&quot;))$tab[[1]] Table 4.1: 2A Pooled One Stage Models with Dummy Codes: Overall Effects of Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Covariates b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted 0.05[0.02, 0.08] -0.00[-0.03, 0.02] 0.04[0.02, 0.06] -0.13[-0.15, -0.11] 0.29[0.25, 0.32] Age 0.05[0.02, 0.08] 0.01[-0.02, 0.04] 0.04[0.01, 0.07] -0.13[-0.16, -0.11] 0.30[0.26, 0.33] Gender 0.05[0.02, 0.08] 0.01[-0.02, 0.04] 0.04[0.01, 0.07] -0.13[-0.15, -0.11] 0.29[0.26, 0.33] Education 0.02[-0.01, 0.05] -0.00[-0.03, 0.03] 0.01[-0.02, 0.04] -0.07[-0.09, -0.04] 0.17[0.14, 0.21] Fully Adjusted 0.02[-0.01, 0.05] -0.01[-0.04, 0.02] 0.01[-0.02, 0.04] -0.07[-0.09, -0.05] 0.17[0.14, 0.21] ipd2a_tab_fun &lt;- function(d, type, cov){ # long outcome name covar &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$short_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- sprintf(&quot;2A Pooled One Stage Models with Dummy Codes: Fixed Effect Estimates of %s Personality-Crystallized Domain Associations&quot;, cov) # kable the table tab &lt;- d %&gt;% select(-Moderator, -study) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs, escape = F) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/tables/key terms/%s.html&quot; , local_path, type, covar)) return(tab) # return the html table } ipd2a_fx_tab2 &lt;- ipd2a_reg_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% arrange(Moderator, term2) %&gt;% filter(Covariate %in% c(&quot;Unadjusted&quot;, &quot;Fully Adjusted&quot;)) %&gt;% group_by(Outcome, type, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Covariate), ipd2a_tab_fun)) ## Frequentist, no moderator (ipd2a_fx_tab2 %&gt;% filter(type == &quot;Frequentist&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] Table 4.2: 2A Pooled One Stage Models with Dummy Codes: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.02[-0.01, 0.05] -0.01[-0.04, 0.02] 0.01[-0.02, 0.04] -0.07[-0.09, -0.05] 0.17[0.14, 0.21] Age Age -0.00[-0.01, 0.00] -0.000[-0.00, 0.00] -0.00[-0.01, 0.001] 0.00[-0.000, 0.01] 0.000[-0.00, 0.01] Gender Gender (Male v Female) 0.06[0.001, 0.12] 0.02[-0.04, 0.08] -0.00[-0.06, 0.05] -0.04[-0.09, 0.01] -0.01[-0.08, 0.06] Education Education (Years) -0.00[-0.01, 0.01] -0.00[-0.02, 0.01] 0.01[-0.001, 0.02] -0.00[-0.01, 0.01] -0.00[-0.02, 0.01] ## bayesian (ipd2a_fx_tab2 %&gt;% filter(type == &quot;Bayesian&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] Table 4.2: 2A Pooled One Stage Models with Dummy Codes: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.02[-0.01, 0.05] -0.01[-0.04, 0.02] 0.01[-0.02, 0.04] -0.07[-0.09, -0.05] 0.17[0.14, 0.21] Age Age -0.00[-0.01, 0.00] -0.000[-0.00, 0.00] -0.00[-0.01, 0.001] 0.00[-0.001, 0.01] 0.000[-0.00, 0.01] Gender Gender (Male v Female) 0.06[0.00, 0.12] 0.02[-0.04, 0.08] -0.00[-0.06, 0.05] -0.04[-0.09, 0.01] -0.01[-0.08, 0.07] Education Education (Years) -0.00[-0.01, 0.01] -0.00[-0.02, 0.01] 0.01[-0.001, 0.02] -0.00[-0.01, 0.01] -0.00[-0.02, 0.01] # save(ipd1a_fx_tab, ipd1a_fx_tab2, ipd1a_res, file = sprintf(&quot;%s/manuscript/results/ipd1b_fx_tab.RData&quot;, res_path)) 4.2.1.7.1.2 Study-Specific Effects ## table function ipd2a_rx_tab_fun &lt;- function(d, type, moder){ md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term2)) == 1) c(2, rep(1,5)) else c(3, rep(1,5)) names(cs) &lt;- c(&quot; &quot;, traits$short_name) cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariates&quot;, &quot;Study&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Study&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariates&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) al &lt;- if(length(unique(d$term2)) == 1) c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term2)) == 1) d &lt;- d %&gt;% select(-term2) # caption cap &lt;- if(md == &quot;none&quot;) &quot;2A Pooled One Stage Models with Dummy Codes: Overall Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;2A Pooled One Stage Models with Dummy Codes: Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, moder) tab &lt;- d %&gt;% arrange(Outcome) %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% collapse_rows(1, &quot;top&quot;) %&gt;% add_header_above(cs) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/tables/study-specific/%s.html&quot; , local_path, type, md)) return(tab) } ipd2a_rx_tab &lt;- ipd2a_reg_tab %&gt;% filter(study != &quot;Overall&quot;) %&gt;% arrange(type, Outcome, Moderator, Covariate, study, term2) %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd2a_rx_tab_fun)) ipd2a_fx_tab ## # A tibble: 8 × 4 ## type Moderator data tab ## &lt;chr&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 Bayesian None &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 2 Bayesian Age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 3 Bayesian Gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 4 Bayesian Education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 5 Frequentist None &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 6 Frequentist Age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 7 Frequentist Gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 8 Frequentist Education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; (ipd2a_rx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Frequentist&quot;))$tab[[1]] Table 4.3: 2A Pooled One Stage Models with Dummy Codes: Overall Effects of Personality-Crystallized Domain Associations E A C N O Covariates Study b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted EAS 0.13[0.08, 0.19] 0.02[-0.03, 0.07] 0.02[-0.03, 0.07] -0.13[-0.18, -0.08] 0.37[0.32, 0.42] GSOEP 0.08[0.03, 0.13] -0.02[-0.07, 0.03] -0.03[-0.08, 0.03] -0.06[-0.11, -0.02] 0.10[0.05, 0.14] HILDA 0.01[-0.01, 0.04] 0.05[0.02, 0.08] 0.07[0.04, 0.09] -0.15[-0.18, -0.13] 0.27[0.25, 0.30] HRS -0.00[-0.03, 0.02] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.07[-0.10, -0.05] 0.21[0.19, 0.24] LASA NULL NULL NULL -0.13[-0.17, -0.09] NULL MAP 0.03[-0.03, 0.09] NULL 0.10[0.02, 0.19] -0.16[-0.22, -0.09] NULL MARS NULL NULL NULL -0.28[-0.39, -0.18] NULL ROS -0.01[-0.07, 0.06] 0.12[0.04, 0.20] 0.13[0.05, 0.21] -0.09[-0.15, -0.02] 0.18[0.10, 0.27] SATSA 0.04[-0.05, 0.14] -0.23[-0.35, -0.12] -0.17[-0.27, -0.07] -0.09[-0.19, -0.00] 0.44[0.30, 0.58] Age EAS 0.12[0.03, 0.21] 0.09[0.01, 0.18] 0.01[-0.08, 0.09] -0.13[-0.21, -0.05] 0.42[0.34, 0.51] GSOEP 0.08[0.03, 0.13] -0.02[-0.07, 0.03] -0.03[-0.08, 0.02] -0.06[-0.11, -0.02] 0.10[0.05, 0.14] HILDA 0.01[-0.01, 0.04] 0.04[0.01, 0.07] 0.07[0.04, 0.09] -0.16[-0.19, -0.14] 0.28[0.25, 0.30] HRS -0.00[-0.03, 0.02] 0.06[0.03, 0.09] 0.16[0.14, 0.19] -0.08[-0.10, -0.05] 0.22[0.19, 0.24] LASA NULL NULL NULL -0.12[-0.17, -0.08] NULL MAP 0.03[-0.03, 0.09] NULL 0.10[0.02, 0.19] -0.16[-0.22, -0.09] NULL MARS NULL NULL NULL -0.28[-0.38, -0.18] NULL ROS -0.01[-0.08, 0.06] 0.12[0.04, 0.20] 0.13[0.06, 0.21] -0.09[-0.16, -0.02] 0.19[0.11, 0.27] SATSA 0.04[-0.05, 0.14] -0.23[-0.35, -0.12] -0.17[-0.27, -0.07] -0.09[-0.18, -0.00] 0.45[0.30, 0.59] Gender EAS 0.12[0.03, 0.21] 0.10[0.01, 0.18] 0.01[-0.08, 0.09] -0.13[-0.22, -0.05] 0.42[0.34, 0.51] GSOEP 0.08[0.03, 0.13] -0.02[-0.07, 0.03] -0.03[-0.08, 0.02] -0.06[-0.11, -0.02] 0.10[0.05, 0.14] HILDA 0.01[-0.02, 0.04] 0.05[0.02, 0.08] 0.07[0.04, 0.09] -0.15[-0.18, -0.13] 0.27[0.25, 0.30] HRS -0.00[-0.03, 0.02] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.07[-0.10, -0.05] 0.21[0.19, 0.24] LASA NULL NULL NULL -0.13[-0.17, -0.09] NULL MAP 0.03[-0.03, 0.09] NULL 0.10[0.02, 0.19] -0.16[-0.22, -0.10] NULL MARS NULL NULL NULL -0.28[-0.39, -0.18] NULL ROS -0.01[-0.08, 0.06] 0.12[0.04, 0.20] 0.13[0.06, 0.21] -0.09[-0.16, -0.02] 0.19[0.11, 0.27] SATSA 0.05[-0.05, 0.14] -0.23[-0.35, -0.12] -0.17[-0.27, -0.07] -0.09[-0.18, -0.00] 0.44[0.30, 0.58] Education EAS 0.07[-0.01, 0.16] 0.05[-0.03, 0.13] -0.04[-0.13, 0.04] -0.06[-0.14, 0.02] 0.19[0.11, 0.27] GSOEP 0.09[0.01, 0.17] 0.03[-0.06, 0.12] 0.01[-0.08, 0.10] -0.03[-0.10, 0.05] 0.06[-0.02, 0.13] HILDA 0.01[-0.01, 0.04] 0.04[0.01, 0.07] 0.03[0.01, 0.06] -0.14[-0.16, -0.11] 0.19[0.17, 0.22] HRS -0.03[-0.06, -0.01] 0.04[0.01, 0.06] 0.09[0.06, 0.11] -0.02[-0.04, -0.00] 0.10[0.08, 0.13] LASA NULL NULL NULL -0.05[-0.09, -0.01] NULL MAP 0.01[-0.05, 0.07] NULL 0.06[-0.02, 0.14] -0.03[-0.09, 0.03] NULL MARS NULL NULL NULL -0.13[-0.23, -0.03] NULL ROS -0.08[-0.14, -0.01] 0.03[-0.04, 0.11] 0.08[0.00, 0.15] -0.01[-0.07, 0.06] -0.01[-0.09, 0.07] SATSA 0.02[-0.07, 0.12] -0.19[-0.30, -0.08] -0.14[-0.24, -0.05] -0.07[-0.15, 0.02] 0.31[0.17, 0.45] Fully Adjusted EAS 0.07[-0.01, 0.16] 0.05[-0.03, 0.13] -0.04[-0.13, 0.04] -0.06[-0.14, 0.02] 0.19[0.11, 0.27] GSOEP 0.08[0.01, 0.16] 0.02[-0.06, 0.11] 0.00[-0.09, 0.10] -0.03[-0.10, 0.05] 0.06[-0.01, 0.13] HILDA 0.01[-0.01, 0.03] 0.03[-0.00, 0.05] 0.03[0.00, 0.05] -0.14[-0.16, -0.11] 0.20[0.17, 0.22] HRS -0.03[-0.06, -0.01] 0.03[0.00, 0.06] 0.08[0.06, 0.11] -0.02[-0.05, -0.00] 0.10[0.08, 0.13] LASA NULL NULL NULL -0.05[-0.09, -0.01] NULL MAP 0.01[-0.05, 0.07] NULL 0.06[-0.02, 0.14] -0.03[-0.09, 0.03] NULL MARS NULL NULL NULL -0.13[-0.23, -0.03] NULL ROS -0.08[-0.14, -0.01] 0.04[-0.04, 0.11] 0.08[0.01, 0.15] -0.00[-0.07, 0.06] -0.01[-0.08, 0.07] SATSA 0.03[-0.07, 0.12] -0.20[-0.31, -0.09] -0.14[-0.24, -0.05] -0.07[-0.16, 0.02] 0.31[0.17, 0.45] 4.2.1.7.1.3 Heterogeneity Estimates This header is here to simply emphasize that this method does not provide heterogeneity estimates because it does not provide study-specific estimates, unlike Methods 2b, 3, and 4. 4.2.1.7.1.4 All Model Terms ipd2a_mod_tab &lt;- nested_ipd2a_reg %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate, term) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd2a_mod_tab_fun &lt;- function(d, type, out, moder, cov){ print(paste(type, out, moder, cov)) md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- if(md == &quot;none&quot;) &quot;2A Pooled One Stage Models with Dummy Codes: All Model Estimates of Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;2A Pooled One Stage Models with Dummy Codes: All Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) # kable the table tab &lt;- d %&gt;% arrange(term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs, escape = F) # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/2a_ipd_dc/%s/tables/all terms/%s-%s-%s.html&quot; , local_path, type, o, md, cv)) return(tab) # return the html table } ipd2a_mod_tab &lt;- ipd2a_mod_tab %&gt;% filter(!Moderator %in% stdyModers$long_name) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ipd2a_mod_tab_fun)) ## [1] &quot;Bayesian Crystallized Ability None Unadjusted&quot; ## [1] &quot;Bayesian Crystallized Ability None Age&quot; ## [1] &quot;Bayesian Crystallized Ability None Gender&quot; ## [1] &quot;Bayesian Crystallized Ability None Education&quot; ## [1] &quot;Bayesian Crystallized Ability None Fully Adjusted&quot; ## [1] &quot;Bayesian Crystallized Ability Age Unadjusted&quot; ## [1] &quot;Bayesian Crystallized Ability Age Fully Adjusted&quot; ## [1] &quot;Bayesian Crystallized Ability Gender Unadjusted&quot; ## [1] &quot;Bayesian Crystallized Ability Gender Fully Adjusted&quot; ## [1] &quot;Bayesian Crystallized Ability Education Unadjusted&quot; ## [1] &quot;Bayesian Crystallized Ability Education Fully Adjusted&quot; ## [1] &quot;Frequentist Crystallized Ability None Unadjusted&quot; ## [1] &quot;Frequentist Crystallized Ability None Age&quot; ## [1] &quot;Frequentist Crystallized Ability None Gender&quot; ## [1] &quot;Frequentist Crystallized Ability None Education&quot; ## [1] &quot;Frequentist Crystallized Ability None Fully Adjusted&quot; ## [1] &quot;Frequentist Crystallized Ability Age Unadjusted&quot; ## [1] &quot;Frequentist Crystallized Ability Age Fully Adjusted&quot; ## [1] &quot;Frequentist Crystallized Ability Gender Unadjusted&quot; ## [1] &quot;Frequentist Crystallized Ability Gender Fully Adjusted&quot; ## [1] &quot;Frequentist Crystallized Ability Education Unadjusted&quot; ## [1] &quot;Frequentist Crystallized Ability Education Fully Adjusted&quot; 4.2.1.7.2 Figures 4.2.1.7.2.1 Overall Forest ipd2a_fx_plot_fun &lt;- function(df, mod, type, cov){ print(paste(mod, type, cov)) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- if(d &gt; .01) round(c(0-d-(d/5), 0, 0+d+(d/5)),2) else round(c(0-d-(d/5), 0, 0+d+(d/5)),3) # lim_high &lt;- lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, m)} titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cv, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cv, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- df %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high)) %&gt;% ggplot(aes(x = Outcome, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(1.8, 1.3)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;blue&quot;, &quot;black&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .25, color = &quot;gray50&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL , y = &quot;Estimate (POMP)&quot; , title = titl , subtitle = &quot;Method 2A: Pooled Regression Using Dummy Codes&quot;) + guides(shape = &quot;none&quot;, color = &quot;none&quot;) + facet_grid(~Trait, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(df$Outcome)); ht2 &lt;- length(unique(df$term)) local_path &lt;- length(unique(df$Trait)) ggsave(file = sprintf(&quot;%s/results/2a_ipd_dc/%s/figures/overall forest/%s_%s_fixed.png&quot;, local_path, type, mod, cov), width = local_path*2, height = ht+ht2) rm(p) gc() return(T) } nested_ipd2a_reg %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% select(-rx) %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), sig = factor(sig, levels = c(&quot;sig&quot;,&quot;ns&quot;)), Trait = factor(Trait, levels = traits$short_name), Outcome = factor(Outcome, levels = outcomes$short_name, labels = str_wrap(outcomes$long_name, 15)), Outcome = forcats::fct_rev(Outcome)) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(pmap(list(data, Moderator, type, Covariate), possibly(ipd2a_fx_plot_fun, NA_real_))) 4.2.1.7.2.2 Study-Specific Forest ipd2a_rx_plot_fun &lt;- function(df, outcome, mod, type, cov, trait){ print(paste(outcome, mod)) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- round(c(0-d-(d/5), 0, 0+d+(d/5)),2) lab &lt;- str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){trt} else {sprintf(&quot;%s x %s&quot;, trt, m)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} df &lt;- df %&gt;% full_join(tibble(study = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) stds &lt;- df$study[!df$study %in% c(&quot; Overall&quot;, &quot; &quot;)] df &lt;- df %&gt;% mutate(study = factor(study, rev(c(&quot; &quot;, stds, &quot; Overall&quot;))) # , conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low) # , conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot;, &quot;no&quot;) , ub = ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;no&quot;) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) # , study = factor(study, levels = str_remove_all(c(&quot;Overall&quot;, studies_long), &quot;-&quot;), labels = c(&quot;Overall&quot;, studies_long)) # Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), , type = ifelse(study == &quot; Overall&quot;, &quot;fixed&quot;, &quot;random&quot;)) p1 &lt;- df %&gt;% ggplot(aes(x = study, y = estimate)) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high) , position = &quot;dodge&quot; , width = .2) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(ub == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + annotate(&quot;rect&quot;, xmin = length(stds) + 1.6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = &quot; &quot; ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1)) d2 &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high) , ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^0.&quot;, &quot;.&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^-0.&quot;, &quot;-.&quot;)) %&gt;% mutate(est = ifelse(study != &quot; &quot;, sprintf(&quot;%s [%s, %s] &quot;, estimate, conf.low, conf.high), &quot;&quot;) , n = as.character(n) ) %&gt;% select(study, n, est) %&gt;% pivot_longer(cols = c(n, est), names_to = &quot;est&quot;, values_to = &quot;value&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = study, y = est)) + geom_text(aes(label = value), hjust = .5, size = 3.5) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(stds) + 1.75, y = &quot;est&quot;, hjust = .5, vjust = 0) + annotate(&quot;text&quot;, label = &quot;N&quot;, x = length(stds) + 1.75, y = &quot;n&quot;, hjust = .5, vjust = 0) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + coord_flip() + theme_void() + theme(plot.title = element_text(face = &quot;bold&quot;, hjust = 0) , axis.text = element_blank() , axis.ticks = element_blank() , axis.title = element_blank()) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size - 2 ) p3 &lt;- cowplot::plot_grid(p1, p2 , rel_widths = c(.5, .5)#c(.4, .6) , axis = &quot;tblr&quot; , align = &quot;h&quot; ) # p &lt;- cowplot::plot_grid(ttl, subttl, p3, rel_heights = c(.05, .05, .9), nrow = 3) p &lt;- cowplot::plot_grid(ttl, p3, rel_heights = c(.05, .95), nrow = 2) gc() save(p , file = sprintf(&quot;%s/results/2a_ipd_dc/%s/figures/study specific forest/rdata/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) return(p) } ## fixed effects nested_ipd2a_reg_fp &lt;- nested_ipd2a_reg %&gt;% filter(Moderator %in% moders$short_name) %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% mutate(study = &quot; Overall&quot;) %&gt;% ## random effects full_join( nested_ipd2a_reg %&gt;% filter(Moderator %in% moders$short_name) %&gt;% mutate(rx = map2(rx, n, ~(.x) %&gt;% full_join(.y))) %&gt;% select(-fx, -n) %&gt;% unnest(rx) %&gt;% mutate(study = mapvalues(study, c(&quot;OCTOTWIN&quot;, &quot;BASEI&quot;), c(&quot;OCTO-Twin&quot;, &quot;BASE&quot;)) , study = mapvalues(study, studies_long, studies_sp, warn_missing = F)) # mutate(term = ifelse(Moderator != &quot;none&quot;, paste(term, mapvalues(Moderator, moders$short_name, moders$short_term, warn_missing = F), sep = &quot;:&quot;), term)) ) %&gt;% ## filter key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, type, Covariate, Trait) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, type, Covariate, Trait), ipd2a_rx_plot_fun)) ipd2a_rx_plot_comb_fun &lt;- function(outcome, cov, mod, type, d){ o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) titl &lt;- paste0(o, &quot;,&quot;) titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(titl, cv, &quot;Adjusted&quot;, collapse = &quot;, &quot;) else paste(titl, cv, collapse = &quot;, &quot;) p1 &lt;- plot_grid( d$p[[1]] , d$p[[2]] , d$p[[3]] , d$p[[4]] , d$p[[5]] , nrow = 3 , ncol = 2 , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) my_theme &lt;- function(...) { theme_classic() + theme(plot.subtitle = element_text(hjust = 0)) } subtitle_theme &lt;- calc_element(&quot;subplot.title&quot;, my_theme()) subttl &lt;- ggdraw() + draw_label( &quot;Method 2A: Pooled Regression Using Dummy Codes&quot;, fontfamily = subtitle_theme$family, fontface = subtitle_theme$face, size = subtitle_theme$size ) p &lt;- cowplot::plot_grid(ttl, subttl, p1, rel_heights = c(.03, .03, .94), nrow = 3) ggsave(p , file = sprintf(&quot;%s/results/2a_ipd_dc/%s/figures/study specific forest/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) ggsave(p , file = sprintf(&quot;%s/results/2a_ipd_dc/%s/figures/study specific forest/%s_%s_%s.pdf&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) return(T) } nested_ipd2a_reg_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(Trait) %&gt;% select(-data) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(Outcome, Covariate, Moderator, type, data), ipd2a_rx_plot_comb_fun)) 4.2.1.7.2.3 Overall Simple Effects loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/2a_ipd_dc/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd2a_simp &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/2a_ipd_dc/%s/predicted&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), pred.fx = map2(file, type, ~loadRData(.x, .y, &quot;pred.fx&quot;, &quot;predicted&quot;)), pred.rx = map2(file, type, ~loadRData(.x, .y, &quot;pred.rx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) nested_ipd2a_simp ipd2a_se_plot_fun &lt;- function(df, outcome, mod, type, cov){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) # mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) # maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) # lim &lt;- c(mini, maxi) # brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} # lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; df &lt;- df %&gt;% unclass %&gt;% data.frame df$mod_value &lt;- df[,mod] df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(df$mod_value) == &quot;factor&quot;){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} else{df &lt;- df %&gt;% group_by(Trait) %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() } lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(df$mod_fac))] df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), lower = ifelse(lower &lt; 4, 4, lower), upper = ifelse(upper &gt; 10, 10, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = mod_fac)) + scale_y_continuous(limits = c(4,10) , breaks = c(4, 6, 8, 10) , labels = c(4, 6, 8, 10)) + scale_linetype_manual(values = lt) + geom_ribbon(aes(ymin = lower , ymax = upper , fill = mod_fac) , alpha = .25) + geom_line(aes(linetype = mod_fac)) + labs(x = &quot;Personality (POMP)&quot; , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = m , fill = m , subtitle = &quot;Method 2A: Pooled Regression Using Dummy Codes&quot;) + facet_wrap(~Trait, nrow = 3) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/2a_ipd_dc/%s/figures/overall simple effects/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov), width = 6, height = 6) } ipd2a_se_plot &lt;- nested_ipd2a_simp %&gt;% select(-pred.rx) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.fx)), plot = pmap(list(data, Outcome, Moderator, type, Covariate), ipd2a_se_plot_fun)) 4.2.1.7.2.4 Study-Specific Simple Effects ipd2a_std_se_plot_fun &lt;- function(df, outcome, trait, mod, cov, type){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) # mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) # maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) # lim &lt;- c(mini, maxi) # brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} # lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; df &lt;- df %&gt;% mutate(study = mapvalues(study, c(&quot;BASEI&quot;, &quot;OCTOTWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) df &lt;- df %&gt;% unclass %&gt;% data.frame df$mod_value &lt;- df[,mod] df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(df$mod_value) == &quot;factor&quot;){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} else{df &lt;- df %&gt;% group_by(study) %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() } # lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(df$mod_fac))] std &lt;- unique(df$study) cols &lt;- (stdcolors %&gt;% filter(studies %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies %in% std))$lt ht &lt;- length(unique(df$mod_fac)) df %&gt;% as_tibble() %&gt;% mutate(gr = ifelse(study == &quot;Overall&quot;, &quot;Overall&quot;, &quot;study&quot;)) %&gt;% group_by(p_value, mod_fac, study, gr) %&gt;% summarize_at(vars(pred, lower, upper), mean, na.rm = T) %&gt;% mutate(study = factor(study , levels = c(&quot;Overall&quot;, studies_long), , labels = c(&quot;Overall&quot;, studies_long)), lower = ifelse(lower &lt; 4, 4, lower), upper = ifelse(upper &gt; 10, 10, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = study)) + scale_y_continuous(limits = c(4,10) , breaks = c(4, 6, 8, 10) , labels = c(4, 6, 8, 10)) + scale_linetype_manual(values = lt) + scale_color_manual(values = cols) + scale_size_manual(values = c(2,.8)) + # geom_ribbon(aes(ymin = lower # , ymax = upper # , fill = study) # , alpha = .25) + geom_line(aes(linetype = study, color = study, size = gr)) + labs(x = paste(trt, &quot;(POMP)&quot;) , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = &quot;Study&quot; , fill = &quot;Study&quot; , color = &quot;Study&quot; , subtitle = &quot;Method 2A: Pooled Regression Using Dummy Codes&quot;) + guides(size = &quot;none&quot;) + facet_wrap(~mod_fac, nrow = 1) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/2a_ipd_dc/%s/figures/study specific simple effects/%s_%s_%s_%s.png&quot;, local_path, type, outcome, trt, mod, cov), width = 3*ht, height = 5) } nested_ipd2a_simp %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% mutate(pred.fx = map(pred.fx, ~(.) %&gt;% mutate(study = &quot;Overall&quot;)), comb.fx = map2(pred.fx, pred.rx, full_join)) %&gt;% select(-pred.fx, -pred.rx) %&gt;% mutate(pmap(list(comb.fx, Outcome, Trait, Moderator, Covariate, type), possibly(ipd2a_std_se_plot_fun, NA_real_))) 4.2.1.8 Sample Results Section We examined estimates of overall prospective associations between Big Five personality characteristics and crystallized abilities as well as participant-level moderators of those associations using fully pooled, one-stage regression models with effects codes to capture sample-specific estimates using individual participant data in 11 studies. Heterogeneity was indirectly estimated by extracting sample-level estimates of associations and examining dispersion measures. Table S3 presents the fully adjusted estimates of the key terms from all prospective Big Five personality characteristic-crystallized abilities associations and participant-level moderators of those associations. Across the 20 key terms, four (20%) were significant. For unmoderated personality-cognition associations, neuroticism (-) and openness (+) were significantly associated with later crystallized abilities. In other words, higher neuroticism was prospectively associated with lower crystallized abilities across samples, while higher openness was prospectively associated with higher crystallized abilities across samples. Table 4.2: 2A Pooled One Stage Models with Dummy Codes: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.02[-0.01, 0.05] -0.01[-0.04, 0.02] 0.01[-0.02, 0.04] -0.07[-0.09, -0.05] 0.17[0.14, 0.21] Age Age -0.00[-0.01, 0.00] -0.000[-0.00, 0.00] -0.00[-0.01, 0.001] 0.00[-0.000, 0.01] 0.000[-0.00, 0.01] Gender Gender (Male v Female) 0.06[0.001, 0.12] 0.02[-0.04, 0.08] -0.00[-0.06, 0.05] -0.04[-0.09, 0.01] -0.01[-0.08, 0.06] Education Education (Years) -0.00[-0.01, 0.01] -0.00[-0.02, 0.01] 0.01[-0.001, 0.02] -0.00[-0.01, 0.01] -0.00[-0.02, 0.01] In addition to the overall effects, we also examined those same effects at the sample level. Figure S3 presents the forest plot of fully adjusted sample-specific and overall prospective associations between the Big Five and crystallized abilities across all methods. Forest plots for all participant-level moderators are available in the online materials and the web app. As shown in the forest plot, openness was most consistently associated with crystallized ability, with five of seven samples showing a positive and significant prospective association between openness and crystallized abilities. Other associations, such as those with extraversion and conscientiousness, were less consistent, with at least one significant association in different directions across samples. For example, although there was no overall association between conscientiousness and crystallized abilities, SATSA showed a significant negative association, and HILDA, ROS, and HRS showed positive associations. Figure 4.1: Figure S3. Forest plot of fully adjusted prospective associations between Big Five personality characteristics and crystallized abilities across samples for using one-stage pooled integrative data analysis via effects coded contrasts. Overall point estimates (squares) represent the grand-mean estimates of the association across samples, while sample point estimates represent regression terms or linear combinations of regression terms. Error bars capture the 95% CI around the point estimate. Arrows indicate the confidence band was truncated to better visualize the estimates. Finally, we also examined the consistency of simple effects across samples for each moderator. Figure S4 displays the fully adjusted predicted crystallized abilities levels at different levels of extraversion across samples for those who identified as male or female. The pattern suggests a positive association for females and null association for males. This holds for females in EAS (b = 0.22, 95% CI [0.09, 0.34]) and GSOEP (b = 0.14, 95% CI [0.02, 0.25]), while all other samples demonstrate null associations. For men, the associations seem somewhat less consistent, with three samples demonstrating significant negative associations (HILDA, b = -0.04, 95% CI [-0.08, -0.005]; HRS, b = -0.04, 95% CI [-0.08, -0.006]; ROS, b = -0.08, 95% CI [-0.16, -0.008]) one sample demonstrating a positive association (EAS, b = 0.16, 95% CI [0.03, 0.29]), and four samples demonstrating null associations (GSOEP, b = 0.08, 95% CI [-0.04, 0.19]; MAP, b = 0.009, 95% CI [-0.06, 0.08]; OCTO-Twin, b = 0.08, 95% CI [-0.07, 0.22]; BASE, b = -0.14, 95% CI [-0.37, 0.10]). Figure 4.2: Figure S4. Prospective sample-specific and overall associations between extraversion (in POMP units, 0-10) and crystallized abilities (in POMP units, 0-10) across genders (male, female). Different colors and line types indicate different samples. Thicker, black lines indicate the average association across samples, while thinner lines indicate sample-specific associations. rm(list = ls()[grepl(&quot;ipd2a&quot;, ls())]) 4.2.2 Method 2B: Pooled One Stage Models with Random Effects For Method 2B, we’ll be estimating overall and study-specific effects using multilevel models in which participants are nested within studies. In a basic sense, these differ from using dummy codes in that those models are estimated using OLS, while multilevel models are estimated using maximum likelihood. In addition, unlike OLS, linear models, ML MLM treats nesting units as a distribution centered around the overall effect and shrinks random effects toward 0. 4.2.2.1 Analytic Plan In the present study, we estimate associations between the Big Five personality traits and crystallized cognitive abilities using a one-stage, fully pooled, multilevel regression approach with participants nested within sample using individual participant data. The procedure is as follows: 4.2.2.1.1 Statistical Modeling Models are estimated separately for each personality characteristic, outcome, covariate, and moderator combination. Because these multilevel models provide both sample-specific estimates and estimates of cross-sample heterogeneity, we created a series of functions in the R programming language to (1) set up and run the model and extract model coefficients and (2) extract overall simple-effects predictions for participant- and sample-level moderator models (i.e. predicted values across levels of the moderator values), (3) extract the sample-specific effects, (4) extract sample-specific simple-effects prediction for the participant-level moderators, and (5) extract estimates of heterogeneity. Each of these functions were designed to flexibly handle different classes of covariates and moderators (e.g., nominal, numeric) and to wrangle the results into easily combined and understandable data frames. The functions and more detail on them can be found in the online materials. The simple unadjusted personality characteristic-crystallized abilities model is as follows: Level 1 \\(Y_{ij}=\\beta_{0J}+\\beta_{1J}*predictor_{ij}+\\epsilon_{ij}\\) Level 2 \\(\\beta_{0j}=\\gamma_{00}+u_{0j}\\) \\(\\beta_{1J}=\\gamma_{10}+u_{1j}\\) \\(\\epsilon_{ij}\\sim\\mathcal{N}\\left(0,\\sigma^2\\right)\\) \\(\\begin{matrix}u_{0j}\\\\\\ u_{1j}\\\\\\end{matrix}\\ \\sim\\mathcal{N}\\left(\\begin{matrix}\\tau_{00}^2\\ \\ &amp;\\tau_{10}\\\\\\ \\tau_{10}&amp;\\tau_{11}^2\\\\\\end{matrix}\\ \\right)\\), where the prospective associations for each sample will be captured by \\(\\beta_{1j}\\), \\(j\\) indicates each sample 1 to \\(j\\), and \\(u_{1j}\\) captures the sample specific deviation from the overall estimate of the personality-cognition relationship \\(\\gamma_{10}\\). The multilevel models decompose the residual variance into different sources, in this case, participant-level residual variance (\\(\\sigma^2\\)) and sample-level residual variance (\\(\\tau_{00}^2\\) and \\(\\tau_{11}^2\\)). The models also use partial pooling, which pools information across samples and shrinks sample-level estimates toward the fixed effect. Participant-level moderators will be added at Level 1 with random effects at Level 2. For example, two new Level 1 terms were added for baseline age (centered at 60): \\(\\beta_{2J}\\), which indicates the sample-specific estimate of the main effect of age, and \\(\\beta_{3J}\\), which indicates the difference in the sample-specific estimate of the prospective personality-outcome association as a function of age. For each, we will include random slopes (\\(u_{2j}\\) and \\(u_{3j}\\)) to allow these to vary across samples. The overall main effect of the moderator and the moderator estimate will be captured by \\(\\gamma_{20}\\) and \\(\\gamma_{30}\\), respectively. Heterogeneity estimates are captured in \\(\\tau\\) matrix, where \\(\\tau_{00}^2\\) captures the variance in the random intercepts (i.e. variance in average levels of cognitive ability across samples), \\(\\tau_{11}^2\\) captures the variance in random slope (i.e. variance in the personality-cognitive ability association across samples), and \\(\\tau_{01}\\) captures the correlation between average levels of cognitive ability and personality-cognitive ability associations across samples (e.g., is the association stronger in samples with higher average crystallized ability). Moderators, but not covariates, were included as random slopes and allowed to covary with other random terms. Models were tested using the lme4 package in R, and the tidy() function from the broom.mixed package to extract model coefficients and confidence intervals (CI) of fixed effects and heterogeneity estimates. . In order to extract the random effects (i.e. Level 2 variances) and interval estimates, the effects argument was set to \"ran_pars,\" the conf.int argument was set to TRUE, the conf.method argument was set to \"boot\", and the n.sim argument was set to 500. Inferences were made based on the 95% bootstrapped confidence intervals. As before, overall simple-effects predictions were calculated by providing the full range of personality (0-10) and average levels of the covariates from the data used to estimate the model as the \"newdata\" argument, and setting the \"re.form\" argument as FALSE in the lme4 predict.merMod() function in conjunction with the bootMer() function to provide intervals around the estimates. For sample-specific effects, averages and levels of covariates were determined using data from each sample separately and provided to the lme4 predict.merMod() function as \"newdata.\" 4.2.2.2 Model Function The first thing we need is a function that will bring in the data, create a formula in the model based on input on the type (Frequentist or Bayesian), moderators (none, age, gender, and education), and combinations of covariates (single or fully adjusted based on age, gender, and education). This case is slightly less complicated than the case of dummy codes, because we simply include study as the nesting unit and personality effect of the personality and moderator effect as random slopes. This results in a intercept and target effect for each study without the need to build contrasts. Then we run the model, extract its fixed and study-specific effect estimates, and save both for later. By saving the results, it will make it easier and faster for us to extract the necessary model results later while still retaining all information from the original model. ipd2b_mod_fun &lt;- function(trait, outcome, type, mod, cov){ ## load the data load(sprintf(&quot;%s/data/one_stage/%s_%s.RData&quot;, local_path, trait, outcome)) ## compiled Bayesian model to speed up processing and avoid crashing if(type == &quot;Bayesian&quot;) load(sprintf(&quot;%s/results/2b_ipd_mlm/bayes_sample_mod.RData&quot;, local_path)) ## formula if (cov == &quot;all&quot;) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if (!cov %in% c(&quot;all&quot;, &quot;none&quot;)) cv &lt;- cov rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;none&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;){rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;))} re &lt;- if(mod == &quot;none&quot; | mod %in% stdyModers$short_name) &quot;(p_value | study)&quot; else paste(paste(&quot;(p_value&quot;, mod, sep = &quot; * &quot;), &quot;| study)&quot;) rhs &lt;- paste(c(rhs, re), collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## run the models &amp; save m &lt;- if(type == &quot;Frequentist&quot;){lmer(f, data = d)} else {update(m, formula = f, newdata = d, iter = 2000 , warmup = 1000)} save(m, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/models/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) rx &lt;- std_eff_fun(m, type) save(fx, rx, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/summary/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) ## extract heterogeneity estimates het &lt;- ipd2b_hetero_fun(m, type) save(het, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/heterogeneity/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) ## simple effects for moderators if(mod != &quot;none&quot;){ pred.fx &lt;- ipd2b_fx_pred_fun(m, mod, type) pred.rx &lt;- if(mod %in% stdyModers$short_name) NULL else ipd2b_rx_pred_fun(m, mod, type) save(pred.fx, pred.rx, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/predicted/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;rhs&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;rx&quot;, &quot;het&quot;)) gc() } 4.2.2.3 Study-Specific Effects Function As noted previously, once we run the model, we will have to use a second step to get the study-specific estimates for all studies. Unlike with dummy codes, doing so is much more straightforward. We just have to pull study-specific effects using the coef() for both Bayesian and Frequentist approaches. However, to get confidence intervals for Frequentist approaches, we will additionally have to use the standard_error() function from the parameters package to get standard errors. std_eff_fun &lt;- function(m, type){ if(type == &quot;Frequentist&quot;){ # coef function gives fixed + random effect estimates but not SE&#39;s # so we&#39;ll take those estimates and get their SE&#39;s from the parameters package coef(m)$study %&gt;% data.frame() %&gt;% rownames_to_column(&quot;study&quot;) %&gt;% mutate(term = &quot;estimate&quot;) %&gt;% full_join( parameters::standard_error(m, effects = &quot;random&quot;)$study %&gt;% data.frame() %&gt;% rownames_to_column(&quot;study&quot;) %&gt;% mutate(term = &quot;SE&quot;)) %&gt;% rename(Intercept = X.Intercept.) %&gt;% # select(study, term, , p_value) %&gt;% pivot_longer(c(-study, -term), names_to = &quot;names&quot;, values_to = &quot;estimate&quot;) %&gt;% pivot_wider(names_from = &quot;term&quot;, values_from = &quot;estimate&quot;) %&gt;% rename(term = names) %&gt;% mutate(conf.low = estimate - 2*SE, conf.high = estimate + 2*SE, term = ifelse(grepl(&quot;p_value.&quot;, term), str_replace_all(term, &quot;p_value.&quot;, &quot;p_value:&quot;), term)) } else { coef(m, probs = c(0.025, 0.975))[[1]] %&gt;% array_tree(3) %&gt;% tibble(term = names(.), data = .) %&gt;% mutate(data = map(data, ~(.) %&gt;% data.frame %&gt;% rownames_to_column(&quot;study&quot;))) %&gt;% unnest(data) %&gt;% select(term, study, estimate = Estimate, conf.low = Q2.5, conf.high = Q97.5) } } 4.2.2.4 Heterogeneity Estimates Function The Final pieces of information we need to extract from these models are estimates of the heterogeneity of effects across studies. ipd2b_hetero_fun &lt;- function(m, type){ args &lt;- list(x = m, effects = &quot;ran_pars&quot;, conf.int = T) if(type == &quot;Frequentist&quot;)args$conf.method = &quot;boot&quot;; args$nsim &lt;- 100; args$parallel = &quot;multicore&quot;; args$ncpus = 4 do.call(tidy, args) %&gt;% select(group, term, estimate, conf.low, conf.high) %&gt;% separate(term, c(&quot;est&quot;, &quot;term&quot;), sep = &quot;__&quot;) %&gt;% mutate_at(vars(estimate:conf.high), ~ifelse(est == &quot;sd&quot;, .^2, .)) %&gt;% mutate(est = ifelse(est == &quot;sd&quot;, &quot;var&quot;, est)) } 4.2.2.5 Simple Effects Function 4.2.2.5.1 Fixed Effects predIntlme4 &lt;- function(m, mod_frame, ref){ b &lt;- bootMer(m , FUN = function(x) lme4:::predict.merMod(x, newdata = mod_frame , re.form = ref) , nsim = 100 , parallel = &quot;multicore&quot; , ncpus = 8 ) ci &lt;- apply(b$t, 2, quantile, probs = c(.05/2, 1 - .05/2)) %&gt;% t() data.frame(pred = b$t0, ci) %&gt;% setNames(c(&quot;pred&quot;, &quot;lower&quot;, &quot;upper&quot;)) %&gt;% as_tibble() } ipd2b_fx_pred_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m@frame d &lt;- d %&gt;% select(-o_value, -p_value, -study) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_vars &lt;- colnames(d)[sapply(d, class) == &quot;factor&quot;] fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(levels(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { (fct_lev %&gt;% select(one_of(moder)) %&gt;% unnest(one_of(moder)) %&gt;% data.frame())[,moder] } mod_frame &lt;- expand.grid( p_value = seq(0,10,.5) , modvalue = md_levs , stringsAsFactors = F ) %&gt;% setNames(c(&quot;p_value&quot;, moder)) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)[1])) } } pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m , newdata = mod_frame , re_formula = NA) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, predIntlme4(m, mod_frame, NA) ) #%&gt;% # select(one_of(colnames(m@frame)), pred, lower, upper) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 4.2.2.5.2 Study-Specific Effects ipd2b_rx_pred_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m@frame d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% pivot_longer(-study , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(study, item) %&gt;% summarize_at(vars(value), lst(mean, sd), na.rm = T) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_vars &lt;- colnames(d)[sapply(d %&gt;% select(-study), class) == &quot;factor&quot;] fct_lev &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) %&gt;% ungroup() #%&gt;% # unnest(one_of(fct_vars)) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { (fct_lev %&gt;% select(one_of(moder)) %&gt;% unnest(one_of(moder)) %&gt;% data.frame())[,moder] } mod_frame &lt;- if(md_cl == &quot;numeric&quot;) { crossing( p_value = seq(0,10,.5), modvalue = md_levs, study = unique(d$study) ) %&gt;% setNames(c(&quot;p_value&quot;, moder, &quot;study&quot;))#%&gt;% full_join( # msd %&gt;% # filter(item == moder) %&gt;% # mutate(lower = mean - sd, upper = mean + sd) %&gt;% # select(-sd) %&gt;% # pivot_longer(cols = c(mean, lower, upper) # , names_to = &quot;meas&quot; # , values_to = &quot;modvalue&quot;) %&gt;% # pivot_wider(names_from = &quot;item&quot;, values_from = &quot;modvalue&quot;) %&gt;% # select(study, one_of(moder)) # ) } else { crossing( p_value = seq(0,10,.5) , mod_value = md_levs#unique(fct_lev[,moder][[1]]) , study = unique(d$study) ) %&gt;% setNames(c(&quot;p_value&quot;, moder, &quot;study&quot;)) } if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean, na.rm = T) %&gt;% ungroup() %&gt;% full_join(mod_frame) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.factor) %&gt;% summarize_all(levels) %&gt;% ungroup() %&gt;% full_join(mod_frame) } } pred.rx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m , newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, tibble(pred = predict(m, newdata = mod_frame))#predIntlme4(m, mod_frame, NULL) ) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;)) gc() return(pred.rx) } 4.2.2.6 Run Models and Summaries # Sample Bayesian Model # load data load(sprintf(&quot;%s/data/one_stage/N_crystallized.RData&quot;, local_path)) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = F)))) %&gt;% unnest(data) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;cauchy(0,1)&quot;, class = &quot;sd&quot;), set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- formula(o_value ~ p_value*age + gender + education + (age*p_value | study)) m &lt;- brm(formula = f , data = d , prior = Prior , iter = Iter , warmup = Warmup , cores = 4) save(m, file = sprintf(&quot;%s/results/2b_ipd_mlm/bayes_sample_mod.RData&quot;, local_path)) rm(list = c(&quot;d&quot;, &quot;Prior&quot;, &quot;Iter&quot;, &quot;Warmup&quot;, &quot;treedepth&quot;, &quot;f&quot;, &quot;m&quot;)) # done &lt;- tibble(type = c(&quot;Bayesian&quot;, &quot;Frequentist&quot;), # file = map(type, ~list.files(sprintf(&quot;%s/results/2b_ipd_mlm/%s/predicted&quot;, local_path, .)))) %&gt;% # unnest(file) %&gt;% # separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;) %&gt;% # mutate(Covariate = str_remove_all(Covariate, &quot;.RData&quot;) # , done = &quot;done&quot;) %&gt;% # filter(!is.na(Covariate)) nested_ipd_reg &lt;- crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) , Covariate = c(&quot;none&quot;, &quot;all&quot;) ) %&gt;% full_join( crossing( Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;none&quot;, stdyModers$short_name) , Covariate = c(&quot;none&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;all&quot;) ) ) %&gt;% # full_join(done) %&gt;% filter(is.na(done) &amp; type != &quot;Frequentist&quot;) %&gt;% filter(Moderator %in% c(&quot;age&quot;, &quot;education&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;, &quot;predInt&quot;)) %&gt;% filter(Trait == &quot;N&quot; &amp; type == &quot;Frequentist&quot;) mutate(run = pmap(list(Trait, Outcome, type, Moderator, Covariate), ipd2b_mod_fun)) nested_ipd_reg %&gt;% write.table(. , file = sprintf(&quot;%s/scripts/cluster/args/frequentist/ipd2b_frequentist_pred.txt&quot;, local_path) , row.names = F) 4.2.2.7 Compile Results Once all the models are run, we are ready to compile all their results. By saving the fixed and study-level effects results previously, we are able to simply load those results and ignore the models. However, because we also saved the models, we can also recall and extract information from them if and when needed. loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/2b_ipd_mlm/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } n_fun &lt;- function(fileName, type){ m &lt;- loadRData(fileName, type, &quot;^m&quot;, &quot;models&quot;) d &lt;- if(type == &quot;Bayesian&quot;) m$data else m@frame n &lt;- d %&gt;% group_by(study) %&gt;% tally() %&gt;% ungroup() return(n) } fix_terms &lt;- function(rx){ if(!&quot;term&quot; %in% colnames(rx)) rx &lt;- rx %&gt;% mutate(term = names) return(rx) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd2b_reg &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/2b_ipd_mlm/%s/summary&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), fx = map2(file, type, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;)), rx = map2(file, type, possibly(~loadRData(.x, .y, &quot;rx&quot;, &quot;summary&quot;), NA_real_)), n = map2(file, type, n_fun)) %&gt;% select(-file) %&gt;% filter(!is.na(rx)) %&gt;% mutate(rx = map(rx, fix_terms)) 4.2.2.7.1 Tables Next, we want to format the study results in APA table format. In this case, we are interested in the fixed and study-specific effects of personality predicting cognitive ability when there were no moderators, and the personality x moderator interaction when there was a moderator. We’ll anticipate a need to present both just fixed effects as well as fixed and study-specific effects by creating tables for each. First, let’s format the data. ipd2b_reg_tab &lt;- ### fixed effects nested_ipd2b_reg %&gt;% select(-rx) %&gt;% unnest(fx) %&gt;% # unnesting # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term)) &amp; !grepl(&quot;cor&quot;, term) &amp; !grepl(&quot;sd&quot;, term)) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ### study specific effects full_join( nested_ipd2b_reg %&gt;% select(-fx) %&gt;% unnest(rx) %&gt;% # unnesting mutate(term = ifelse(is.na(term), names, term)) %&gt;% select(-names) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) ) %&gt;% # reformatting: mark significance, prettify Trait, covariate, and moderator names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, c(&quot;scaleBFIMS&quot;, &quot;scaleIPIPNEO&quot;, &quot;scaleTDAM40&quot;, &quot;countryTheNetherlands&quot;, &quot;scaleBFI.S&quot;, &quot;scaleIPIP.NEO&quot;, &quot;scaleTDA.40&quot;, &quot;countryThe.Netherlands&quot;) , c(&quot;scaleBFI-S&quot;, &quot;scaleIPIP NEO&quot;, &quot;scaleTDA-40&quot;, &quot;countryThe Netherlands&quot;, &quot;scaleBFI-S&quot;, &quot;scaleIPIP NEO&quot;, &quot;scaleTDA-40&quot;, &quot;countryThe Netherlands&quot;)), term = factor(term, c(moders$short_term, stdyModers$short_term), c(moders$long_term, stdyModers$long_term))) %&gt;% # prettify the number format mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .0014, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% # combine the effects, bold significance, factor and label study-specfic effects mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est), study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;)), study = factor(study, levels = c(studies_long, &quot;Overall&quot;), labels = c(studies_long, &quot;Overall&quot;))) %&gt;% # reshaping: remove extra columns, arrange by key variables, and make wide select(type, Outcome, Trait, Moderator, Covariate, study, term, est) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate, study, term, est) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd2b_reg_tab ## # A tibble: 1,824 × 11 ## type Outcome Moderator Covariate study term E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bayesian Crystallized Ability None Unadjusted BASE Personality 0.05&lt;br&gt;[-0.04, 0.16] &lt;NA&gt; &lt;NA&gt; &lt;str… &lt;str… ## 2 Bayesian Crystallized Ability None Unadjusted EAS Personality &lt;strong&gt;0.10&lt;br&gt;[0.04, 0… 0.02… 0.02… &lt;str… &lt;str… ## 3 Bayesian Crystallized Ability None Unadjusted GSOEP Personality &lt;strong&gt;0.07&lt;br&gt;[0.03, 0… -0.0… -0.0… &lt;str… &lt;str… ## 4 Bayesian Crystallized Ability None Unadjusted HILDA Personality 0.01&lt;br&gt;[-0.01, 0.04] &lt;str… &lt;str… &lt;str… &lt;str… ## 5 Bayesian Crystallized Ability None Unadjusted HRS Personality 0.001&lt;br&gt;[-0.02, 0.03] &lt;str… &lt;str… &lt;str… &lt;str… ## 6 Bayesian Crystallized Ability None Unadjusted MAP Personality 0.04&lt;br&gt;[-0.01, 0.09] &lt;NA&gt; &lt;str… &lt;str… &lt;NA&gt; ## 7 Bayesian Crystallized Ability None Unadjusted OCTO-Twin Personality 0.05&lt;br&gt;[-0.02, 0.11] &lt;NA&gt; &lt;NA&gt; &lt;str… &lt;NA&gt; ## 8 Bayesian Crystallized Ability None Unadjusted ROS Personality 0.02&lt;br&gt;[-0.05, 0.07] &lt;str… &lt;str… &lt;str… &lt;str… ## 9 Bayesian Crystallized Ability None Unadjusted SATSA Personality 0.04&lt;br&gt;[-0.02, 0.12] &lt;str… &lt;str… &lt;str… &lt;str… ## 10 Bayesian Crystallized Ability None Unadjusted Overall Personality &lt;strong&gt;0.04&lt;br&gt;[0.00, 0… 0.00… 0.04… &lt;str… &lt;str… ## # ℹ 1,814 more rows ipd2b_res &lt;- nested_ipd2b_reg %&gt;% select(-rx) %&gt;% unnest(fx) %&gt;% # unnesting # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term)) &amp; !grepl(&quot;cor&quot;, term) &amp; !grepl(&quot;sd&quot;, term)) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;\\\\textit{b} = %s, 95\\\\%% CI [%s, %s]&quot;, estimate, conf.low, conf.high)) Now that we’ve formatted the values, we can group by moderators and save results as separate tables. Even though additional information could be included given that we have one outcome, we’ll stick with this split because it will make it easier for those using this tutorial who multiple traits, outcomes, covariates, and moderators. 4.2.2.7.1.1 Fixed Effects ## table function ipd2b_tab_fun &lt;- function(d, type, moder){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term)) == 1) rep(1,6) else c(2, rep(1,5)) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$short_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- if(length(unique(d$term)) == 1) c(&quot;Covariates&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) # cln &lt;- if(length(unique(d$term)) == 1) c(&quot;Covariates&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) al &lt;- if(length(unique(d$term)) == 1) c(&quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term)) == 1) d &lt;- d %&gt;% select(-term) cap &lt;- if(md == &quot;none&quot;) &quot;2B Pooled One Stage Models with Random Effects: Overall Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;2B Pooled One Stage Models with Random Effects: Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% arrange(Outcome) %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/tables/overall/%s.html&quot; , local_path, type, md)) return(tab) } ipd2b_fx_tab &lt;- ipd2b_reg_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% select(-study) %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd2b_tab_fun)) # save(ipd2b_reg_tab, ipd2b_res, file = sprintf(&quot;%s/manuscript/results/ipd2b_fx_tab.RData&quot;, res_path)) ## Frequentist (ipd2b_fx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Frequentist&quot;))$tab[[1]] Table 4.4: 2B Pooled One Stage Models with Random Effects: Overall Effects of Personality-Crystallized Domain Associations E A C N O Covariates b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted 0.04[0.01, 0.08] 0.01[-0.08, 0.09] 0.05[-0.03, 0.12] -0.12[-0.15, -0.09] 0.27[0.18, 0.36] Age 0.03[0.01, 0.06] 0.02[-0.08, 0.11] 0.04[-0.04, 0.12] -0.12[-0.16, -0.09] 0.28[0.19, 0.38] Gender 0.03[0.01, 0.06] 0.02[-0.07, 0.11] 0.04[-0.04, 0.12] -0.12[-0.15, -0.09] 0.28[0.18, 0.38] Education 0.01[-0.02, 0.05] 0.01[-0.02, 0.04] 0.02[-0.04, 0.07] -0.06[-0.09, -0.03] 0.16[0.07, 0.25] Fully Adjusted 0.01[-0.02, 0.05] 0.00[-0.03, 0.03] 0.01[-0.04, 0.07] -0.06[-0.09, -0.03] 0.16[0.07, 0.25] ## bayesian (ipd2b_fx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Bayesian&quot;))$tab[[1]] Table 4.4: 2B Pooled One Stage Models with Random Effects: Overall Effects of Personality-Crystallized Domain Associations E A C N O Covariates b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted 0.04[0.00, 0.09] 0.00[-0.13, 0.12] 0.04[-0.07, 0.15] -0.12[-0.16, -0.09] 0.28[0.16, 0.40] Age 0.03[0.00, 0.07] 0.01[-0.11, 0.14] 0.04[-0.07, 0.16] -0.12[-0.16, -0.08] 0.29[0.17, 0.42] Gender 0.03[-0.001, 0.07] 0.01[-0.12, 0.14] 0.04[-0.07, 0.15] -0.12[-0.17, -0.08] 0.28[0.15, 0.43] Education 0.01[-0.03, 0.06] 0.01[-0.06, 0.08] 0.02[-0.06, 0.09] -0.06[-0.10, -0.02] 0.16[0.02, 0.29] Fully Adjusted 0.01[-0.03, 0.06] 0.00[-0.07, 0.07] 0.02[-0.07, 0.09] -0.06[-0.10, -0.03] 0.16[0.04, 0.29] ipd2b_tab_fun &lt;- function(d, type, cov){ # long outcome name covar &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$short_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- sprintf(&quot;2B Pooled One Stage Models with Random Effects: Fixed Effect Estimates of %s Personality-Crystallized Domain Associations&quot;, cov) # kable the table tab &lt;- d %&gt;% select(-Moderator) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/tables/key terms/%s.html&quot; , local_path, type, covar)) return(tab) # return the html table } ipd2b_fx_tab2 &lt;- ipd2b_reg_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% select(-study) %&gt;% arrange(Moderator, term) %&gt;% filter(Covariate %in% c(&quot;Unadjusted&quot;, &quot;Fully Adjusted&quot;)) %&gt;% group_by(Outcome, type, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Covariate), ipd2b_tab_fun)) ## Frequentist, no moderator (ipd2b_fx_tab2 %&gt;% filter(type == &quot;Frequentist&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]] Table 4.5: 2B Pooled One Stage Models with Random Effects: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.01[-0.02, 0.05] 0.00[-0.03, 0.03] 0.01[-0.04, 0.07] -0.06[-0.09, -0.03] 0.16[0.07, 0.25] Age Age 0.001[-0.03, 0.03] 0.000[-0.09, 0.09] -0.001[-0.01, 0.01] 0.00[-0.00, 0.01] 0.001[-0.09, 0.09] Gender Gender (Male v Female) 0.05[0.01, 0.09] 0.02[-0.02, 0.06] 0.01[-0.03, 0.06] -0.02[-0.05, 0.01] -0.000[-0.06, 0.06] Education Education (Years) -0.01[-0.07, 0.06] -0.01[-0.02, 0.01] 0.01[-0.02, 0.04] 0.00[-0.01, 0.01] -0.01[-0.12, 0.09] Continent Continent (North America v Europe) 0.07[0.00, 0.14] -0.12[-0.26, 0.03] -0.12[-0.24, 0.00] -0.03[-0.06, 0.01] 0.14[-0.08, 0.36] Continent (North America v Australia) 0.03[-0.05, 0.10] -0.01[-0.18, 0.15] -0.02[-0.16, 0.11] -0.11[-0.14, -0.08] 0.11[-0.19, 0.40] Country Country (United States v Germany) 0.08[-0.02, 0.18] -0.01[-0.10, 0.08] -0.05[-0.19, 0.09] -0.02[-0.09, 0.05] 0.12[-0.15, 0.38] Country (United States v Sweden) 0.07[-0.03, 0.16] -0.23[-0.35, -0.12] -0.20[-0.34, -0.06] -0.05[-0.11, 0.01] 0.22[-0.13, 0.58] Country (United States v The Netherlands) -0.02[-0.06, 0.03] Country (United States v Australia) 0.02[-0.06, 0.11] -0.01[-0.05, 0.03] -0.02[-0.13, 0.08] -0.11[-0.14, -0.08] 0.11[-0.21, 0.43] Personality Scale Scale (NEO-FFI v DPQ) 0.01[-0.09, 0.11] Scale (NEO-FFI v Eysenck) 0.09[-0.01, 0.18] -0.24[-9.45, 8.97] -0.21[-0.33, -0.10] -0.02[-0.11, 0.08] 0.14[-0.50, 0.77] Scale (NEO-FFI v MIDI) -0.00[-0.08, 0.08] -0.01[-9.22, 9.20] 0.01[-0.06, 0.08] 0.03[-0.06, 0.12] -0.07[-0.70, 0.55] Scale (NEO-FFI v BFI-S) 0.12[0.01, 0.23] -0.01[-9.22, 9.20] -0.07[-0.18, 0.05] 0.03[-0.09, 0.14] -0.12[-0.75, 0.51] Scale (NEO-FFI v IPIP NEO) 0.11[-0.01, 0.22] 0.01[-9.20, 9.22] -0.12[-0.22, -0.01] -0.00[-0.12, 0.12] 0.01[-0.61, 0.64] Scale (NEO-FFI v TDA-40) 0.04[-0.04, 0.13] -0.01[-9.22, 9.20] -0.04[-0.11, 0.02] -0.08[-0.17, 0.01] 0.02[-0.60, 0.65] Baseline Age Study Baseline Age -0.001[-0.00, 0.00] 0.00[-0.00, 0.01] 0.00[-0.00, 0.01] 0.001[-0.001, 0.00] -0.000[-0.01, 0.01] Baseline Year Study Baseline Year -0.000[-0.01, 0.00] 0.01[0.00, 0.01] 0.01[-0.00, 0.01] 0.001[-0.00, 0.01] -0.01[-0.02, 0.00] Prediction Interval Prediction Interval -0.00[-0.01, 0.01] -0.01[-0.02, -0.00] -0.01[-0.02, 0.01] -0.00[-0.01, 0.01] 0.01[-0.02, 0.04] ## bayesian (ipd2b_fx_tab2 %&gt;% filter(type == &quot;Bayesian&quot; &amp; Covariate == &quot;Fully Adjusted&quot;))$tab[[1]]# save(ipd1a_fx_tab, ipd1a_fx_tab2, ipd1a_res, file = sprintf(&quot;%s/manuscript/results/ipd1b_fx_tab.RData&quot;, res_path)) Table 4.5: 2B Pooled One Stage Models with Random Effects: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.01[-0.03, 0.06] 0.00[-0.07, 0.07] 0.02[-0.07, 0.09] -0.06[-0.10, -0.03] 0.16[0.04, 0.29] Age Age -0.00[-0.01, 0.00] -0.001[-0.01, 0.00] -0.00[-0.01, 0.00] 0.001[-0.00, 0.01] -0.001[-0.01, 0.01] Gender Gender (Male v Female) 0.04[-0.01, 0.10] 0.00[-0.08, 0.07] -0.02[-0.09, 0.04] -0.01[-0.06, 0.03] -0.04[-0.09, 0.04] Education Education (Years) -0.00[-0.01, 0.01] -0.00[-0.02, 0.02] 0.01[-0.02, 0.04] 0.000[-0.01, 0.01] -0.00[-0.02, 0.01] Continent Continent (North America v Europe) 0.07[-0.04, 0.16] -0.08[-0.35, 0.15] -0.11[-0.30, 0.12] -0.03[-0.07, 0.02] 0.14[-0.09, 0.40] Continent (North America v Australia) 0.02[-0.12, 0.14] -0.03[-0.31, 0.27] -0.03[-0.27, 0.22] -0.11[-0.17, -0.04] 0.09[-0.24, 0.41] Country Country (United States v Germany) 0.08[-0.06, 0.21] 0.01[-0.15, 0.21] -0.04[-0.29, 0.27] -0.02[-0.13, 0.08] 0.11[-0.14, 0.37] Country (United States v Sweden) 0.07[-0.07, 0.19] -0.22[-0.40, -0.03] -0.18[-0.42, 0.11] -0.04[-0.13, 0.05] 0.24[-0.09, 0.58] Country (United States v The Netherlands) -0.01[-0.11, 0.09] Country (United States v Australia) 0.02[-0.14, 0.16] -0.01[-0.15, 0.13] -0.03[-0.29, 0.20] -0.11[-0.19, -0.01] 0.08[-0.23, 0.39] Personality Scale Scale (NEO-FFI v DPQ) 0.01[-0.17, 0.22] Scale (NEO-FFI v Eysenck) 0.08[-0.08, 0.28] -0.21[-1.49, 1.03] -0.21[-0.58, 0.14] -0.02[-0.16, 0.13] 0.19[-0.68, 1.10] Scale (NEO-FFI v MIDI) -0.01[-0.24, 0.21] -0.12[-1.40, 1.05] 0.00[-0.40, 0.30] 0.04[-0.14, 0.25] -0.07[-0.90, 0.84] Scale (NEO-FFI v BFI-S) 0.12[-0.09, 0.32] -0.04[-1.55, 1.11] -0.06[-0.41, 0.28] 0.03[-0.14, 0.24] -0.01[-0.89, 0.97] Scale (NEO-FFI v IPIP NEO) 0.10[-0.11, 0.32] 0.03[-1.11, 1.27] -0.11[-0.48, 0.23] -0.00[-0.20, 0.20] 0.05[-0.84, 1.04] Scale (NEO-FFI v TDA-40) 0.04[-0.19, 0.23] -0.12[-1.52, 0.95] -0.05[-0.43, 0.38] -0.08[-0.23, 0.12] 0.000[-0.91, 0.83] Baseline Age Study Baseline Age -0.001[-0.00, 0.00] 0.00[-0.01, 0.01] 0.00[-0.00, 0.01] 0.001[-0.00, 0.00] -0.000[-0.01, 0.01] Baseline Year Study Baseline Year -0.000[-0.01, 0.01] 0.01[0.00, 0.01] 0.01[-0.01, 0.02] 0.001[-0.00, 0.01] -0.01[-0.02, 0.01] Prediction Interval Prediction Interval -0.00[-0.02, 0.01] -0.01[-0.03, 0.000] -0.01[-0.03, 0.01] -0.001[-0.01, 0.01] 0.01[-0.02, 0.05] 4.2.2.7.1.2 Study-Specific Effects ## table function ipd2b_tab_fun &lt;- function(d, type, moder){ print(paste(type, moder)) md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term)) == 1) c(2, rep(1,5)) else c(3, rep(1,5)) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$short_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- if(length(unique(d$term)) == 1) c(&quot;Covariate&quot;, &quot;Study&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot;Covariate&quot;, &quot;Study&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- if(length(unique(d$term)) == 1) c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term)) == 1) d &lt;- d %&gt;% select(-term) cap &lt;- if(md == &quot;none&quot;) &quot;Overall Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% arrange(Outcome) %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) %&gt;% collapse_rows(1, valign = &quot;top&quot;) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/tables/study specific/%s.html&quot; , local_path, type, md)) return(tab) } ipd2b_rx_tab &lt;- ipd2b_reg_tab %&gt;% filter(!Moderator %in% stdyModers$long_name) %&gt;% arrange(type, Outcome, Moderator, Covariate, study, term) %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd2b_tab_fun)) ## [1] &quot;Bayesian None&quot; ## [1] &quot;Bayesian Age&quot; ## [1] &quot;Bayesian Gender&quot; ## [1] &quot;Bayesian Education&quot; ## [1] &quot;Frequentist None&quot; ## [1] &quot;Frequentist Age&quot; ## [1] &quot;Frequentist Gender&quot; ## [1] &quot;Frequentist Education&quot; ipd2b_rx_tab ## # A tibble: 8 × 4 ## type Moderator data tab ## &lt;chr&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 Bayesian None &lt;tibble [60 × 9]&gt; &lt;kablExtr [1]&gt; ## 2 Bayesian Age &lt;tibble [24 × 9]&gt; &lt;kablExtr [1]&gt; ## 3 Bayesian Gender &lt;tibble [24 × 9]&gt; &lt;kablExtr [1]&gt; ## 4 Bayesian Education &lt;tibble [24 × 9]&gt; &lt;kablExtr [1]&gt; ## 5 Frequentist None &lt;tibble [60 × 9]&gt; &lt;kablExtr [1]&gt; ## 6 Frequentist Age &lt;tibble [24 × 9]&gt; &lt;kablExtr [1]&gt; ## 7 Frequentist Gender &lt;tibble [24 × 9]&gt; &lt;kablExtr [1]&gt; ## 8 Frequentist Education &lt;tibble [24 × 9]&gt; &lt;kablExtr [1]&gt; ## Frequentist (ipd2b_rx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Frequentist&quot;))$tab[[1]] (#tab:ipd2b study specific table)Overall Effects of Personality-Crystallized Domain Associations E A C N O Covariate Study b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted BASE 0.05[-0.02, 0.12] -0.13[-0.20, -0.06] 0.39[0.27, 0.52] EAS 0.10[0.06, 0.15] 0.02[-0.03, 0.07] 0.02[-0.03, 0.07] -0.13[-0.17, -0.08] 0.37[0.32, 0.42] GSOEP 0.07[0.03, 0.11] -0.02[-0.07, 0.03] -0.02[-0.07, 0.03] -0.08[-0.12, -0.04] 0.10[0.06, 0.15] HILDA 0.01[-0.01, 0.04] 0.05[0.01, 0.08] 0.07[0.04, 0.09] -0.15[-0.17, -0.12] 0.27[0.25, 0.30] HRS 0.001[-0.02, 0.03] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.08[-0.10, -0.06] 0.22[0.19, 0.24] LASA -0.13[-0.17, -0.09] MAP 0.04[-0.01, 0.09] 0.09[0.02, 0.17] -0.15[-0.20, -0.10] MARS -0.18[-0.25, -0.12] OCTO-Twin 0.05[-0.01, 0.11] -0.10[-0.16, -0.04] ROS 0.02[-0.03, 0.07] 0.10[0.02, 0.17] 0.12[0.04, 0.19] -0.10[-0.15, -0.05] 0.19[0.11, 0.27] SATSA 0.04[-0.02, 0.11] -0.17[-0.27, -0.07] -0.12[-0.21, -0.03] -0.11[-0.17, -0.05] 0.37[0.25, 0.49] Overall 0.04[0.01, 0.08] 0.01[-0.08, 0.09] 0.05[-0.03, 0.12] -0.12[-0.15, -0.09] 0.27[0.18, 0.36] Age BASE 0.03[-0.02, 0.07] -0.14[-0.21, -0.06] 0.40[0.28, 0.53] EAS 0.05[0.01, 0.09] 0.08[0.01, 0.16] 0.01[-0.07, 0.10] -0.13[-0.19, -0.07] 0.41[0.33, 0.49] GSOEP 0.06[0.03, 0.09] -0.02[-0.07, 0.03] -0.02[-0.08, 0.03] -0.08[-0.12, -0.04] 0.10[0.06, 0.15] HILDA 0.01[-0.01, 0.04] 0.04[0.01, 0.07] 0.07[0.04, 0.09] -0.16[-0.19, -0.14] 0.28[0.25, 0.30] HRS 0.00[-0.02, 0.02] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.08[-0.10, -0.06] 0.22[0.19, 0.24] LASA -0.12[-0.16, -0.09] MAP 0.04[0.01, 0.08] 0.09[0.02, 0.17] -0.15[-0.20, -0.10] MARS -0.19[-0.26, -0.12] OCTO-Twin 0.03[-0.01, 0.07] -0.10[-0.16, -0.04] ROS 0.03[-0.01, 0.06] 0.10[0.03, 0.18] 0.12[0.05, 0.19] -0.10[-0.16, -0.05] 0.19[0.12, 0.27] SATSA 0.04[-0.00, 0.08] -0.18[-0.28, -0.08] -0.13[-0.22, -0.04] -0.11[-0.17, -0.05] 0.38[0.26, 0.50] Overall 0.03[0.01, 0.06] 0.02[-0.08, 0.11] 0.04[-0.04, 0.12] -0.12[-0.16, -0.09] 0.28[0.19, 0.38] Gender BASE 0.03[-0.02, 0.07] -0.13[-0.21, -0.06] 0.40[0.27, 0.53] EAS 0.05[0.01, 0.09] 0.09[0.01, 0.16] 0.01[-0.07, 0.10] -0.13[-0.19, -0.07] 0.41[0.33, 0.49] GSOEP 0.06[0.03, 0.09] -0.02[-0.07, 0.03] -0.02[-0.08, 0.03] -0.08[-0.12, -0.04] 0.10[0.06, 0.14] HILDA 0.01[-0.01, 0.04] 0.05[0.02, 0.08] 0.07[0.04, 0.09] -0.15[-0.17, -0.12] 0.27[0.25, 0.30] HRS 0.00[-0.02, 0.02] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.08[-0.10, -0.06] 0.22[0.19, 0.24] LASA -0.13[-0.17, -0.09] MAP 0.04[0.01, 0.08] 0.09[0.02, 0.17] -0.15[-0.20, -0.10] MARS -0.19[-0.25, -0.12] OCTO-Twin 0.03[-0.01, 0.07] -0.10[-0.16, -0.04] ROS 0.03[-0.01, 0.06] 0.10[0.03, 0.18] 0.12[0.05, 0.19] -0.10[-0.16, -0.05] 0.19[0.11, 0.27] SATSA 0.04[-0.00, 0.08] -0.18[-0.28, -0.08] -0.13[-0.22, -0.04] -0.11[-0.17, -0.05] 0.38[0.26, 0.50] Overall 0.03[0.01, 0.06] 0.02[-0.07, 0.11] 0.04[-0.04, 0.12] -0.12[-0.15, -0.09] 0.28[0.18, 0.38] Education BASE 0.00[-0.06, 0.07] -0.09[-0.15, -0.02] 0.30[0.18, 0.42] EAS 0.03[-0.02, 0.09] 0.03[0.02, 0.03] -0.02[-0.09, 0.05] -0.07[-0.12, -0.01] 0.19[0.11, 0.27] GSOEP 0.06[0.01, 0.12] -0.04[-0.04, -0.03] 0.00[-0.07, 0.08] -0.03[-0.08, 0.02] 0.06[-0.01, 0.13] HILDA 0.01[-0.01, 0.03] 0.04[0.04, 0.04] 0.03[0.01, 0.06] -0.13[-0.15, -0.11] 0.19[0.17, 0.22] HRS -0.03[-0.05, -0.01] 0.04[0.04, 0.04] 0.08[0.06, 0.11] -0.03[-0.05, -0.01] 0.10[0.08, 0.13] LASA -0.05[-0.09, -0.01] MAP 0.02[-0.03, 0.07] 0.04[-0.03, 0.10] -0.04[-0.08, 0.01] MARS -0.08[-0.14, -0.02] OCTO-Twin 0.04[-0.02, 0.09] -0.07[-0.13, -0.02] ROS -0.04[-0.09, 0.01] 0.01[0.01, 0.02] 0.06[-0.00, 0.12] -0.03[-0.08, 0.02] 0.01[-0.07, 0.08] SATSA 0.03[-0.03, 0.09] -0.02[-0.03, -0.02] -0.08[-0.16, -0.01] -0.05[-0.11, 0.00] 0.26[0.14, 0.38] Overall 0.01[-0.02, 0.05] 0.01[-0.02, 0.04] 0.02[-0.04, 0.07] -0.06[-0.09, -0.03] 0.16[0.07, 0.25] Fully Adjusted BASE 0.00[-0.06, 0.07] -0.09[-0.16, -0.02] 0.31[0.18, 0.43] EAS 0.03[-0.02, 0.09] 0.02[0.01, 0.02] -0.02[-0.09, 0.05] -0.07[-0.12, -0.01] 0.19[0.11, 0.27] GSOEP 0.06[0.01, 0.12] -0.04[-0.04, -0.04] 0.000[-0.08, 0.08] -0.03[-0.08, 0.02] 0.06[-0.00, 0.13] HILDA 0.01[-0.02, 0.03] 0.03[0.03, 0.03] 0.03[0.00, 0.05] -0.13[-0.16, -0.11] 0.20[0.17, 0.22] HRS -0.03[-0.05, -0.01] 0.03[0.03, 0.03] 0.08[0.06, 0.11] -0.03[-0.05, -0.01] 0.10[0.08, 0.13] LASA -0.05[-0.09, -0.01] MAP 0.02[-0.02, 0.07] 0.04[-0.03, 0.11] -0.03[-0.08, 0.01] MARS -0.08[-0.14, -0.02] OCTO-Twin 0.04[-0.02, 0.09] -0.07[-0.13, -0.02] ROS -0.04[-0.09, 0.01] 0.01[0.00, 0.01] 0.06[-0.000, 0.13] -0.03[-0.08, 0.02] 0.01[-0.06, 0.09] SATSA 0.03[-0.03, 0.09] -0.03[-0.03, -0.02] -0.09[-0.16, -0.01] -0.05[-0.11, 0.00] 0.26[0.14, 0.38] Overall 0.01[-0.02, 0.05] 0.00[-0.03, 0.03] 0.01[-0.04, 0.07] -0.06[-0.09, -0.03] 0.16[0.07, 0.25] ## bayesian (ipd2b_rx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; type == &quot;Bayesian&quot;))$tab[[1]] (#tab:ipd2b study specific table)Overall Effects of Personality-Crystallized Domain Associations E A C N O Covariate Study b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability Unadjusted BASE 0.05[-0.04, 0.16] -0.14[-0.23, -0.06] 0.39[0.26, 0.53] EAS 0.10[0.04, 0.16] 0.02[-0.03, 0.07] 0.02[-0.03, 0.07] -0.13[-0.17, -0.08] 0.37[0.32, 0.42] GSOEP 0.07[0.03, 0.12] -0.02[-0.07, 0.04] -0.02[-0.08, 0.03] -0.08[-0.12, -0.03] 0.10[0.06, 0.15] HILDA 0.01[-0.01, 0.04] 0.04[0.01, 0.08] 0.07[0.04, 0.09] -0.15[-0.17, -0.12] 0.27[0.25, 0.30] HRS 0.001[-0.02, 0.03] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.08[-0.10, -0.06] 0.22[0.19, 0.24] LASA -0.13[-0.17, -0.09] MAP 0.04[-0.01, 0.09] 0.10[0.02, 0.17] -0.15[-0.20, -0.09] MARS -0.19[-0.29, -0.11] OCTO-Twin 0.05[-0.02, 0.11] -0.10[-0.17, -0.03] ROS 0.02[-0.05, 0.07] 0.10[0.02, 0.18] 0.12[0.05, 0.20] -0.10[-0.15, -0.04] 0.19[0.12, 0.27] SATSA 0.04[-0.02, 0.12] -0.17[-0.30, -0.04] -0.13[-0.22, -0.03] -0.11[-0.17, -0.04] 0.38[0.26, 0.52] Overall 0.04[0.00, 0.09] 0.00[-0.13, 0.12] 0.04[-0.07, 0.15] -0.12[-0.16, -0.09] 0.28[0.16, 0.40] Age BASE 0.03[-0.03, 0.12] -0.14[-0.24, -0.06] 0.39[0.26, 0.53] EAS 0.05[0.00, 0.14] 0.08[0.00, 0.17] 0.01[-0.07, 0.09] -0.13[-0.19, -0.06] 0.41[0.32, 0.49] GSOEP 0.06[0.02, 0.11] -0.02[-0.07, 0.04] -0.02[-0.07, 0.03] -0.08[-0.12, -0.03] 0.10[0.06, 0.15] HILDA 0.01[-0.01, 0.04] 0.04[0.01, 0.07] 0.07[0.04, 0.09] -0.16[-0.19, -0.14] 0.28[0.25, 0.30] HRS 0.00[-0.02, 0.03] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.08[-0.10, -0.06] 0.22[0.19, 0.24] LASA -0.12[-0.16, -0.08] MAP 0.04[-0.01, 0.09] 0.10[0.02, 0.17] -0.15[-0.20, -0.09] MARS -0.19[-0.29, -0.11] OCTO-Twin 0.03[-0.02, 0.10] -0.10[-0.17, -0.03] ROS 0.02[-0.04, 0.07] 0.10[0.03, 0.18] 0.12[0.05, 0.20] -0.10[-0.15, -0.04] 0.20[0.12, 0.27] SATSA 0.04[-0.01, 0.10] -0.18[-0.30, -0.05] -0.13[-0.23, -0.03] -0.11[-0.17, -0.04] 0.40[0.26, 0.54] Overall 0.03[0.00, 0.07] 0.01[-0.11, 0.14] 0.04[-0.07, 0.16] -0.12[-0.16, -0.08] 0.29[0.17, 0.42] Gender BASE 0.03[-0.03, 0.12] -0.14[-0.24, -0.06] 0.39[0.26, 0.53] EAS 0.05[0.01, 0.14] 0.08[0.01, 0.16] 0.01[-0.07, 0.09] -0.13[-0.19, -0.06] 0.41[0.32, 0.49] GSOEP 0.06[0.02, 0.11] -0.02[-0.07, 0.03] -0.02[-0.07, 0.03] -0.08[-0.12, -0.03] 0.10[0.06, 0.15] HILDA 0.01[-0.01, 0.04] 0.05[0.02, 0.08] 0.07[0.04, 0.09] -0.15[-0.17, -0.12] 0.27[0.25, 0.30] HRS 0.00[-0.02, 0.03] 0.06[0.03, 0.09] 0.16[0.13, 0.19] -0.08[-0.10, -0.06] 0.22[0.19, 0.24] LASA -0.13[-0.17, -0.09] MAP 0.04[-0.01, 0.09] 0.10[0.02, 0.17] -0.15[-0.20, -0.09] MARS -0.19[-0.29, -0.11] OCTO-Twin 0.03[-0.02, 0.10] -0.10[-0.17, -0.03] ROS 0.02[-0.03, 0.07] 0.10[0.03, 0.18] 0.12[0.05, 0.20] -0.10[-0.16, -0.04] 0.19[0.12, 0.27] SATSA 0.04[-0.01, 0.10] -0.18[-0.29, -0.06] -0.13[-0.23, -0.03] -0.11[-0.17, -0.04] 0.39[0.26, 0.53] Overall 0.03[-0.001, 0.07] 0.01[-0.12, 0.14] 0.04[-0.07, 0.15] -0.12[-0.17, -0.08] 0.28[0.15, 0.43] Education BASE 0.01[-0.08, 0.10] -0.09[-0.17, -0.02] 0.30[0.17, 0.44] EAS 0.04[-0.03, 0.11] 0.04[-0.02, 0.10] -0.02[-0.10, 0.05] -0.06[-0.12, -0.00] 0.18[0.11, 0.26] GSOEP 0.06[-0.00, 0.14] 0.01[-0.06, 0.09] 0.01[-0.07, 0.09] -0.03[-0.09, 0.03] 0.07[-0.00, 0.14] HILDA 0.01[-0.01, 0.03] 0.04[0.01, 0.06] 0.03[0.01, 0.06] -0.13[-0.15, -0.11] 0.19[0.17, 0.22] HRS -0.03[-0.05, -0.01] 0.04[0.01, 0.06] 0.08[0.06, 0.11] -0.03[-0.05, -0.00] 0.10[0.08, 0.12] LASA -0.05[-0.09, -0.01] MAP 0.02[-0.03, 0.07] 0.05[-0.02, 0.12] -0.04[-0.09, 0.02] MARS -0.09[-0.17, -0.02] OCTO-Twin 0.04[-0.02, 0.11] -0.07[-0.13, -0.01] ROS -0.04[-0.10, 0.01] 0.02[-0.03, 0.08] 0.06[-0.00, 0.13] -0.03[-0.08, 0.03] 0.01[-0.07, 0.08] SATSA 0.03[-0.04, 0.09] -0.08[-0.22, 0.03] -0.08[-0.19, 0.01] -0.05[-0.12, 0.01] 0.27[0.14, 0.41] Overall 0.01[-0.03, 0.06] 0.01[-0.06, 0.08] 0.02[-0.06, 0.09] -0.06[-0.10, -0.02] 0.16[0.02, 0.29] Fully Adjusted BASE 0.00[-0.08, 0.09] -0.09[-0.18, -0.01] 0.30[0.17, 0.44] EAS 0.04[-0.03, 0.11] 0.03[-0.03, 0.10] -0.02[-0.10, 0.05] -0.07[-0.13, -0.01] 0.19[0.11, 0.26] GSOEP 0.06[-0.00, 0.13] 0.01[-0.07, 0.09] 0.01[-0.07, 0.09] -0.03[-0.09, 0.03] 0.07[-0.00, 0.14] HILDA 0.01[-0.02, 0.03] 0.03[-0.001, 0.05] 0.03[0.00, 0.05] -0.13[-0.16, -0.11] 0.20[0.17, 0.22] HRS -0.03[-0.06, -0.01] 0.03[0.00, 0.05] 0.08[0.05, 0.11] -0.03[-0.05, -0.01] 0.10[0.08, 0.13] LASA -0.05[-0.09, -0.01] MAP 0.02[-0.03, 0.07] 0.05[-0.02, 0.12] -0.03[-0.09, 0.02] MARS -0.09[-0.16, -0.02] OCTO-Twin 0.04[-0.02, 0.11] -0.07[-0.14, -0.02] ROS -0.04[-0.10, 0.01] 0.02[-0.03, 0.09] 0.06[-0.001, 0.13] -0.03[-0.08, 0.03] 0.01[-0.06, 0.09] SATSA 0.03[-0.04, 0.10] -0.10[-0.23, 0.02] -0.09[-0.19, 0.01] -0.06[-0.12, 0.01] 0.27[0.14, 0.41] Overall 0.01[-0.03, 0.06] 0.00[-0.07, 0.07] 0.02[-0.07, 0.09] -0.06[-0.10, -0.03] 0.16[0.04, 0.29] 4.2.2.7.1.3 Heterogeneity Estimates loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/2b_ipd_mlm/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd2b_het &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/2b_ipd_mlm/%s/heterogeneity&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), het = map2(file, type, ~loadRData(.x, .y, &quot;het&quot;, &quot;heterogeneity&quot;))) %&gt;% select(-file) ip2b_hetero_tab_fun &lt;- function(d, type, out, mod, cov){ moder &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d2 &lt;- d %&gt;% separate(term, c(&quot;V1&quot;, &quot;V2&quot;), sep = &quot;[.]&quot;) %&gt;% mutate(V2 = ifelse(is.na(V2), V1, V2) , est = sprintf(&quot;%.2f [%.2f, %.2f]&quot;, estimate, conf.low, conf.high)) %&gt;% mutate_at(vars(V1, V2), ~mapvalues(., moders$short_term, moders$long_term)) %&gt;% mutate_at(vars(V1, V2), ~str_replace_all(., &quot;p_value&quot;, &quot;Personality&quot;)) %&gt;% mutate_at(vars(V1, V2), ~str_replace_all(., &quot;:&quot;, &quot; : &quot;)) %&gt;% mutate_at(vars(V1, V2), str_to_title) %&gt;% mutate_at(vars(V1, V2), ~str_replace_all(., &quot;:&quot;, &quot;x&quot;)) %&gt;% mutate_at(vars(V1, V2), ~str_remove_all(., &quot;[()]&quot;)) %&gt;% mutate_at(vars(V1, V2), ~ifelse(. == &quot;Observation&quot;, &quot;Sigma&quot;, .)) %&gt;% select(-group, -estimate, -conf.low, -conf.high) %&gt;% # unite(V1, Trait, V1, sep = &quot;_&quot;, remove = T) %&gt;% pivot_wider(names_from = &quot;V1&quot;, values_from = &quot;est&quot;) %&gt;% rename(&quot; &quot; = V2) %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) rs &lt;- d2 %&gt;% group_by(Trait) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cap &lt;- if(mod == &quot;none&quot;) &quot;Heterogeneity, Variance, and Correlations Among Random Effects for Overall Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;Heterogeneity, Variance, and Correlations Among Random Effects for Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, moder) cap &lt;- sprintf(&quot;&lt;strong&gt;Table SX&lt;/strong&gt;&lt;br&gt;&lt;em&gt;%s&lt;/em&gt;&quot;, cap) tab &lt;- d2 %&gt;% select(-Trait) %&gt;% kable(. , &quot;html&quot; , align = c(&quot;r&quot;, rep(&quot;c&quot;, ncol(d2)-2)) , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% footnote(&quot;Diagnonal elements represent variances, while off diagnal elements represent correlations. Interval estimates are 95% bootstrapped CI&#39;s.&quot;) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Trait[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/tables/heterogeneity/%s-%s-%s.html&quot;, local_path, type, out, mod, cov)) return(tab) } nested_ipd2b_het_tab &lt;- nested_ipd2b_het %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% unnest(het) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ip2b_hetero_tab_fun)) 4.2.2.7.1.4 All Model Terms ipd2b_mod_tab &lt;- nested_ipd2b_reg %&gt;% select(-n, -rx) %&gt;% unnest(fx) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd2b_mod_tab_fun &lt;- function(d, type, out, moder, cov){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- if(md == &quot;none&quot;) &quot;1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: All Model Estimates of Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;1B Pooled Analysis of Individual Participant Data with Cluster Corrected Standard Errors: All Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) # kable the table tab &lt;- d %&gt;% arrange(term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/tables/all terms/%s-%s-%s.html&quot; , local_path, type, o, md, cv)) return(tab) # return the html table } ipd2b_mod_tab &lt;- ipd2b_mod_tab %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ipd2b_mod_tab_fun)) 4.2.2.7.2 Figures 4.2.2.7.2.1 Overall Forest ipd2b_fx_plot_fun &lt;- function(df, mod, type, cov){ m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- if(d &gt; .01) round(c(0-d-(d/5), 0, 0+d+(d/5)),2) else round(c(0-d-(d/5), 0, 0+d+(d/5)),3) # lim_high &lt;- lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, m)} titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cv, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cv, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} # if(length(unique(df$term)) &gt; 1) df &lt;- df %&gt;% full_join(crossing(Trait = unique(df$Trait), Outcome = unique(df$Outcome), term = unique(df$term))) p &lt;- df %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high)) %&gt;% ggplot(aes(x = term, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(1.8, 1.3)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;blue&quot;, &quot;black&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .25, color = &quot;gray50&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high) , width = .01 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL , y = &quot;Estimate (POMP)&quot; , title = titl , subtitle = &quot;Method 2B: Pooled Regression Using Random Effects&quot; ) + guides(color = &quot;none&quot;, size = &quot;none&quot;) + facet_grid(Outcome~Trait, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5), plot.subtitle = element_text(size = rel(1.1), hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(df$Outcome)); ht2 &lt;- length(unique(df$term)) local_path &lt;- length(unique(df$Trait)) ggsave(p, file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/figures/overall forest/%s_%s_fixed.png&quot;, local_path, type, mod, cov), width = local_path*2, height = 1.25*ht + .75*ht2) rm(p) gc() return(T) } nested_ipd2b_reg %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), sig = factor(sig, levels = c(&quot;sig&quot;,&quot;ns&quot;)), Trait = factor(Trait, levels = traits$short_name), Outcome = factor(Outcome, levels = outcomes$short_name, labels = str_wrap(outcomes$long_name, 15)), Outcome = forcats::fct_rev(Outcome)) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Moderator == &quot;country&quot;) %&gt;% mutate(pmap(list(data, Moderator, type, Covariate), ipd2b_fx_plot_fun)) 4.2.2.7.2.2 Study-Specific Forest ipd2b_rx_plot_fun &lt;- function(df, outcome, mod, type, cov, trait){ print(paste(outcome, mod)) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- round(c(0-d-(d/5), 0, 0+d+(d/5)),2) lab &lt;- str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){trt} else {sprintf(&quot;%s x %s&quot;, trt, m)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} df &lt;- df %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) %&gt;% full_join(tibble(study = &quot; &quot;, estimate = NA, n = NA)) %&gt;% arrange(estimate) stds &lt;- df$study[!df$study %in% c(&quot;Overall&quot;, &quot; &quot;)] df &lt;- df %&gt;% mutate(study = factor(study, rev(c(&quot; &quot;, stds, &quot;Overall&quot;))) # , conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low) # , conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot; , ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;neither&quot;)) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) # , study = factor(study, levels = str_remove_all(c(&quot;Overall&quot;, studies_long), &quot;-&quot;), labels = c(&quot;Overall&quot;, studies_long)) # Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), , type = ifelse(study == &quot;Overall&quot;, &quot;fixed&quot;, &quot;random&quot;)) p1 &lt;- df %&gt;% ggplot(aes(x = study, y = estimate)) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high) , position = &quot;dodge&quot; , width = .2) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(lb == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + annotate(&quot;rect&quot;, xmin = length(stds) + 1.6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = &quot; &quot; ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1)) d2 &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high) , ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^0.&quot;, &quot;.&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^-0.&quot;, &quot;-.&quot;)) %&gt;% mutate(est = ifelse(study != &quot; &quot;, sprintf(&quot;%s [%s, %s] &quot;, estimate, conf.low, conf.high), &quot;&quot;) , n = as.character(n) ) %&gt;% select(study, n, est) %&gt;% pivot_longer(cols = c(n, est), names_to = &quot;est&quot;, values_to = &quot;value&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = study, y = est)) + geom_text(data = d2 %&gt;% filter(est == &quot;est&quot;), aes(label = value), hjust = .5, size = 3.5) + geom_text(data = d2 %&gt;% filter(est == &quot;n&quot;), aes(label = value), hjust = .5, size = 3.5) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(stds) + 1.75, y = &quot;est&quot;, hjust = .5, vjust = 0) + annotate(&quot;text&quot;, label = &quot;N&quot;, x = length(stds) + 1.75, y = &quot;n&quot;, hjust = .5, vjust = 0) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + coord_flip() + theme_void() + theme(plot.title = element_text(face = &quot;bold&quot;, hjust = 0) , axis.text = element_blank() , axis.ticks = element_blank() , axis.title = element_blank()) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p3 &lt;- cowplot::plot_grid(p1, p2 , rel_widths = c(.5, .5) , align = &quot;h&quot; ) # p &lt;- cowplot::plot_grid(ttl, subttl, p3, rel_heights = c(.05, .05, .9), nrow = 3) p &lt;- cowplot::plot_grid(ttl, p3, rel_heights = c(.05, .95), nrow = 2) gc() save(p , file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/figures/study specific forest/rdata/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) return(p) } ## fixed effects nested_ipd2b_reg_fp &lt;- nested_ipd2b_reg %&gt;% filter(Moderator %in% moders$short_name) %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ## random effects full_join( nested_ipd2b_reg %&gt;% filter(Moderator %in% moders$short_name) %&gt;% mutate(rx = map2(rx, n, ~(.x) %&gt;% full_join(.y))) %&gt;% select(-fx, -n) %&gt;% unnest(rx) #%&gt;% # mutate(term = ifelse(Moderator != &quot;none&quot;, paste(term, mapvalues(Moderator, moders$short_name, moders$short_term, warn_missing = F), sep = &quot;:&quot;), term)) ) %&gt;% ## filter key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;) , study = mapvalues(study, studies_long, studies_sp, warn_missing = F)) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, type, Covariate, Trait) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Trait == &quot;N&quot; &amp; type == &quot;Frequentist&quot;) %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, type, Covariate, Trait), ipd2b_rx_plot_fun)) ipd2b_rx_plot_comb_fun &lt;- function(outcome, cov, mod, type, d){ o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) titl &lt;- paste0(o, &quot;,&quot;) titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(titl, cv, &quot;Adjusted&quot;, collapse = &quot;, &quot;) else paste(titl, cv, collapse = &quot;, &quot;) p1 &lt;- plot_grid( d$p[[1]] , d$p[[2]] , d$p[[3]] , d$p[[4]] , d$p[[5]] , nrow = 3 , ncol = 2 , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) my_theme &lt;- function(...) { theme_classic() + theme(plot.subtitle = element_text(hjust = 0)) } subtitle_theme &lt;- calc_element(&quot;subplot.title&quot;, my_theme()) subttl &lt;- ggdraw() + draw_label( &quot;Method 2B: Pooled Regression Using Random Effects&quot;, fontfamily = subtitle_theme$family, fontface = subtitle_theme$face, size = subtitle_theme$size ) p &lt;- cowplot::plot_grid(ttl, subttl, p1, rel_heights = c(.03, .03, .94), nrow = 3) ggsave(p , file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/figures/study specific forest/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) ggsave(p , file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/figures/study specific forest/%s_%s_%s.pdf&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) return(T) } nested_ipd2b_reg_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(Trait) %&gt;% select(-data) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(Outcome, Covariate, Moderator, type, data), ipd2b_rx_plot_comb_fun)) 4.2.2.7.2.3 Overall Simple Effects loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/2b_ipd_mlm/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd2b_simp &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/2b_ipd_mlm/%s/predicted&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), pred.fx = map2(file, type, ~loadRData(.x, .y, &quot;pred.fx&quot;, &quot;predicted&quot;)), pred.rx = map2(file, type, ~loadRData(.x, .y, &quot;pred.rx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) nested_ipd2b_simp simp_eff_fun &lt;- function(df, outcome, mod, type, cov){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) # mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) # maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) # lim &lt;- c(mini, maxi) # brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} # lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; df &lt;- df %&gt;% unclass %&gt;% data.frame df$mod_value &lt;- df[,mod] df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(df$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} else { if(mod == &quot;age&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;-10 yrs&quot;, &quot;M&quot;, &quot;+10 yrs&quot;))) else if(mod == &quot;baseYear&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;1990&quot;, &quot;200)0&quot;, &quot;2010&quot;))) else if(mod == &quot;baseAge&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;50&quot;, &quot;60&quot;, &quot;70&quot;))) else if(mod == &quot;predInt&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;5 yrs&quot;, &quot;+5 yrs&quot;))) else if(mod == &quot;education&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;))) else df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) } lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(df$mod_fac))] mini &lt;- floor(min(df$pred)); maxi &lt;- 10 df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, 10, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = mod_fac)) + scale_y_continuous(limits = c(mini,maxi) , breaks = seq(mini, maxi, by = 2) , labels = seq(mini, maxi, by = 2)) + scale_linetype_manual(values = lt) + geom_ribbon(aes(ymin = lower , ymax = upper , fill = mod_fac) , alpha = .25) + geom_line(aes(linetype = mod_fac)) + labs(x = &quot;Personality (POMP)&quot; , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = m , fill = m , subtitle = &quot;Method 2B: Pooled Regression Using Random Effects&quot;) + facet_wrap(~Trait, nrow = 3) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/figures/overall simple effects/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov), width = 6, height = 6) } ipd2b_se_plot &lt;- nested_ipd2b_simp %&gt;% select(-pred.rx) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Moderator== &quot;education&quot;) %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.fx)), plot = pmap(list(data, Outcome, Moderator, type, Covariate), simp_eff_fun)) 4.2.2.7.2.4 Study-Specific Simple Effects ipd2b_std_se_plot_fun &lt;- function(df, outcome, trait, mod, cov, type){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) # mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) # maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) # lim &lt;- c(mini, maxi) # brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} # lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; df &lt;- df %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) df &lt;- df %&gt;% unclass %&gt;% data.frame df$mod_value &lt;- df[,mod] df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(df$mod_value) == &quot;factor&quot;){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} if(class(df$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value))} else { if(mod == &quot;age&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;-10 yrs&quot;, &quot;M&quot;, &quot;+10 yrs&quot;))) else if(mod == &quot;baseYear&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;1990&quot;, &quot;200)0&quot;, &quot;2010&quot;))) else if(mod == &quot;baseAge&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;50&quot;, &quot;60&quot;, &quot;70&quot;))) else if(mod == &quot;predInt&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;5 yrs&quot;, &quot;+5 yrs&quot;))) else if(mod == &quot;education&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;))) else df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) } std &lt;- unique(df$study) cols &lt;- (stdcolors %&gt;% filter(studies %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies %in% std))$lt ht &lt;- length(unique(df$mod_fac)) mini &lt;- floor(min(df$pred)); maxi &lt;- 10 df %&gt;% mutate(study = factor(study, levels = stdcolors$studies), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, 10, upper), gr = ifelse(study == &quot;Overall&quot;, &quot;Overall&quot;, &quot;study&quot;)) %&gt;% group_by(study, mod_fac, p_value, gr) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() %&gt;% ggplot(aes(x = p_value , y = pred , group = study)) + scale_y_continuous(limits = c(mini,maxi) , breaks = seq(mini, maxi, by = 2) , labels = seq(mini, maxi, by = 2)) + scale_linetype_manual(values = lt) + scale_color_manual(values = cols) + scale_fill_manual(values = cols) + scale_size_manual(values = c(2,.8)) + # geom_ribbon(aes(ymin = lower # , ymax = upper # , fill = study) # , alpha = .25) + geom_line(aes(linetype = study, color = study, size = gr)) + labs(x = &quot;Personality (POMP)&quot; , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = &quot;Study&quot; , color = &quot;Study&quot; , fill = &quot;Study&quot; , subtitle = &quot;Method 2B: Pooled Regression Using Random Effects&quot;) + guides(size = &quot;none&quot;) + facet_wrap(~mod_fac, nrow = 1) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/2b_ipd_mlm/%s/figures/study specific simple effects/%s_%s_%s_%s.png&quot;, local_path, type, outcome, trt, mod, cov), width = 3*ht, height = 5) } nested_ipd2b_simp %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% # filter(map_lgl(pred.rx, ~!is.null(.))) mutate(pred.fx = map(pred.fx, ~(.) %&gt;% mutate(study = &quot;Overall&quot;)), comb.fx = map2(pred.fx, pred.rx, full_join)) %&gt;% select(-pred.fx, -pred.rx) %&gt;% # filter(Moderator %in% c(&quot;age&quot;, &quot;education&quot;)) %&gt;% mutate(pmap(list(comb.fx, Outcome, Trait, Moderator, Covariate, type), ipd2b_std_se_plot_fun)) load(&quot;~/Documents/projects/data synthesis/crystallized/results/2b_ipd_mlm/Frequentist/models/crystallized_C_scale_all.RData&quot;) fixef(m) ## (Intercept) p_value age genderFemale education ## 6.737893882 0.070935261 0.001625964 0.103872146 0.255833361 ## scaleBFI-S scaleEysenck scaleIPIP NEO scaleMIDI scaleTDA-40 ## 1.445698251 1.649520347 -0.586613200 -2.027132359 -1.593313674 ## p_value:scaleBFI-S p_value:scaleEysenck p_value:scaleIPIP NEO p_value:scaleMIDI p_value:scaleTDA-40 ## -0.066244543 -0.213937506 -0.115922216 0.012948027 -0.043546168 cntrm &lt;- rbind( c(0,1,rep(0,13)) # NEO FFI , c(0,1,rep(0,8),1,0,0,0,0) # BFI-S , c(0,1,rep(0,9),1,0,0,0) # Eysenck , c(0,1,rep(0,10),1,0,0) # IPIP NEO , c(0,1,rep(0,11),1,0) # MIDI , c(0,1,rep(0,12),1) # TDA-40 ); rownames(cntrm) &lt;- c(&quot;NEO-FFI&quot;, &quot;BFI-S&quot;, &quot;Eysenck&quot;, &quot;IPIP NEO&quot;, &quot;MIDI&quot;, &quot;TDA-40&quot;) (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = rownames(cntrm)) %&gt;% select(-cntr) %&gt;% mutate(est = sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr)) ## Estimate lwr upr term est ## 1 0.070935261 0.01391155 0.12795897 NEO-FFI b = 0.07, 95% CI [0.01, 0.13] ## 2 0.004690717 -0.09200863 0.10139006 BFI-S b = 0.00, 95% CI [-0.09, 0.10] ## 3 -0.143002245 -0.24210542 -0.04389907 Eysenck b = -0.14, 95% CI [-0.24, -0.04] ## 4 -0.044986955 -0.13309875 0.04312484 IPIP NEO b = -0.04, 95% CI [-0.13, 0.04] ## 5 0.083883288 0.04542256 0.12234401 MIDI b = 0.08, 95% CI [0.05, 0.12] ## 6 0.027389093 -0.01026313 0.06504132 TDA-40 b = 0.03, 95% CI [-0.01, 0.07] load(&quot;~/Documents/projects/data synthesis/crystallized/results/2b_ipd_mlm/Frequentist/models/crystallized_A_baseYear_all.RData&quot;) fixef(m) ## (Intercept) p_value age genderFemale education baseYear p_value:baseYear ## 6.631036181 -0.019513289 0.002262725 0.103624853 0.274346670 -0.118874391 0.008497705 cntrm &lt;- c( &quot;p_value = 0&quot; # 2000 , &quot;p_value - 10*p_value:baseYear = 0&quot; # 1990 , &quot;p_value + 10*p_value:baseYear = 0&quot; # 2010 ); names(cntrm) &lt;- c(2000, 1990, 2010) (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = names(cntrm)) %&gt;% select(-cntr) %&gt;% mutate(est = sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr)) ## Estimate lwr upr term est ## 1 -0.01951329 -0.04827826 0.009251684 2000 b = -0.02, 95% CI [-0.05, 0.01] ## 2 -0.10449034 -0.17448848 -0.034492203 1990 b = -0.10, 95% CI [-0.17, -0.03] ## 3 0.06546376 0.03595811 0.094969409 2010 b = 0.07, 95% CI [0.04, 0.09] 4.2.2.8 Sample Results Section We examined estimates of overall prospective associations between Big Five personality characteristics and crystallized abilities as well as participant and sample-level moderators of those associations using fully pooled, one-stage multilevel models with individual participant data in 11 studies. Multilevel models allowed us to estimate overall, sample-specific, and heterogeneity estimates as well as both participant-level and sample-level moderators of Big Five personality characteristic-crystallized abilities associations. Heterogeneity estimates were estimated for both personality-cognitive ability associations (\\(\\tau_{11}^2\\)) as well as for participant-level moderators (\\(\\tau_{22}^2\\); see online materials). Fully adjusted prospective Big Five personality characteristic-crystallized abilities associations and participant- and sample-level moderators of these associations can be found in the fourth section of Table S4. Table 4.5: 2B Pooled One Stage Models with Random Effects: Fixed Effect Estimates of Fully Adjusted Personality-Crystallized Domain Associations E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.01[-0.02, 0.05] 0.00[-0.03, 0.03] 0.01[-0.04, 0.07] -0.06[-0.09, -0.03] 0.16[0.07, 0.25] Age Age 0.001[-0.03, 0.03] 0.000[-0.09, 0.09] -0.001[-0.01, 0.01] 0.00[-0.00, 0.01] 0.001[-0.09, 0.09] Gender Gender (Male v Female) 0.05[0.01, 0.09] 0.02[-0.02, 0.06] 0.01[-0.03, 0.06] -0.02[-0.05, 0.01] -0.000[-0.06, 0.06] Education Education (Years) -0.01[-0.07, 0.06] -0.01[-0.02, 0.01] 0.01[-0.02, 0.04] 0.00[-0.01, 0.01] -0.01[-0.12, 0.09] Continent Continent (North America v Europe) 0.07[0.00, 0.14] -0.12[-0.26, 0.03] -0.12[-0.24, 0.00] -0.03[-0.06, 0.01] 0.14[-0.08, 0.36] Continent (North America v Australia) 0.03[-0.05, 0.10] -0.01[-0.18, 0.15] -0.02[-0.16, 0.11] -0.11[-0.14, -0.08] 0.11[-0.19, 0.40] Country Country (United States v Germany) 0.08[-0.02, 0.18] -0.01[-0.10, 0.08] -0.05[-0.19, 0.09] -0.02[-0.09, 0.05] 0.12[-0.15, 0.38] Country (United States v Sweden) 0.07[-0.03, 0.16] -0.23[-0.35, -0.12] -0.20[-0.34, -0.06] -0.05[-0.11, 0.01] 0.22[-0.13, 0.58] Country (United States v The Netherlands) -0.02[-0.06, 0.03] Country (United States v Australia) 0.02[-0.06, 0.11] -0.01[-0.05, 0.03] -0.02[-0.13, 0.08] -0.11[-0.14, -0.08] 0.11[-0.21, 0.43] Personality Scale Scale (NEO-FFI v DPQ) 0.01[-0.09, 0.11] Scale (NEO-FFI v Eysenck) 0.09[-0.01, 0.18] -0.24[-9.45, 8.97] -0.21[-0.33, -0.10] -0.02[-0.11, 0.08] 0.14[-0.50, 0.77] Scale (NEO-FFI v MIDI) -0.00[-0.08, 0.08] -0.01[-9.22, 9.20] 0.01[-0.06, 0.08] 0.03[-0.06, 0.12] -0.07[-0.70, 0.55] Scale (NEO-FFI v BFI-S) 0.12[0.01, 0.23] -0.01[-9.22, 9.20] -0.07[-0.18, 0.05] 0.03[-0.09, 0.14] -0.12[-0.75, 0.51] Scale (NEO-FFI v IPIP NEO) 0.11[-0.01, 0.22] 0.01[-9.20, 9.22] -0.12[-0.22, -0.01] -0.00[-0.12, 0.12] 0.01[-0.61, 0.64] Scale (NEO-FFI v TDA-40) 0.04[-0.04, 0.13] -0.01[-9.22, 9.20] -0.04[-0.11, 0.02] -0.08[-0.17, 0.01] 0.02[-0.60, 0.65] Baseline Age Study Baseline Age -0.001[-0.00, 0.00] 0.00[-0.00, 0.01] 0.00[-0.00, 0.01] 0.001[-0.001, 0.00] -0.000[-0.01, 0.01] Baseline Year Study Baseline Year -0.000[-0.01, 0.00] 0.01[0.00, 0.01] 0.01[-0.00, 0.01] 0.001[-0.00, 0.01] -0.01[-0.02, 0.00] Prediction Interval Prediction Interval -0.00[-0.01, 0.01] -0.01[-0.02, -0.00] -0.01[-0.02, 0.01] -0.00[-0.01, 0.01] 0.01[-0.02, 0.04] Of the 20 key terms (five main effects and 15 moderators) tested at the participant-level, two (10%) were significant. Openness to experience was associated with later crystallized abilities across samples, and gender moderated the relationship between Extraversion and cognitive ability (b = 0.05, 95% CI [0.01, 0.09]). For the latter, we examined simple effects plots for gender moderating of extraversion and crystallized abilities. The black line in Figure S5 displays the fully adjusted association across genders. In this case, the interaction indicates that although the association was null for both males (b = -0.02, 95% CI [-0.04, 0.01]) and females (b = 0.03, 95% CI [-0.01, 0.08]), the associations did differ from one another. Figure 4.3: Figure S5. Prospective sample-specific and overall associations between extraversion (in POMP units, 0-10) and crystallized abilities (in POMP units, 0-10) across genders (male, female). Different colors and line types indicate different samples. Thicker, black lines indicate the average association across samples, while thinner lines indicate sample-specific associations. Next, we examined the sample-specific effects to see how consistent associations were across samples. Figure S6 presents the forest plot of fully adjusted sample-specific and overall prospective associations between the Big Five personality characteristics and crystallized abilities. As shown in the forest plot, openness showed the most consistent association with crystallized ability, with five of seven samples being positively and significantly associated with crystallized abilities. Other prospective associations, such as those with extraversion, agreeableness, and conscientiousness, were less consistent, with at least one significant association in different directions across samples. For example, although there was no overall association between conscientiousness and crystallized abilities, SATSA had a significant negative association, and HILDA and HRS had positive associations. Figure 4.4: Figure S6. Forest plot of fully adjusted prospective associations between Big Five personality characteristics and crystallized abilities across samples for using one-stage pooled integrative data analysis via effects coded contrasts. Overall point estimates (squares) represent the grand-mean estimates of the association across samples, while sample point estimates represent regression terms or linear combinations of regression terms. Error bars capture the 95% CI around the point estimate. Arrows indicate the confidence band was truncated to better visualize the estimates. Finally, we can also examine the consistency of simple effects across samples for each moderator. The thinner dashed and colored lines in Figure S5 display the fully adjusted predicted crystallized abilities levels at different levels of extraversion across samples for males and females. As noted above, the overall trend suggests a positive association for females and null association for males, such that women who were higher in extraversion tended to score better on crystallized / knowledge domain tasks and that these associations were quite consistent across samples. Women show a slight positive relationship in all samples but HRS and ROS. For men, the associations were also quite consistent, with all the samples showing significant negative associations but GSOEP, MAP, and OCTO-Twin, which showed positive associations. We also examined sample-level moderators of the associations, which are displayed in Table S4 (fully adjusted) above. Across the 67 tested associations, 10 (14.93%) were significant. Some of these differences were a function of the personality scale, with for example, estimates of the association between Conscientiousness and crystallized / knowledge domain cognitive ability differing across scales. The NEO-FFI (b = 0.07, 95% CI [0.01, 0.13]) and MIDI (b = 0.08, 95% CI [0.05, 0.12] ) demonstrated positive associations; the IPIP NEO (b = -0.04, 95% CI [-0.13, 0.04]), BFI-S (b = 0.00, 95% CI [-0.09, 0.10]), and TDA-40 (b = 0.03, 95% CI [-0.01, 0.07]) demonstrated null associations; and the measure used in SATSA and OCTO-Twin (b = -0.14, 95% CI [-0.24, -0.04]) had a negative association. In addition, for Agreeableness, samples with earlier baseline years had more negative effects than samples with later baseline effects. For example, samples with baseline years around 1990 demonstrated a negative association (b = -0.10, 95% CI [-0.17, -0.03]), samples with baseline years around 2000 demonstrated a null association (b = -0.02, 95% CI [-0.05, 0.01]), and samples with baseline years around 2010 demonstrated a positive association (b = 0.07, 95% CI [0.04, 0.09]). rm(list = ls()[grepl(&quot;ipd2&quot;, ls())]) "],["method-3-two-stage-individual-participant-meta-analysis.html", "Chapter 5 Method 3: Two-Stage Individual Participant Meta-Analysis 5.1 Analytic Plan 5.2 Step 1: Combine Data 5.3 Step 2: Run Models for Each Study 5.4 Step 3: Meta-Analyze Results 5.5 Sample Results Section", " Chapter 5 Method 3: Two-Stage Individual Participant Meta-Analysis 5.1 Analytic Plan In the present study, we estimate associations between the Big Five personality traits and crystallized cognitive abilities using a two-stage individual participant data meta-analysis (also known as a coordinated data analysis when multiple analysts are used). The procedure is as follows: 5.1.1 1. Sample-Specific Statistical Modeling Models were run separately for each sample, personality characteristic, outcome, covariate, and moderator combination. To do so, we wrote a series of functions in the R programming language (see online materials) to (1) set up and run the model and extract model coefficients, (2) extract simple-effects predictions for moderator models (i.e. predicted values across levels of the moderator values), and (3) extract effect size metrics for the later meta-analysis. The basic form of the model is as follows: \\(Y_{ij}=b_0+b_1\\ast predictor_{ij}+\\epsilon_{ij}\\) \\(\\epsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\), where \\(b_1\\) represents the effect of personality predicting the outcome separately in each sample. The modeling function used the base R lm() function to run the models and the tidy() function from the broom package to extract model coefficients and confidence intervals (CI). Inferences will be made based on the 95% confidence intervals. Effect sizes and their standard errors were extracted from the model summary(). Simple-effects predictions were calculated by providing the full range of personality levels (0-10) and average levels of the covariates from the data used to estimate the model as the “newdata” argument in the base R predict() function. 5.1.2 2. Results Pooling Using Meta-Analysis Once all the models were run, we next combined the effects across samples for each personality characteristic (5), outcome (1), covariate (6; none, each alone, all covariates), and moderator (3) combination and estimated a meta-analysis model of the target effect. We chose to conduct a random effects meta-analysis, which assumes that all effect sizes are randomly drawn from a population of effect sizes. To do so, we constructed three helper functions to (1) set up and run the meta-analytic models, (2) extract the meta-analytic estimates, and (3) extract heterogeneity estimates. The functions and more detail on them can be found in the online materials. The meta-analytic model is as follows: \\(T_i=\\mu+\\zeta_i+\\epsilon_i\\) \\(\\epsilon_i\\sim \\mathcal{N}\\left(0,\\sigma^2\\right)\\ \\) \\(\\zeta_i\\sim \\mathcal{N}\\left(0,\\tau^2\\right)\\ \\) \\(Cov\\left(\\zeta_i,\\epsilon_i\\right)=0\\), where \\(T_i\\) is the sample-specific effect of sample \\(i\\), \\(\\mu\\) is the overall meta-analytic estimate, \\(\\zeta_i\\) is true sample variability of sample \\(i\\) from the overall estimate, and \\(\\epsilon_i\\) is sampling error. Random effects meta-analyses were estimated using the metafor package in R. Meta-analytic estimates and confidence intervals were extracted using the coef() function. Inferences were based on the 95% confidence intervals (CI). Heterogeneity estimates were directly extracted from the model. Simple effects predictions of participant-level moderators were calculated using the weighted average sample-level predictions across levels of the moderators. 5.2 Step 1: Combine Data We again need to combine data. However, rather than combining data across studies, for the two-stage approach, we’ll be combining data within studies in order to run separate analyses for each before combining via meta-analytic tools. loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) print(path) load(path) get(ls()[grepl(type, ls())]) } ipd3_meta_data &lt;- tibble( study = studies[!studies %in% c(&quot;CNLSY&quot;, &quot;SLS&quot;)] , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID))) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% mutate(age = ifelse(is.na(age), p_year - yearBrth, age)) ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/base-i_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/eas_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/gsoep_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/hilda_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/hrs_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/lasa_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/map_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/mars_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/octo-twin_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/ros_cleaned.RData&quot; ## [1] &quot;~/Documents/projects/data synthesis/crystallized/data/clean/satsa_cleaned.RData&quot; ipd3_meta_data ## # A tibble: 119,597 × 13 ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 3.83 1990 10004 crystallized 2.17 2000 17 0 4 1918 72 ## 2 BASE E 3.83 1990 10010 crystallized 3.08 1995 11 0 2 1911 79 ## 3 BASE E 2.5 1990 10033 crystallized 0.909 1997 8 1 5 1910 80 ## 4 BASE E 3 1990 10034 crystallized 6.54 1995 10 0 5 1914 76 ## 5 BASE E 2.5 1990 10111 crystallized 6.54 1995 13 1 4 1901 89 ## 6 BASE E 3.17 1990 10115 crystallized 10 1995 11 0 2 1918 72 ## 7 BASE E 3 1990 10116 crystallized 3.85 1995 10 0 4 1917 73 ## 8 BASE E 3 1990 10145 crystallized 6.36 1997 10 1 5 1897 93 ## 9 BASE E 3.33 1990 10175 crystallized 2.31 1995 8 1 3 1911 79 ## 10 BASE E 3.33 1990 10188 crystallized 5.77 2004 10 1 2 1903 87 ## # ℹ 119,587 more rows 5.2.1 Study-Level Moderators save_fun &lt;- function(d, trait, outcome){ save(d, file = sprintf(&quot;%s/data/two_stage/meta_data/%s_%s.RData&quot;, local_path, trait, outcome)) } url &lt;- &quot;https://github.com/emoriebeck/data-synthesis-tutorial/raw/main/codebooks/crystallized_tables.xlsx&quot; destfile &lt;- &quot;tables.xlsx&quot; curl::curl_download(url, destfile) ipd_metaMod_data &lt;- readxl::read_xlsx(destfile, sheet = &quot;Table 4&quot;) %&gt;% select(-Category, -Construct, -category) %&gt;% pivot_longer(cols = c(&quot;BASE-I&quot;:&quot;SATSA&quot;) , names_to = &quot;study&quot; , values_to = &quot;value&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) %&gt;% mutate(continent = relevel(factor(continent), ref = &quot;North America&quot;) , country = relevel(factor(country), ref = &quot;United States&quot;) , scale = relevel(factor(scale), ref = &quot;NEO-FFI&quot;)) %&gt;% right_join( ipd3_meta_data %&gt;% select(-p_value, -o_value, -(education:yearBrth)) ) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate(baseAge = mean(age, na.rm = T) - 60, # center at age 60 predInt = mean(o_year - p_year) - 5, # center at 5 years baseYear = ifelse(study %in% c(&quot;MARS&quot;, &quot;MAP&quot;, &quot;ROS&quot;), mean(p_year), mean(p_year) - 2000)) %&gt;% # center at 2000 ungroup() %&gt;% select(Trait, Outcome, study, continent, country, scale, baseAge, baseYear, predInt) %&gt;% distinct() %&gt;% group_by(Trait, Outcome) %&gt;% nest() %&gt;% ungroup() ipd_metaMod_data ## # A tibble: 5 × 3 ## Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 A crystallized &lt;tibble [6 × 7]&gt; ## 2 C crystallized &lt;tibble [7 × 7]&gt; ## 3 E crystallized &lt;tibble [9 × 7]&gt; ## 4 N crystallized &lt;tibble [11 × 7]&gt; ## 5 O crystallized &lt;tibble [7 × 7]&gt; ipd_metaMod_data %&gt;% mutate(pmap(list(data, Trait, Outcome), save_fun)) ## # A tibble: 5 × 4 ## Trait Outcome data `pmap(list(data, Trait, Outcome), save_fun)` ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 A crystallized &lt;tibble [6 × 7]&gt; &lt;NULL&gt; ## 2 C crystallized &lt;tibble [7 × 7]&gt; &lt;NULL&gt; ## 3 E crystallized &lt;tibble [9 × 7]&gt; &lt;NULL&gt; ## 4 N crystallized &lt;tibble [11 × 7]&gt; &lt;NULL&gt; ## 5 O crystallized &lt;tibble [7 × 7]&gt; &lt;NULL&gt; readxl::read_xlsx(destfile, sheet = &quot;Table 4&quot;) %&gt;% select(-Category, -Construct, -category) %&gt;% pivot_longer(cols = c(&quot;BASE-I&quot;:&quot;SATSA&quot;) , names_to = &quot;study&quot; , values_to = &quot;value&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) %&gt;% right_join( ipd3_meta_data %&gt;% select(-p_value, -o_value, -(education:yearBrth)) ) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate(baseAge = mean(age, na.rm = T), # center at age 60 baseAgeSD = sd(age, na.rm = T), # center at age 60 predInt = mean(o_year - p_year), # center at 5 years predIntSD = sd(o_year - p_year), # center at 5 years baseYear = ifelse(study %in% c(&quot;MARS&quot;, &quot;MAP&quot;, &quot;ROS&quot;), median(p_year), median(p_year)), baseYearSD = ifelse(study %in% c(&quot;MARS&quot;, &quot;MAP&quot;, &quot;ROS&quot;), sd(p_year), sd(p_year)), cogYear = ifelse(study %in% c(&quot;MARS&quot;, &quot;MAP&quot;, &quot;ROS&quot;), median(o_year), median(o_year)), cogYearSD = ifelse(study %in% c(&quot;MARS&quot;, &quot;MAP&quot;, &quot;ROS&quot;), sd(o_year), sd(o_year))) %&gt;% # center at 2000 ungroup() %&gt;% select(Trait, Outcome, study, continent, country, scale, baseAge, baseAgeSD, baseYear, baseYearSD, cogYear, cogYearSD, predInt, predIntSD) %&gt;% distinct() %&gt;% group_by(study, Outcome) %&gt;% summarize_at(vars(baseAge:predIntSD), mean) %&gt;% kable(., &quot;html&quot;, digits = 2) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) study Outcome baseAge baseAgeSD baseYear baseYearSD cogYear cogYearSD predInt predIntSD BASE crystallized 78.23 6.66 1990 0.00 1997.00 3.51 8.56 3.51 EAS crystallized 79.47 5.36 2011 3.18 2014.00 3.09 2.15 2.41 GSOEP crystallized 49.83 15.83 2005 0.00 2012.00 0.00 7.00 0.00 HILDA crystallized 44.51 16.92 2005 0.00 2012.00 0.00 7.00 0.00 HRS crystallized 71.71 6.97 2006 0.00 2010.00 0.00 4.00 0.00 LASA crystallized 61.46 15.71 1992 1.19 1995.00 9.09 8.39 9.45 MAP crystallized 79.45 7.32 0 0.00 6.33 4.53 6.75 4.53 MARS crystallized 73.60 6.37 0 0.00 6.00 3.86 6.46 3.86 OCTO-Twin crystallized 82.99 2.66 1991 0.00 1997.00 2.82 6.21 2.82 ROS crystallized 75.87 7.38 0 0.03 8.00 6.42 9.53 6.42 SATSA crystallized 54.77 9.84 1984 0.00 1999.00 0.00 15.00 0.00 5.2.2 Harmonize Data ipd3_meta_data &lt;- ipd3_meta_data %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, o_value, SRhealth), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate(gender = factor(gender, levels = c(0,1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), education = education - 12, age = age - mean(age, na.rm = T)) %&gt;% ungroup() ipd3_meta_data ## # A tibble: 119,597 × 13 ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 7 1990 10004 crystallized 2.17 2000 5 Male 7.5 1918 -6.23 ## 2 BASE E 7 1990 10010 crystallized 3.08 1995 -1 Male 2.5 1911 0.766 ## 3 BASE E 3 1990 10033 crystallized 0.909 1997 -4 Female 10 1910 1.77 ## 4 BASE E 4.5 1990 10034 crystallized 6.54 1995 -2 Male 10 1914 -2.23 ## 5 BASE E 3 1990 10111 crystallized 6.54 1995 1 Female 7.5 1901 10.8 ## 6 BASE E 5 1990 10115 crystallized 10 1995 -1 Male 2.5 1918 -6.23 ## 7 BASE E 4.5 1990 10116 crystallized 3.85 1995 -2 Male 7.5 1917 -5.23 ## 8 BASE E 4.5 1990 10145 crystallized 6.36 1997 -2 Female 10 1897 14.8 ## 9 BASE E 5.5 1990 10175 crystallized 2.31 1995 -4 Female 5 1911 0.766 ## 10 BASE E 5.5 1990 10188 crystallized 5.77 2004 -2 Female 2.5 1903 8.77 ## # ℹ 119,587 more rows 5.2.3 Save Data Files save_fun &lt;- function(d, trait, outcome, study){ save(d, file = sprintf(&quot;%s/data/two_stage/%s_%s_%s.RData&quot;, local_path, trait, outcome, study)) } ipd3_meta_data %&gt;% group_by(study, Trait, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, Trait, Outcome, study), save_fun)) ## # A tibble: 40 × 4 ## study Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 BASE E crystallized &lt;NULL&gt; ## 2 BASE N crystallized &lt;NULL&gt; ## 3 BASE O crystallized &lt;NULL&gt; ## 4 EAS A crystallized &lt;NULL&gt; ## 5 EAS C crystallized &lt;NULL&gt; ## 6 EAS E crystallized &lt;NULL&gt; ## 7 EAS N crystallized &lt;NULL&gt; ## 8 EAS O crystallized &lt;NULL&gt; ## 9 GSOEP A crystallized &lt;NULL&gt; ## 10 GSOEP C crystallized &lt;NULL&gt; ## # ℹ 30 more rows 5.3 Step 2: Run Models for Each Study 5.3.1 Functions 5.3.1.1 Model Function ipd3_study_mod_fun &lt;- function(trait, outcome, type, mod, study, cov){ ## load the data load(sprintf(&quot;%s/data/two_stage/%s_%s_%s.RData&quot;, local_path, trait, outcome, study)) ## compiled Bayesian model to speed up processing and avoid crashing if(type == &quot;Bayesian&quot;) load(sprintf(&quot;%s/results/3_ipd_meta/bayes_sample_mod.RData&quot;, local_path)) ## model formula if (cov == &quot;all&quot;) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if (!cov %in% c(&quot;all&quot;, &quot;none&quot;)) cv &lt;- cov rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;none&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;){rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;))} rhs &lt;- paste(rhs, collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## run the models &amp; save m &lt;- if(type == &quot;Frequentist&quot;){do.call(&quot;lm&quot;, list(formula = f, data = quote(d)))} else {update(m, formula = f, newdata = d, warmup = 1000, iter = 2000, cores = 1)} save(m, file = sprintf(&quot;%s/results/3_ipd_meta/%s/studyModels/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) ## extract model terms and confidence intervals &amp; save rx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) save(rx, file = sprintf(&quot;%s/results/3_ipd_meta/%s/studySummary/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) ## calculate effect sizes for random effects meta analysis es &lt;- ipd3_es_fun(m, type, mod) save(es, file = sprintf(&quot;%s/results/3_ipd_meta/%s/studyEffects/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) ## calculate simple effects if(mod != &quot;none&quot;){ pred.rx &lt;- ipd3_study_simpeff_fun(m, mod, type) save(pred.rx, file = sprintf(&quot;%s/results/3_ipd_meta/%s/studyPredicted/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;es&quot;, &quot;rhs&quot;)) gc() } 5.3.1.2 Effect Size Function ipd3_es_fun &lt;- function(m, type, mod){ ## extract model features needed for meta-analysis ts &lt;- insight::clean_parameters(m)$Cleaned_Parameter ts &lt;- if(mod == &quot;none&quot;) &quot;p_value&quot; else ts[grepl(&quot;p_value.&quot;, ts)] ts &lt;- str_replace(ts, &quot;[.]&quot;, &quot;:&quot;) ## standardize the model # ms &lt;- standardize(m) ## get standardized model coefficients and standard errors ## for bayesian models this is the sd of the posterior estimates es &lt;- if(type == &quot;Frequentist&quot;){ summary(m)$coef[c(&quot;(Intercept)&quot;, ts), c(&quot;Estimate&quot;, &quot;Std. Error&quot;)] %&gt;% as.data.frame() %&gt;% setNames(c(&quot;Estimate&quot;, &quot;SEI&quot;)) } else { fixef(m)[c(&quot;Intercept&quot;, ts), c(&quot;Estimate&quot;, &quot;Est.Error&quot;)] %&gt;% as.data.frame() %&gt;% setNames(c(&quot;Estimate&quot;, &quot;SEI&quot;)) } ## format to standardized format es &lt;- es %&gt;% rownames_to_column(&quot;term&quot;) %&gt;% # t() %&gt;% # as.data.frame() %&gt;% mutate(ni = if(type == &quot;Frequentist&quot;) {nrow(m$model)} else {nrow(m$data)}) return(es) } 5.3.1.3 Study-Specific Simple Effects Function ipd3_study_simpeff_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { unique(fct_lev[,moder][[1]]) } mod_frame &lt;- crossing( p_value = seq(0,10,.5) , modvalue = md_levs ) %&gt;% setNames(c(&quot;p_value&quot;, moder)) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)[1])) } } pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m, newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, predict(m, newdata = mod_frame, interval = &quot;confidence&quot;) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$model)), pred = fit, lower = lwr, upper = upr) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 5.3.2 Run Models # done &lt;- tibble(file = list.files(sprintf(&quot;%s/results/3_ipd_meta/Bayesian/studyModels&quot;, local_path))) %&gt;% # separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;) %&gt;% # mutate(study = str_remove_all(study, &quot;.RData&quot;), # done = &quot;done&quot;) plan(multisession(workers = 12L)) nested_ipd_reg &lt;- tibble(files = list.files(sprintf(&quot;%s/data/two_stage&quot;, local_path))) %&gt;% separate(files, c(&quot;Trait&quot;, &quot;Outcome&quot;, &quot;study&quot;), sep = &quot;_&quot;) %&gt;% filter(!is.na(study)) %&gt;% mutate(study = str_remove(study, &quot;.RData&quot;)) %&gt;% left_join( crossing( study = studies , Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) , Covariate = c(&quot;none&quot;, &quot;all&quot;) ) %&gt;% full_join( crossing( study = studies , Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = &quot;none&quot; , Covariate = c(&quot;none&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;all&quot;) ) ) ) %&gt;% filter(!is.na(Covariate)) %&gt;% # full_join(done) %&gt;% filter(is.na(done)) %&gt;% # filter(type == &quot;Frequentist&quot;) %&gt;% filter(Trait == &quot;N&quot; &amp; study == &quot;HILDA&quot;) %&gt;% mutate(run = # pmap(list(Trait, Outcome, type, Moderator, study, Covariate) future_pmap(list(Trait, Outcome, type, Moderator, study, Covariate) , possibly(ipd3_study_mod_fun, NA_real_) , .progress = T , .options = furrr_options( globals = c(&quot;ipd3_es_fun&quot; , &quot;ipd3_study_simpeff_fun&quot; , &quot;read_path&quot; , &quot;local_path&quot; , &quot;res_path&quot; , &quot;codebook&quot; , &quot;covars&quot; , &quot;moders&quot; , &quot;outcomes&quot; , &quot;studies&quot; , &quot;stdyModers&quot; , &quot;traits&quot; , &quot;data_path&quot;) , packages = c(&quot;lme4&quot; , &quot;broom&quot; , &quot;psych&quot; , &quot;knitr&quot; , &quot;broom.mixed&quot; , &quot;brms&quot; #, &quot;tidybayes&quot; #, &quot;bootpredictlme4&quot; , &quot;rstan&quot; , &quot;estimatr&quot; #, &quot;merTools&quot; , &quot;plyr&quot; , &quot;tidyverse&quot;)) )) closeAllConnections() 5.4 Step 3: Meta-Analyze Results 5.4.1 Functions 5.4.1.0.1 Meta-Analysis Function ipd3_meta_fun &lt;- function(es, type, trait, outcome, mod, cov){ print(paste(type, trait, outcome, mod, cov)) ## bayesian sample models for stability and speed if(type == &quot;Bayesian&quot;) { mr &lt;- if(mod %in% stdyModers$short_name) &quot;metareg&quot; else &quot;meta&quot; load(sprintf(&quot;%s/results/3_ipd_meta/bayes_sample_%s.RData&quot;, local_path, mr)) } ## adding meta-regression values to effect sizes if(mod %in% stdyModers$short_name) { load(sprintf(&quot;%s/data/two_stage/meta_data/%s_%s.RData&quot;, local_path, trait, outcome)) es &lt;- d %&gt;% select(study, one_of(mod)) %&gt;% setNames(c(&quot;study&quot;, &quot;metamod&quot;)) %&gt;% full_join(es) %&gt;% mutate_if(is.character, factor) es0 &lt;- es %&gt;% filter(grepl(&quot;Intercept&quot;, term)) %&gt;% select(-term) } es &lt;- es %&gt;% filter(!grepl(&quot;Intercept&quot;, term)) %&gt;% select(-term) ## base bayesian model # brm(formula = bf(Estimate | se(SEI) ~ 1 + (1 | study)) # , save_pars = &quot;all&quot; # , sample_prior = T # , prior = prior(cauchy(0,1), class = sd) # , iter = 4000) ## base bayesian meta-regression model # update(mt # , formula. = bf(~ . + metamod) # , newdata = es # , sample_prior = T) # run the meta-analytic model f &lt;- if (mod %in% c(&quot;none&quot;, moders$short_name)) &quot;Estimate ~ 1&quot; else &quot;Estimate ~ 1 + metamod&quot; mt &lt;- if(type == &quot;Frequentist&quot;){ rma(formula(f) , sei = SEI , ni = ni , slab = study , data = es) } else { if(!mod %in% stdyModers$short_name) { update(m , newdata = es , iter = 2000 , warmup = 1000 , cores = 1) } else { update(m , formula. = bf(~ . + metamod) , newdata = es , iter = 2000 , warmup = 1000 , cores = 1) } } if(mod %in% stdyModers$short_name) { mt0 &lt;- if(type == &quot;Frequentist&quot;) { rma(formula(f) , sei = SEI , ni = ni , slab = study , data = es0) } else { update(m , formula. = bf(~ . + metamod) , newdata = es0 , iter = 2000 , warmup = 1000 , cores = 1) } } save(mt, file = sprintf(&quot;%s/results/3_ipd_meta/%s/metaModels/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) # pull out and format the fixed effects (i.e. overall effects) fx &lt;- ipd3_meta_fx_fun(mt, type, mod) save(fx, file = sprintf(&quot;%s/results/3_ipd_meta/%s/metaSummary/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) # meta-analysis predictions if(mod %in% stdyModers$short_name) { pred.fx0 &lt;- ipd3_meta_simpeff_fun(mt0, mod, type) %&gt;% setNames(c(mod, &quot;b0_pred&quot;, &quot;b0_lower&quot;, &quot;b0_higher&quot;)) pred.fx1 &lt;- ipd3_meta_simpeff_fun(mt, mod, type) %&gt;% setNames(c(mod, &quot;b1_pred&quot;, &quot;b1_lower&quot;, &quot;b1_higher&quot;)) pred.fx &lt;- crossing( p_value = seq(0, 10, .25) , pred.fx0 %&gt;% full_join(pred.fx1) ) %&gt;% mutate(pred = b0_pred + b1_pred*p_value) %&gt;% select(p_value, all_of(mod), pred) save(pred.fx, file = sprintf(&quot;%s/results/3_ipd_meta/%s/metaPredicted/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) } # pull out and format the cross-study heterogeneity estimates het &lt;- ipd3_meta_rx_fun(mt, type) save(het, file = sprintf(&quot;%s/results/3_ipd_meta/%s/metaHetero/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) rm(list = c(&quot;mt&quot;, &quot;es&quot;, &quot;type&quot;, &quot;trait&quot;, &quot;outcome&quot;, &quot;mod&quot;, &quot;fx&quot;, &quot;rx&quot;)) return(NULL) } 5.4.1.0.2 Meta-Analysis Fixed Effect Function ipd3_meta_fx_fun &lt;- function(mt, type, mod){ trgt &lt;- if(mod %in% c(&quot;none&quot;, stdyModers$short_name)) &quot;p_value&quot; else paste0(&quot;p_value:&quot;, mod) if (type == &quot;Frequentist&quot;){ coef(summary(mt)) %&gt;% rownames_to_column(&quot;term&quot;) %&gt;% select(term, estimate, SE = se, conf.low = ci.lb, conf.high = ci.ub) %&gt;% mutate(study = &quot;Meta-Analytic&quot;, term = mapvalues(term, &quot;intrcpt&quot;, trgt)) } else { fixef(mt) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;term&quot;) %&gt;% select(term, estimate = Estimate, SE = Est.Error, conf.low = Q2.5, conf.high = Q97.5) %&gt;% mutate(study = &quot;Meta-Analytic&quot;, term = mapvalues(term, &quot;Intercept&quot;, trgt)) } } 5.4.1.0.3 Meta-Analysis Heterogeneity Function ipd3_meta_rx_fun &lt;- function(mt, type){ if (type == &quot;Frequentist&quot;){ ## for frequentist, we&#39;ll grab estimates of: ## - tau^2: estimated between-study heterogeneity ## - I^2: total hetero (tau^2) / total hetero + total var (tau^2 + sigma^2) ## - H^2: total var (tau^2 + sigma^2) / total sampling var (sigma^2) ## - QE: Chi^2 dist Cochran&#39;s Q statistic (hetero &gt; 0) ## - QEp: associated p-value for QE for k df mt[c(&quot;tau2&quot;, &quot;se.tau2&quot;, &quot;I2&quot;, &quot;H2&quot;, &quot;QE&quot;, &quot;QEp&quot;)] %&gt;% ldply() %&gt;% pivot_wider(names_from = &quot;.id&quot;, values_from = &quot;V1&quot;) } else { ## for Bayesian, we&#39;ll grab estimates of: ## note, for these, we must estimate some directly ## but will use Bayes Factor to estimate probability of tau^2 &gt; 0 ## this should converge with other estimates but is more appropriate for Bayes ## - tau^2: average estimated between-study hetero across Bayes samples ## - I^2: total hetero (tau^2) / total hetero + total var (tau^2 + sigma^2) ## - H^2: total var (tau^2 + sigma^2) / total sampling var (sigma^2) ## - BF: posterior prob / prior prob tibble(tau2 = summary(mt)$random$study[,&quot;Estimate&quot;]^2 , se.tau2 = summary(mt)$random$study[,&quot;Est.Error&quot;]^2 , I2 = tau2 / (tau2 + var(resid(mt)[,&quot;Estimate&quot;])) , H2 = (tau2 + var(resid(mt)[,&quot;Estimate&quot;])) / var(resid(mt)[,&quot;Estimate&quot;]) , BF = 1/hypothesis(mt, &quot;study__Intercept^2 = 0&quot;, class = &quot;sd&quot;)$hypothesis$Evid.Ratio ) } } 5.4.1.0.4 Meta-Analysis Simple Effects Function ## seemingly only seems to make sense for meta regressions ## the effect sizes uses would be the difference in the association ## associated with a 1 SD change in the moderator ## or with a dummy code?\\ ipd3_meta_simpeff_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data %&gt;% select(metamod) else m$X %&gt;% data.frame() %&gt;% select(-intrcpt) md_cl &lt;- class(d$metamod) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) } # d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { if(type == &quot;Bayesian&quot;){ unique(fct_lev[,moder][[1]]) } else { unique(d) %&gt;% as.matrix() } } if(moder %in% c(&quot;country&quot;, &quot;continent&quot;, &quot;scale&quot;)) rownames(md_levs) &lt;- 1:nrow(md_levs) probs &lt;- tribble( ~wrong , ~correct, &quot;metamodNEO.FFI&quot; , &quot;metamodNEO-FFI&quot;, &quot;metamodBFI.S&quot; , &quot;metamodBFI-S&quot;, &quot;metamodIPIP.NEO&quot;, &quot;metamodIPIP NEO&quot;, &quot;metamodTDA.40&quot; , &quot;metamodTDA-40&quot;, &quot;metamodThe.Netherlands&quot; , &quot;metamodThe Netherlands&quot; ) mod_frame &lt;- if(type == &quot;Bayesian&quot;) { expand.grid( SEI = 0 , metamod = md_levs , stringsAsFactors = F ) } else { md_levs } if(moder %in% c(&quot;scale&quot;, &quot;country&quot;)) colnames(mod_frame) &lt;- mapvalues(colnames(mod_frame), probs$wrong, probs$correct) pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m , newdata = mod_frame , re_formula = NA ) %&gt;% data.frame ) %&gt;% select(metamod, pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( tibble(modvalue = mod_frame), predict(m, mod_frame) %&gt;% data.frame() ) %&gt;% select(modvalue, pred, lower = ci.lb, upper = ci.ub) } if(moder %in% c(&quot;country&quot;, &quot;scale&quot;, &quot;continent&quot;)){ mssng &lt;- if(moder == &quot;country&quot;) &quot;United States&quot; else if(moder == &quot;continent&quot;) &quot;North America&quot; else &quot;NEO-FFI&quot; nms &lt;- str_remove(colnames(mod_frame), &quot;metamod&quot;) trck &lt;- apply(mod_frame, 1, function(x){ if(sum(x) &gt; 0) which(x == 1) else ncol(mod_frame) + 1 }); trck &lt;- c(nms, mssng)[trck] rownames(mod_frame) &lt;- trck pred.fx &lt;- pred.fx %&gt;% mutate(modvalue = trck) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 5.4.2 Run Meta-Analysis and Meta-Regression Models loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/3_ipd_meta/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in effect size data ## first get file names nested_ipd3_meta &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/3_ipd_meta/%s/studyEffects&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!is.na(study)) %&gt;% # filter(Trait == &quot;N&quot;) %&gt;% ## read in the files mutate(study = str_remove(study, &quot;.RData&quot;), data = map2(file, type, ~loadRData(.x, .y, &quot;es&quot;, &quot;studyEffects&quot;))) %&gt;% select(-file) %&gt;% ## unnest effect sizes unnest(data) nested_ipd3_meta ## # A tibble: 1,712 × 10 ## type Outcome Trait Moderator Covariate study term Estimate SEI ni ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Frequentist crystallized A age all EAS (Intercept) 5.67 0.344 788 ## 2 Frequentist crystallized A age all EAS p_value:age -0.0103 0.00881 788 ## 3 Frequentist crystallized A age all GSOEP (Intercept) 8.08 0.206 647 ## 4 Frequentist crystallized A age all GSOEP p_value:age -0.00168 0.00195 647 ## 5 Frequentist crystallized A age all HILDA (Intercept) 5.13 0.110 7755 ## 6 Frequentist crystallized A age all HILDA p_value:age 0.000451 0.000817 7755 ## 7 Frequentist crystallized A age all HRS (Intercept) 5.14 0.112 8432 ## 8 Frequentist crystallized A age all HRS p_value:age -0.00142 0.00185 8432 ## 9 Frequentist crystallized A age all ROS (Intercept) 7.02 0.284 1372 ## 10 Frequentist crystallized A age all ROS p_value:age 0.0136 0.00651 1372 ## # ℹ 1,702 more rows ## group and nest nested_ipd3_meta &lt;- nested_ipd3_meta %&gt;% group_by(type, Trait, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() ## add in meta-moderators, which requires taking original models and ## modifying the Moderator column nested_ipd3_meta &lt;- nested_ipd3_meta %&gt;% filter(Moderator == &quot;none&quot;) %&gt;% select(-Moderator) %&gt;% full_join(crossing( Trait = traits$short_name , Moderator = stdyModers$short_name)) %&gt;% full_join(nested_ipd3_meta) mod &lt;- &quot;age&quot; mr &lt;- if(mod %in% stdyModers$short_name) &quot;metareg&quot; else &quot;meta&quot; ## adding meta-regression values to effect sizes es &lt;- (nested_ipd3_meta %&gt;% filter(Trait == &quot;N&quot; &amp; Covariate == &quot;all&quot; &amp; Moderator == &quot;age&quot; &amp; type == &quot;Bayesian&quot;))$data[[1]] # base bayesian model m &lt;- brm(formula = bf(Estimate | se(SEI) ~ 1 + (1 | study)) , data = es , save_pars = save_pars(all = T) , sample_prior = T , prior = prior(cauchy(0,1), class = sd) , iter = 30 , warmup = 20) save(m, file = sprintf(&quot;%s/results/3_ipd_meta/bayes_sample_meta.RData&quot;, local_path)) mod &lt;- &quot;scale&quot; load(sprintf(&quot;%s/data/two_stage/meta_data/N_episodicMem.RData&quot;, local_path)) es &lt;- d %&gt;% select(study, one_of(mod)) %&gt;% setNames(c(&quot;study&quot;, &quot;metamod&quot;)) %&gt;% full_join(es) m &lt;- brm(formula = bf(Estimate | se(SEI) ~ 1 + metamod + (1 | study)) , data = es , save_pars = save_pars(all = T) , sample_prior = T , prior = prior(cauchy(0,1), class = sd) , iter = 30 , warmup = 20) save(m, file = sprintf(&quot;%s/results/3_ipd_meta/bayes_sample_metareg.RData&quot;, local_path)) rm(list = c(&quot;d&quot;, &quot;es&quot;, &quot;mod&quot;, &quot;m&quot;, &quot;mr&quot;)) plan(multisession(workers = 12L)) nested_ipd3_meta &lt;- nested_ipd3_meta %&gt;% # full_join(done) %&gt;% filter(is.na(done)) %&gt;% filter(type == &quot;Bayesian&quot;) %&gt;% # filter(Moderator %in% c(&quot;scale&quot;, &quot;country&quot;, &quot;continent&quot;)) %&gt;% mutate(metamod = # pmap(list(data, type, Trait, Outcome, Moderator, Covariate) future_pmap(list(data, type, Trait, Outcome, Moderator, Covariate) , possibly(ipd3_meta_fun, NA_real_) , .progress = T , .options = furrr_options( globals = c(&quot;ipd3_meta_fx_fun&quot; , &quot;ipd3_meta_rx_fun&quot; , &quot;ipd3_meta_simpeff_fun&quot; , &quot;read_path&quot; , &quot;local_path&quot; , &quot;res_path&quot; , &quot;codebook&quot; , &quot;covars&quot; , &quot;moders&quot; , &quot;outcomes&quot; , &quot;studies&quot; , &quot;stdyModers&quot; , &quot;traits&quot; , &quot;data_path&quot;) , packages = c(&quot;lme4&quot; , &quot;broom&quot; , &quot;psych&quot; , &quot;knitr&quot; , &quot;broom.mixed&quot; , &quot;brms&quot; #, &quot;tidybayes&quot; #, &quot;bootpredictlme4&quot; , &quot;rstan&quot; , &quot;estimatr&quot; , &quot;metafor&quot; , &quot;plyr&quot; , &quot;tidyverse&quot;)) )) closeAllConnections() nested_ipd3_meta contr_fun &lt;- function(m, std){ cntrm &lt;- c(&quot;p_value = 0&quot;, &quot;p_value + p_value:genderFemale = 0&quot;) (multcomp::glht(m, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% mutate(term = c(&quot;male&quot;, &quot;female&quot;)) %&gt;% rename(estimate = Estimate, conf.low = lwr, conf.high = upr) } res &lt;- nested_ipd3_meta %&gt;% filter(type == &quot;Frequentist&quot; &amp; Covariate == &quot;all&quot;) %&gt;% mutate(res = map2(model, study, contr_fun)) res %&gt;% select(-model) %&gt;% unnest(res) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% filter(sig == &quot;sig&quot;) 5.4.3 Compile Results loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/3_ipd_meta/%s/%s/%s&quot;, local_path, type, folder, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } ## load in effect size data ## first get file names nested_ipd3_meta &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/3_ipd_meta/%s/studyEffects&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!is.na(study)) %&gt;% ## read in the files mutate(study = str_remove(study, &quot;.RData&quot;), studyEff = map2(file, type, ~loadRData(.x, .y, &quot;x&quot;, &quot;studySummary&quot;)), n = map2(file, type, ~loadRData(.x, .y, &quot;es&quot;, &quot;studyEffects&quot;)), n = map_dbl(n, ~(.)$ni[1])) %&gt;% select(-file) %&gt;% unnest(studyEff) %&gt;% group_by(type, Trait, Outcome, Moderator, Covariate) %&gt;% nest(studyEff = study:n) %&gt;% ungroup() ## now we add in the study-level moderators (i.e. meta-regression) nested_ipd3_meta &lt;- nested_ipd3_meta %&gt;% filter(Moderator == &quot;none&quot;) %&gt;% select(-Moderator) %&gt;% full_join(crossing( Trait = traits$short_name , Moderator = stdyModers$short_name)) %&gt;% full_join(nested_ipd3_meta) %&gt;% mutate(file = sprintf(&quot;%s_%s_%s_%s.RData&quot;, Outcome, Trait, Moderator, Covariate), metaEff = map2(file, type, ~loadRData(.x, .y, &quot;fx&quot;, &quot;metaSummary&quot;)), metaHet = map2(file, type, possibly(~loadRData(.x, .y, &quot;het&quot;, &quot;metaHetero&quot;), NA_real_))) %&gt;% select(-file) This results in a nested data frame, with columns: studyEff = standardized study-specific effects from stage 1 regressions metaEff = standardized meta-analytic effect from stage 2 meta-analysis metaHet = Measures of cross-study heterogeneity nested_ipd3_meta ## # A tibble: 410 × 8 ## type Outcome Trait Covariate studyEff Moderator metaEff metaHet ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Frequentist crystallized A age &lt;tibble [18 × 6]&gt; baseAge &lt;df [2 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 2 Frequentist crystallized A age &lt;tibble [18 × 6]&gt; baseYear &lt;df [2 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 3 Frequentist crystallized A age &lt;tibble [18 × 6]&gt; continent &lt;df [3 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 4 Frequentist crystallized A age &lt;tibble [18 × 6]&gt; country &lt;df [4 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 5 Frequentist crystallized A age &lt;tibble [18 × 6]&gt; predInt &lt;df [2 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 6 Frequentist crystallized A age &lt;tibble [18 × 6]&gt; scale &lt;df [2 × 6]&gt; &lt;dbl [1]&gt; ## 7 Frequentist crystallized A all &lt;tibble [30 × 6]&gt; baseAge &lt;df [2 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 8 Frequentist crystallized A all &lt;tibble [30 × 6]&gt; baseYear &lt;df [2 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 9 Frequentist crystallized A all &lt;tibble [30 × 6]&gt; continent &lt;df [3 × 6]&gt; &lt;tibble [1 × 6]&gt; ## 10 Frequentist crystallized A all &lt;tibble [30 × 6]&gt; country &lt;df [4 × 6]&gt; &lt;tibble [1 × 6]&gt; ## # ℹ 400 more rows 5.4.3.0.1 Tables First, we’ll combine study and meta-analytic results. ipd3_meta_res &lt;- nested_ipd3_meta %&gt;% mutate(comEff = map2(studyEff, metaEff, ~(.y) %&gt;% full_join(.x))) %&gt;% select(type, Outcome, Trait, Moderator, Covariate, comEff) %&gt;% unnest(comEff) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (!Moderator %in% stdyModers$short_name &amp; (grepl(&quot;p_value:&quot;, term))) | (Moderator %in% stdyModers$short_name &amp; grepl(&quot;metamod&quot;, term))) %&gt;% mutate(term = str_replace_all(term, &quot;metamod&quot;, paste0(&quot;p_value:&quot;, Moderator)), study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) %&gt;% select(-SE) ipd3_meta_res ## # A tibble: 1,635 × 11 ## type Outcome Trait Moderator Covariate term estimate conf.low conf.high study n ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Frequentist crystallized A baseAge age p_value:baseAge 0.00400 -0.00174 0.00973 Meta-Ana… NA ## 2 Frequentist crystallized A baseYear age p_value:baseYear 0.0102 0.00399 0.0164 Meta-Ana… NA ## 3 Frequentist crystallized A continent age p_value:continentAustralia -0.0489 -0.211 0.113 Meta-Ana… NA ## 4 Frequentist crystallized A continent age p_value:continentEurope -0.177 -0.314 -0.0391 Meta-Ana… NA ## 5 Frequentist crystallized A country age p_value:countryAustralia -0.0309 -0.0775 0.0158 Meta-Ana… NA ## 6 Frequentist crystallized A country age p_value:countryGermany -0.0873 -0.133 -0.0418 Meta-Ana… NA ## 7 Frequentist crystallized A country age p_value:countrySweden -0.268 -0.377 -0.158 Meta-Ana… NA ## 8 Frequentist crystallized A predInt age p_value:predInt -0.0198 -0.0331 -0.00647 Meta-Ana… NA ## 9 Frequentist crystallized A baseAge all p_value:baseAge 0.00164 -0.00104 0.00431 Meta-Ana… NA ## 10 Frequentist crystallized A baseYear all p_value:baseYear 0.00507 0.000720 0.00943 Meta-Ana… NA ## # ℹ 1,625 more rows 5.4.3.0.1.1 Study-Specific Next, we’ll make a table of the results, separately for each moderator. To do this efficiently, we’ll make a function that creates those tables across all combinations. Before calling that function, we’ll do some reformatting and reshaping to get the data ready. ipd3_res_tab &lt;- ipd3_meta_res %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% # significance marker mutate_at(vars(estimate:conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;,.))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), study = factor(study, c(studies_long, &quot;Meta-Analytic&quot;)), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name)) %&gt;% select(type:Covariate, term, study, est) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) %&gt;% select(type:study, E, A, C, N, O) %&gt;% arrange(type, Outcome, Moderator, Covariate, study) ipd3_res_tab ## # A tibble: 414 × 11 ## type Outcome Moderator Covariate term study E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bayesian Crystallized Ability age all p_value:age BASE 0.002&lt;br&gt;[-0.04, 0.04] &lt;NA&gt; &lt;NA&gt; 0.01… -0.0… ## 2 Bayesian Crystallized Ability age all p_value:age EAS -0.005&lt;br&gt;[-0.02, 0.01] -0.0… &lt;str… &lt;str… -0.0… ## 3 Bayesian Crystallized Ability age all p_value:age GSOEP -0.000&lt;br&gt;[-0.004, 0.003] -0.0… 0.00… 0.00… -0.0… ## 4 Bayesian Crystallized Ability age all p_value:age HILDA &lt;strong&gt;0.001&lt;br&gt;[0.000, … 0.00… &lt;str… &lt;str… &lt;str… ## 5 Bayesian Crystallized Ability age all p_value:age HRS -0.002&lt;br&gt;[-0.005, 0.001] -0.0… &lt;str… 0.00… &lt;str… ## 6 Bayesian Crystallized Ability age all p_value:age LASA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; -0.0… &lt;NA&gt; ## 7 Bayesian Crystallized Ability age all p_value:age MAP -0.002&lt;br&gt;[-0.009, 0.005] &lt;NA&gt; 0.00… -0.0… &lt;NA&gt; ## 8 Bayesian Crystallized Ability age all p_value:age MARS &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; -0.0… &lt;NA&gt; ## 9 Bayesian Crystallized Ability age all p_value:age OCTO-Twin -0.01&lt;br&gt;[-0.06, 0.03] &lt;NA&gt; &lt;NA&gt; 0.03… &lt;NA&gt; ## 10 Bayesian Crystallized Ability age all p_value:age ROS 0.004&lt;br&gt;[-0.007, 0.01] &lt;str… 0.00… &lt;str… &lt;str… ## # ℹ 404 more rows ipd3_stdmeta_table_fun &lt;- function(d, type, moder, cov){ cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) if(!grepl(&quot;djust&quot;, cv)) cv &lt;- paste(cv, &quot;Adjusted&quot;) md &lt;- mapvalues(moder, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- rep(1,6); names(cs) &lt;- c(&quot; &quot;, traits$short_name) cap &lt;- if(moder == &quot;none&quot;) { sprintf(&quot;&lt;strong&gt;Table X.&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Method 3 Pooled Regression Using Random Effects: Study and Meta-Analytic Estimates of %s Personality-Cognitive Domain Relationships&lt;/em&gt;&quot;, cv) } else { sprintf(&quot;&lt;strong&gt;Table X.&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Method 3 Pooled Regression Using Random Effects: Study and Meta-Analytic %s Moderation of %s Personality-Cognitive Domain Relationships&lt;/em&gt;&quot;, md, cv) } tab &lt;- d %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; , escape = F , booktabs = T , col.names = c(&quot;Study&quot;, rep(&quot;$\\\\beta$ [CI]&quot;, 5)) , align = c(&quot;r&quot;, rep(&quot;c&quot;, 5)) , caption = cap) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs) for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/3_ipd_meta/%s/tables/study specific/%s_%s.html&quot;, local_path, type, moder, cov)) return(tab) } ipd3_std_tab &lt;- ipd3_res_tab %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% select(-term) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator, Covariate), ipd3_stdmeta_table_fun)) 5.4.3.0.1.2 Meta-Analytic ipd3_tab_fun &lt;- function(d, type, moder){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term)) == 1) rep(1,6) else c(2, rep(1,5)) names(cs) &lt;- c(&quot; &quot;, traits$long_name) cln &lt;- if(length(unique(d$term)) == 1) c(&quot;CovariaCtes&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) # cln &lt;- if(length(unique(d$term)) == 1) c(&quot;Covariates&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) al &lt;- if(length(unique(d$term)) == 1) c(&quot;r&quot;, rep(&quot;c&quot;, 5)) else c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) if(length(unique(d$term)) == 1) d &lt;- d %&gt;% select(-term) cap &lt;- if(md == &quot;none&quot;) &quot;&lt;strong&gt;Table X.&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Method 3 Pooled Regression Using Random Effects: Meta-Analytic Effects of Personality-Crystallized Domain Associations&lt;/em&gt;&quot; else sprintf(&quot;&lt;strong&gt;Table X.&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Method 3 Pooled Regression Using Random Effects: Meta-Analytic %s Moderation of Personality-Crystallized Domain Associations&lt;/em&gt;&quot;, md) tab &lt;- d %&gt;% arrange(Outcome) %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/3_ipd_meta/%s/tables/overall/%s.html&quot; , local_path, type, md)) return(tab) } ipd3_meta_res_tab &lt;- ipd3_res_tab %&gt;% filter(study == &quot;Meta-Analytic&quot;) %&gt;% select(-study) %&gt;% mutate(term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, str_remove_all(stdyModers$short_term, &quot; &quot;), stdyModers$long_term), term = mapvalues(term, str_replace_all(stdyModers$short_term, &quot;-&quot;, &quot;M&quot;), stdyModers$long_term), term = mapvalues(term, moders$short_term, moders$long_term), term = mapvalues(term, moders$short_name, moders$long_term), Covariate = mapvalues(Covariate, covars$short_name, covars$long_name)) %&gt;% arrange(Outcome, term, Covariate) ipd3_meta_res_tab %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd3_tab_fun)) ## # A tibble: 20 × 4 ## type Moderator data tab ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Bayesian age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 2 Frequentist age &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 3 Bayesian continent &lt;tibble [10 × 8]&gt; &lt;kablExtr [1]&gt; ## 4 Frequentist continent &lt;tibble [10 × 8]&gt; &lt;kablExtr [1]&gt; ## 5 Bayesian country &lt;tibble [20 × 8]&gt; &lt;kablExtr [1]&gt; ## 6 Frequentist country &lt;tibble [20 × 8]&gt; &lt;kablExtr [1]&gt; ## 7 Bayesian education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 8 Frequentist education &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 9 Bayesian gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 10 Frequentist gender &lt;tibble [2 × 8]&gt; &lt;kablExtr [1]&gt; ## 11 Bayesian none &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 12 Frequentist none &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 13 Bayesian predInt &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 14 Frequentist predInt &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 15 Bayesian scale &lt;tibble [30 × 8]&gt; &lt;kablExtr [1]&gt; ## 16 Frequentist scale &lt;tibble [30 × 8]&gt; &lt;kablExtr [1]&gt; ## 17 Bayesian baseAge &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 18 Frequentist baseAge &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 19 Bayesian baseYear &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ## 20 Frequentist baseYear &lt;tibble [5 × 8]&gt; &lt;kablExtr [1]&gt; ipd3_tab_fun &lt;- function(d, type, cov){ # long outcome name covar &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- sprintf(&quot;Method 3 Pooled Regression Using Random Effects: Meta-Analytic Estimates of %s Personality-Crystallized Domain Associations&quot;, cov) # kable the table tab &lt;- d %&gt;% select(-Moderator) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/3_ipd_meta/%s/tables/key terms/%s.html&quot; , local_path, type, covar)) return(tab) # return the html table } ipd3_fx_tab2 &lt;- ipd3_res_tab %&gt;% filter(study == &quot;Meta-Analytic&quot;) %&gt;% select(-study) %&gt;% mutate(term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, str_remove_all(stdyModers$short_term, &quot; &quot;), stdyModers$long_term), term = mapvalues(term, str_replace_all(stdyModers$short_term, &quot;-&quot;, &quot;M&quot;), stdyModers$long_term), term = mapvalues(term, moders$short_term, moders$long_term), term = mapvalues(term, moders$short_name, moders$long_term), Moderator = factor(Moderator, levels = c(moders$short_name, stdyModers$short_name), labels = c(moders$long_name, stdyModers$long_name)), Covariate = mapvalues(Covariate, covars$short_name, covars$long_name)) %&gt;% arrange(Outcome, Moderator, term, Covariate) %&gt;% filter(Covariate %in% c(&quot;Unadjusted&quot;, &quot;Fully Adjusted&quot;)) %&gt;% group_by(Outcome, type, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Covariate), ipd3_tab_fun)) # save(ipd1a_fx_tab, ipd1a_fx_tab2, ipd1a_res, file = sprintf(&quot;%s/manuscript/results/ipd1b_fx_tab.RData&quot;, res_path)) 5.4.3.0.1.3 All Model Terms ipd3_mod_tab &lt;- nested_ipd3_meta %&gt;% select(-metaEff, -metaHet) %&gt;% unnest(studyEff) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_replace_all(term, &quot;metamod&quot;, paste0(&quot;p_value:&quot;, Moderator))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig, -n) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd3_mod_tab_fun &lt;- function(d, type, out, moder, cov){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- if(md == &quot;none&quot;) &quot;3 Separate Models Followed Random Effects Meta-Analysis: All Model Estimates of Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;3 Separate Models Followed Random Effects Meta-Analysis: All Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) d &lt;- d %&gt;% arrange(study, term) rs &lt;- d %&gt;% group_by(study) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # kable the table tab &lt;- d %&gt;% select(-study) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) for(i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$study[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/3_ipd_meta/%s/tables/all terms/%s-%s-%s.html&quot; , local_path, type, o, md, cv)) return(tab) # return the html table } ipd3_mod_tab2 &lt;- ipd3_mod_tab %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ipd3_mod_tab_fun)) ipd3_meta_all &lt;- nested_ipd3_meta %&gt;% select(-studyEff, -metaHet) %&gt;% unnest(metaEff) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name)), Covariate = ifelse(Moderator != &quot;None&quot; &amp; Covariate == &quot;None&quot;, Moderator, Covariate), Covariate = factor(Covariate, moders$short_name, str_wrap(moders$long_name, 15)), term = str_replace_all(term, &quot;metamod&quot;, paste0(&quot;p_value:&quot;, Moderator))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig, -SE) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) %&gt;% group_by(type, Outcome, Covariate) %&gt;% nest() %&gt;% ungroup() 5.4.3.0.1.4 Heterogeneity loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/3_ipd_meta/%s/%s/%s&quot;, local_path, type, folder, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_ipd3_het &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/3_ipd_meta/%s/metaHetero&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Covariate = str_remove(Covariate, &quot;.RData&quot;), het = map2(file, type, possibly(~loadRData(.x, .y, &quot;het&quot;, &quot;metaHetero&quot;), NA_real_))) %&gt;% filter(!is.na(het)) %&gt;% select(-file) round_fun &lt;- function(x){ ifelse(x &lt; .001 &amp; x &gt; 0, &quot;&amp;lt; .001&quot; , ifelse(x &gt; -.001 &amp; x &lt; 0, &quot;&amp;gt; -.001&quot; , ifelse(abs(x) &lt; .01, sprintf(&quot;%.3f&quot;, x) , sprintf(&quot;%.2f&quot;, x)))) } ip3_hetero_tab_fun &lt;- function(d, type, out, mod, cov){ moder &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d2 &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% mutate_at(vars(-Trait), round_fun) %&gt;% arrange(Trait) cap &lt;- if(mod == &quot;none&quot;) &quot;Heterogeneity Estimates of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;Heterogeneity Estimates for Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, moder) cap &lt;- sprintf(&quot;&lt;strong&gt;Table SX&lt;/strong&gt;&lt;br&gt;&lt;em&gt;%s&lt;/em&gt;&quot;, cap) tab &lt;- d2 %&gt;% kable(. , &quot;html&quot; , align = c(&quot;r&quot;, rep(&quot;c&quot;, ncol(d2)-1)) , caption = cap , escape = F ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) save_kable(tab, file = sprintf(&quot;%s/results/3_ipd_meta/%s/tables/heterogeneity/%s-%s-%s.html&quot;, local_path, type, out, mod, cov)) return(tab) } nested_ipd3_het_tab &lt;- nested_ipd3_het %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% group_by(type) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(het) %&gt;% group_by(Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup())) %&gt;% unnest(data) %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ip3_hetero_tab_fun)) 5.4.4 Figures 5.4.4.0.0.1 Overall Forest ipd3_fx_plot_fun &lt;- function(df, mod, type, cov){ m &lt;- mapvalues(mod, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- if(d &gt; .01) round(c(0-d-(d/5), 0, 0+d+(d/5)),2) else round(c(0-d-(d/5), 0, 0+d+(d/5)),3) # lim_high &lt;- lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, mod)} titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cv, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cv, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- df %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high)) %&gt;% ggplot(aes(x = Outcome, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(1.2, .85)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;blue&quot;, &quot;black&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .25, color = &quot;gray50&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL , y = &quot;Estimate (POMP)&quot; , title = titl , subtitle = &quot;Method 3: Pooled Regression Using Random Effects&quot; ) + guides(size = &quot;none&quot;, color = &quot;none&quot;) + facet_grid(~Trait, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5), plot.subtitle = element_text(size = rel(1.1), hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(df$Outcome)); ht2 &lt;- length(unique(df$term)) local_path &lt;- length(unique(df$Trait)) ggsave(file = sprintf(&quot;%s/results/3_ipd_meta/%s/figures/overall forest/%s_%s_fixed.png&quot;, local_path, type, m, cov), width = local_path*2, height = 1.25*ht + .75*ht2) rm(p) gc() return(T) } nested_ipd3_meta %&gt;% select(-studyEff, -metaHet) %&gt;% unnest(metaEff) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), sig = factor(sig, levels = c(&quot;sig&quot;,&quot;ns&quot;)), Trait = factor(Trait, levels = traits$short_name), Outcome = factor(Outcome, levels = outcomes$short_name, labels = str_wrap(outcomes$long_name, 15)), Moderator = factor(Moderator, levels = c(moders$short_name, stdyModers$short_name), labels = c(moders$long_name, stdyModers$long_name)), Outcome = forcats::fct_rev(Outcome)) %&gt;% filter(type == &quot;Frequentist&quot; &amp; Moderator == &quot;None&quot;) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(pmap(list(data, Moderator, type, Covariate), ipd3_fx_plot_fun)) 5.4.4.0.0.2 Study-Specific Forest ipd3_rx_plot_fun &lt;- function(df, outcome, mod, type, cov, trait){ print(paste(outcome, mod)) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- round(c(0-d-(d/5), 0, 0+d+(d/5)),2) lab &lt;- str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){trt} else {sprintf(&quot;%s x %s&quot;, trt, m)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} df &lt;- df %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) df &lt;- df %&gt;% full_join(tibble(study = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) stds &lt;- df$study[!df$study %in% c(&quot;Meta-Analytic&quot;, &quot; &quot;)] df &lt;- df %&gt;% mutate(study = factor(study, rev(c(&quot; &quot;, stds, &quot;Meta-Analytic&quot;))) # , conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low) # , conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot; , ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;neither&quot;)) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) # , study = factor(study, levels = str_remove_all(c(&quot;Overall&quot;, studies_long), &quot;-&quot;), labels = c(&quot;Overall&quot;, studies_long)) # Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), , type = ifelse(study == &quot;Meta-Analytic&quot;, &quot;fixed&quot;, &quot;random&quot;)) p1 &lt;- df %&gt;% ggplot(aes(x = study, y = estimate)) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high) , position = &quot;dodge&quot; , width = .2) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(lb == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + annotate(&quot;rect&quot;, xmin = length(stds) + 1.6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = &quot; &quot; ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1)) d2 &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high) , ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^0.&quot;, &quot;.&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^-0.&quot;, &quot;-.&quot;)) %&gt;% mutate(est = ifelse(study != &quot; &quot;, sprintf(&quot;%s [%s, %s] &quot;, estimate, conf.low, conf.high), &quot;&quot;) , n = as.character(n) ) %&gt;% select(study, n, est) %&gt;% pivot_longer(cols = c(n, est), names_to = &quot;est&quot;, values_to = &quot;value&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = study, y = est)) + geom_text(aes(label = value), hjust = .5, size = 3.5) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(stds) + 1.75, y = &quot;est&quot;, hjust = .5, vjust = 0) + annotate(&quot;text&quot;, label = &quot;N&quot;, x = length(stds) + 1.75, y = &quot;n&quot;, hjust = .5, vjust = 0) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + coord_flip() + theme_void() + theme(plot.title = element_text(face = &quot;bold&quot;, hjust = 0) , axis.text = element_blank() , axis.ticks = element_blank() , axis.title = element_blank()) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p3 &lt;- cowplot::plot_grid(p1, p2 , rel_widths = c(.5, .5)#c(.4, .6) , align = &quot;h&quot; ) # p &lt;- cowplot::plot_grid(ttl, subttl, p3, rel_heights = c(.05, .05, .9), nrow = 3) p &lt;- cowplot::plot_grid(ttl, p3, rel_heights = c(.05, .95), nrow = 2) save(p , file = sprintf(&quot;%s/results/3_ipd_meta/%s/figures/study specific forest/rdata/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) gc() return(p) } ## fixed effects nested_ipd3_reg_fp &lt;- ipd3_meta_res %&gt;% filter(Moderator %in% moders$short_name) %&gt;% ## filter key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;) , study = mapvalues(study, studies_long, studies_sp, warn_missing = F)) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, type, Covariate, Trait) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, type, Covariate, Trait), ipd3_rx_plot_fun)) ipd3_rx_plot_comb_fun &lt;- function(outcome, cov, mod, type, d){ o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) titl &lt;- paste0(o, &quot;,&quot;) titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(titl, cv, &quot;Adjusted&quot;, collapse = &quot;, &quot;) else paste(titl, cv, collapse = &quot;, &quot;) p1 &lt;- plot_grid( d$p[[1]] , d$p[[2]] , d$p[[3]] , d$p[[4]] , d$p[[5]] , nrow = 3 , ncol = 2 , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) my_theme &lt;- function(...) { theme_classic() + theme(plot.subtitle = element_text(hjust = 0)) } subtitle_theme &lt;- calc_element(&quot;subplot.title&quot;, my_theme()) subttl &lt;- ggdraw() + draw_label( &quot;Method 3: Two-Stage Individual Participant Meta-Analysis&quot;, fontfamily = subtitle_theme$family, fontface = subtitle_theme$face, size = subtitle_theme$size ) p &lt;- cowplot::plot_grid(ttl, subttl, p1, rel_heights = c(.03, .03, .94), nrow = 3) ggsave(p , file = sprintf(&quot;%s/results/3_ipd_meta/%s/figures/study specific forest/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) ggsave(p , file = sprintf(&quot;%s/results/3_ipd_meta/%s/figures/study specific forest/%s_%s_%s.pdf&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) return(T) } nested_ipd3_reg_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(Trait) %&gt;% select(-data) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(Outcome, Covariate, Moderator, type, data), ipd3_rx_plot_comb_fun)) 5.4.4.1 Overall Simple Effects Plots loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/3_ipd_meta/%s/%s/%s&quot;, local_path, type, folder, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } ## load in effect size data ## first get file names nested_ipd3_meta &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/3_ipd_meta/%s/studyPredicted&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!is.na(study)) %&gt;% ## read in the files mutate(study = str_remove(study, &quot;.RData&quot;), pred.rx = map2(file, type, ~loadRData(.x, .y, &quot;pred.rx&quot;, &quot;studyPredicted&quot;)) , n = map2(file, type, ~loadRData(.x, .y, &quot;es&quot;, &quot;studyEffects&quot;)) , n = map_dbl(n, ~(.)$ni[1])) %&gt;% select(-file) %&gt;% unnest(pred.rx) %&gt;% group_by(type, Trait, Outcome, Moderator, Covariate) %&gt;% nest(studyPred = study:n) %&gt;% ungroup() ipd3_pred_fx_fun &lt;- function(d, mod, type, outcome, trait, cov){ d &lt;- d %&gt;% unclass %&gt;% data.frame d$mod_value &lt;- d[,mod] d &lt;- d %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(d$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){ d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value)) } else{ d2 &lt;- d %&gt;% select(study, mod_value) %&gt;% distinct() %&gt;% arrange(study, mod_value) if(mod == &quot;age&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;-10 yrs&quot;, &quot;M&quot;, &quot;+10 yrs&quot;))) else if(mod == &quot;baseYear&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;1990&quot;, &quot;200)0&quot;, &quot;2010&quot;))) else if(mod == &quot;baseAge&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;50&quot;, &quot;60&quot;, &quot;70&quot;))) else if(mod == &quot;predInt&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;5 yrs&quot;, &quot;+5 yrs&quot;))) else if(mod == &quot;education&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;))) else d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) d &lt;- d %&gt;% full_join(d2) %&gt;% ungroup() } pred.fx &lt;- d %&gt;% group_by(p_value, mod_fac) %&gt;% summarize_at(vars(pred, lower, upper), ~weighted.mean(., n)) %&gt;% ungroup() save(pred.fx, file = sprintf(&quot;%s/results/3_ipd_meta/%s/metaPredicted/%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov)) } nested_ipd3_meta %&gt;% # filter(Moderator == &quot;baseAge&quot;) %&gt;% mutate(pred = pmap(list(studyPred, Moderator, type, Outcome, Trait, Covariate), ipd3_pred_fx_fun)) ipd3_se_plot_fun &lt;- function(d, outcome, mod, cov, type){ # print(paste(int, mod, cov, random, imp)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s&quot;, o)} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} d &lt;- d %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;)), study = factor(study, levels = stdcolors$studies)) std &lt;- unique(d$study) # cols &lt;- (stdcolors %&gt;% filter(studies %in% std))$colors d &lt;- d %&gt;% unclass %&gt;% data.frame d$mod_value &lt;- d[,mod] d &lt;- d %&gt;% select(-all_of(mod)) %&gt;% as_tibble d &lt;- if(class(d$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){ d %&gt;% mutate(mod_fac = factor(mod_value)) } else{ d %&gt;% full_join( d %&gt;% select(Trait,study, mod_value) %&gt;% distinct() %&gt;% arrange(study, mod_value) %&gt;% group_by(Trait, study) %&gt;% mutate(mod_fac = factor(c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;), levels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() ) } lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(d$mod_fac))] ht &lt;- length(unique(d$mod_fac)) p &lt;- d %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name)) %&gt;% ggplot(aes(x = p_value, y = pred, group = interaction(Trait, mod_fac), linetype = mod_fac)) + # geom_line(aes(color = study # , group = interaction(study, mod_fac) # , linetype = study) # , size = 1) + # geom_ribbon(aes(fill = study # , group = interaction(study, mod_fac) # , ymin = lower # , ymax = upper) # , alpha = .25) + stat_smooth(aes(weight = n, linetype = mod_fac, fill = mod_fac) , method = &quot;lm&quot; , formula = y~x , size = 1 , color = &quot;black&quot; ) + facet_wrap(~Trait, ncol = 2) + scale_y_continuous(limits = c(4,10) , breaks = c(4, 6, 8, 10) , labels = c(4, 6, 8, 10)) + # scale_color_manual(values = cols) + scale_linetype_manual(values = lt) + labs(x = &quot;Personality Score (POMP)&quot; , y = &quot;Cognition Score (POMP)&quot; # , color = &quot;Study&quot; , fill = m , linetype = m , title = titl , subtitle = &quot;Method 3: Two-Stage Individual Participant Meta-Analysis&quot; ) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/3_ipd_meta/%s/figures/overall simple effects/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov), width = 6, height = 6) } nested_ipd3_meta %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(studyPred)) , p = pmap(list(data, Outcome, Moderator, Covariate, type), ipd3_se_plot_fun)) 5.4.4.2 Study-Specific Simple Effects Plots ipd3_std_se_plot_fun &lt;- function(d, outcome, trait, mod, cov, type){ # print(paste(int, mod, cov, random, imp)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} d &lt;- d %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;)), study = factor(study, levels = stdcolors$studies)) std &lt;- unique(d$study) cols &lt;- (stdcolors %&gt;% filter(studies %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies %in% std))$lt d &lt;- d %&gt;% unclass %&gt;% data.frame d$mod_value &lt;- d[,mod] d &lt;- d %&gt;% select(-all_of(mod)) %&gt;% as_tibble d &lt;- if(class(d$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){ d %&gt;% mutate(mod_fac = factor(mod_value)) } else{ d %&gt;% full_join( d %&gt;% select(study, mod_value) %&gt;% distinct() %&gt;% arrange(study, mod_value) %&gt;% group_by(study) %&gt;% mutate(mod_fac = factor(c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;), levels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() ) } ht &lt;- length(unique(d$mod_fac)) p &lt;- d %&gt;% ggplot(aes(x = p_value, y = pred)) + geom_line(aes(color = study , group = interaction(study, mod_fac) , linetype = study) , size = 1) + # geom_ribbon(aes(fill = study # , group = interaction(study, mod_fac) # , ymin = lower # , ymax = upper) # , alpha = .25) + stat_smooth(aes(weight = n) , method = &quot;lm&quot; , formula = y~x , size = 1.2 , color = &quot;darkslateblue&quot; ) + scale_y_continuous(limits = c(4,10) , breaks = c(4, 6, 8, 10) , labels = c(4, 6, 8, 10)) + scale_color_manual(values = cols) + scale_linetype_manual(values = lt) + labs(x = &quot;Personality Score (POMP)&quot; , y = &quot;Cognition Score (POMP)&quot; , color = &quot;Study&quot; , fill = &quot;Study&quot; , linetype = &quot;Study&quot; , title = titl , subtitle = &quot;Method 3: Two-Stage Individual Participant Meta-Analysis&quot; ) + facet_wrap(~mod_fac) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, hjust = .5, size = rel(.95)) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/3_ipd_meta/%s/figures/study specific simple effects/%s_%s_%s_%s.png&quot;, local_path, type, outcome, trt, mod, cov), width = 3*ht, height = 5) } nested_ipd3_meta %&gt;% mutate(p = pmap(list(studyPred, Outcome, Trait, Moderator, Covariate, type), ipd3_std_se_plot_fun)) load(&quot;~/Documents/projects/data synthesis/crystallized/results/3_ipd_meta/Frequentist/metaModels/crystallized_C_country_all.RData&quot;) coef(mt) ## intrcpt metamodAustralia metamodGermany metamodSweden ## 0.06433784 -0.06106685 -0.06322996 -0.18061653 cntrm &lt;- rbind( c(1,0,0,0) , c(1,1,0,0) , c(1,0,1,0) , c(1,0,0,1) ); rownames(cntrm) &lt;- c(&quot;United States&quot;, &quot;Australia&quot;, &quot;Germany&quot;, &quot;Sweden&quot;) (multcomp::glht(mt, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = rownames(cntrm)) %&gt;% select(-cntr) %&gt;% mutate(est = ifelse(abs(Estimate) &lt; .01, sprintf(&quot;b = %.3f, 95%% CI [%.3f, %.3f]&quot;, Estimate, lwr, upr), sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr))) ## Estimate lwr upr term est ## 1 0.064337841 0.04167694 0.08699874 United States b = 0.06, 95% CI [0.04, 0.09] ## 2 0.003270996 -0.02297616 0.02951815 Australia b = 0.003, 95% CI [-0.023, 0.030] ## 3 0.001107879 -0.05502738 0.05724314 Germany b = 0.001, 95% CI [-0.055, 0.057] ## 4 -0.116278686 -0.20058736 -0.03197002 Sweden b = -0.12, 95% CI [-0.20, -0.03] load(&quot;~/Documents/projects/data synthesis/crystallized/results/3_ipd_meta/Frequentist/metaModels/crystallized_C_scale_all.RData&quot;) coef(mt) ## intrcpt metamodBFI-S metamodEysenck metamodIPIP NEO metamodMIDI metamodTDA-40 ## 0.08889284 -0.08778496 -0.20517153 -0.12764963 -0.02316003 -0.08562185 cntrm &lt;- rbind( c(1,0,0,0,0,0) # NEO-FFI , c(1,1,0,0,0,0) # BFI-S , c(1,0,1,0,0,0) # Eysenck , c(1,0,0,1,0,0) # IPIP NEO , c(1,0,0,0,1,0) # MIDI , c(1,0,0,0,0,1) # TDA-40 ); rownames(cntrm) &lt;- c(&quot;NEO-FFI&quot;, &quot;BFI-S&quot;, &quot;Eysenck&quot;, &quot;IPIP NEO&quot;, &quot;MIDI&quot;, &quot;TDA-40&quot;) (multcomp::glht(mt, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = rownames(cntrm)) %&gt;% select(-cntr) %&gt;% mutate(est = ifelse(abs(Estimate) &lt; .01, sprintf(&quot;b = %.3f, 95%% CI [%.3f, %.3f]&quot;, Estimate, lwr, upr), sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr))) ## Estimate lwr upr term est ## 1 0.088892841 0.03486531 0.14292037 NEO-FFI b = 0.09, 95% CI [0.03, 0.14] ## 2 0.001107879 -0.05488928 0.05710503 BFI-S b = 0.001, 95% CI [-0.055, 0.057] ## 3 -0.116278686 -0.20049547 -0.03206191 Eysenck b = -0.12, 95% CI [-0.20, -0.03] ## 4 -0.038756793 -0.13781345 0.06029986 IPIP NEO b = -0.04, 95% CI [-0.14, 0.06] ## 5 0.065732812 0.04024951 0.09121611 MIDI b = 0.07, 95% CI [0.04, 0.09] ## 6 0.003270996 -0.02267949 0.02922148 TDA-40 b = 0.003, 95% CI [-0.023, 0.029] load(&quot;~/Documents/projects/data synthesis/crystallized/results/3_ipd_meta/Frequentist/metaModels/crystallized_N_scale_all.RData&quot;) coef(mt) ## intrcpt metamodBFI-S metamodDPQ metamodEysenck metamodIPIP NEO metamodMIDI metamodTDA-40 ## -0.11303919 0.07722236 0.06822839 0.07197000 0.06484409 0.09060320 -0.00330891 cntrm &lt;- rbind( c(1,0,0,0,0,0,0) # NEO-FFI , c(1,1,0,0,0,0,0) # BFI-S , c(1,0,1,0,0,0,0) # DPQ , c(1,0,0,1,0,0,0) # Eysenck , c(1,0,0,0,1,0,0) # IPIP NEO , c(1,0,0,0,0,1,0) # MIDI , c(1,0,0,0,0,0,1) # TDA-40 ); rownames(cntrm) &lt;- c(&quot;NEO-FFI&quot;, &quot;BFI-S&quot;, &quot;DPQ&quot;, &quot;Eysenck&quot;, &quot;IPIP NEO&quot;, &quot;MIDI&quot;, &quot;TDA-40&quot;) (multcomp::glht(mt, cntrm) %&gt;% # multcomp hypothesis function confint(., calpha = multcomp::univariate_calpha()))$confint %&gt;% data.frame() %&gt;% data.frame() %&gt;% rownames_to_column(&quot;cntr&quot;) %&gt;% mutate(term = rownames(cntrm), sig = ifelse(sign(lwr) == sign(upr), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% select(-cntr) %&gt;% mutate(est = ifelse(abs(Estimate) &lt; .01, sprintf(&quot;b = %.3f, 95%% CI [%.3f, %.3f]&quot;, Estimate, lwr, upr), sprintf(&quot;b = %.2f, 95%% CI [%.2f, %.2f]&quot;, Estimate, lwr, upr))) %&gt;% arrange(sig, Estimate) ## Estimate lwr upr term sig est ## 1 -0.04819510 -0.14247152 0.046081326 IPIP NEO ns b = -0.05, 95% CI [-0.14, 0.05] ## 2 -0.04106919 -0.10615703 0.024018652 Eysenck ns b = -0.04, 95% CI [-0.11, 0.02] ## 3 -0.03581683 -0.08170762 0.010073957 BFI-S ns b = -0.04, 95% CI [-0.08, 0.01] ## 4 -0.11634810 -0.14179851 -0.090897687 TDA-40 sig b = -0.12, 95% CI [-0.14, -0.09] ## 5 -0.11303919 -0.15448612 -0.071592256 NEO-FFI sig b = -0.11, 95% CI [-0.15, -0.07] ## 6 -0.04481079 -0.08127859 -0.008343002 DPQ sig b = -0.04, 95% CI [-0.08, -0.01] ## 7 -0.02243598 -0.04344011 -0.001431855 MIDI sig b = -0.02, 95% CI [-0.04, -0.00] 5.4.5 Table Meta-Analytic Heterogeneity Relative to previous tables, this is slightly complicated because Frequentist and Bayesian meta-analysis don’t use the same methods for estimating heterogeneity. ipd3_het_tab &lt;- nested_ipd3_meta %&gt;% select(-studyEff, -metaEff) %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name)) %&gt;% arrange(type, Outcome, Trait, Moderator) %&gt;% group_by(type, Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(metaHet))) ipd3_het_tab ## frequentist ipd3_het_tab$data[[nrow(ipd3_het_tab)]] ## bayesian ipd3_het_tab$data[[1]] ipd3_het_tab_fun &lt;- function(d, type, moder){ rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) if(type == &quot;Frequentist&quot;){ d %&gt;% mutate_at(vars(tau2, QEp), ~ifelse(. &lt; .001, &quot;&lt; 0.001&quot;, sprintf(&quot;%.3f&quot;, .))) %&gt;% mutate_at(vars(I2:QE), ~sprintf(&quot;%.2f&quot;, .)) %&gt;% select(Trait, tau2, I2, H2, QE, QEp) %&gt;% kable(., &quot;html&quot; , escape = F , digits = 2 , col.names = c(&quot;Trait&quot;, &quot;$\\\\tau^2$&quot;, &quot;$I^2$&quot;, &quot;$H^2$&quot;, &quot;&lt;em&gt;Q&lt;/em&gt;&quot;, &quot;&lt;em&gt;p&lt;/em&gt;&quot;) , align = c(&quot;r&quot;, rep(&quot;c&quot;,5)) , caption = sprintf(&quot;Table X. Heterogeneity estimates for %s Models with %s Moderator&quot;, type, moder)) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) } else{ d %&gt;% mutate_at(vars(tau2, BF), ~ifelse(. &lt; .001, &quot;&lt; 0.001&quot;, sprintf(&quot;%.3f&quot;, .))) %&gt;% mutate_at(vars(I2, H2), ~sprintf(&quot;%.2f&quot;, .)) %&gt;% select(Trait, tau2, I2, H2, BF) %&gt;% kable(., &quot;html&quot; , escape = F , digits = 2 , col.names = c(&quot;Trait&quot;, &quot;$\\\\tau^2$&quot;, &quot;$I^2$&quot;, &quot;$H^2$&quot;, &quot;BF&quot;) , align = c(&quot;r&quot;, rep(&quot;c&quot;,4)) , caption = sprintf(&quot;Table X. Heterogeneity estimates for %s Models with %s Moderator&quot;, type, moder)) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) } } 5.5 Sample Results Section We examined estimates of overall prospective associations between Big Five personality characteristics and crystallized abilities as well as participant and sample-level moderators of those associations using a two-stage individual participant meta-analysis of 11 studies. This allowed us to estimate both sample-specific and overall prospective associations between personality characteristics and cognitive ability as well as heterogeneity in those estimates. Fully adjusted Big Five personality trait-crystallized ability associations as well as participant- and sample-level moderators of these associations can be found in Table S5. Of the 20 key participant-level personality-crystallized ability associations and moderators of those associations, two (10%) were significant. Specifically, Openness was positively associated with later crystallized abilities, and gender moderated this association. Table 5.1: Method 3 Pooled Regression Using Random Effects: Meta-Analytic Estimates of Fully Adjusted Personality-Crystallized Domain Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Term b [CI] b [CI] b [CI] b [CI] b [CI] None Personality 0.01[-0.02, 0.05] 0.02[-0.001, 0.03] 0.02[-0.03, 0.07] -0.07[-0.10, -0.04] 0.17[0.10, 0.25] Age Age -0.000[-0.003, 0.002] -0.001[-0.003, 0.002] -0.000[-0.005, 0.004] 0.000[-0.004, 0.005] 0.001[-0.006, 0.007] Gender Gender (Male v Female) 0.04[-0.004, 0.09] 0.02[-0.02, 0.05] 0.005[-0.03, 0.04] -0.000[-0.03, 0.03] -0.04[-0.07, -0.01] Education Education (Years) -0.004[-0.02, 0.008] -0.008[-0.02, 0.008] 0.003[-0.01, 0.02] -0.001[-0.01, 0.008] -0.007[-0.02, 0.005] Continent Continent (North America v Australia) 0.03[-0.06, 0.12] -0.03[-0.15, 0.08] -0.06[-0.17, 0.06] -0.05[-0.13, 0.04] 0.06[-0.21, 0.33] Continent (North America v Europe) 0.06[-0.02, 0.14] -0.08[-0.19, 0.03] -0.11[-0.21, -0.006] 0.02[-0.04, 0.08] 0.08[-0.13, 0.28] Country Country (United States v Australia) 0.03[-0.05, 0.12] -0.03[-0.11, 0.06] -0.06[-0.10, -0.03] -0.04[-0.14, 0.06] 0.06[-0.22, 0.34] Country (United States v Germany) 0.09[0.002, 0.18] -0.03[-0.12, 0.07] -0.06[-0.12, -0.003] 0.02[-0.08, 0.12] 0.04[-0.20, 0.28] Country (United States v Sweden) 0.03[-0.06, 0.13] -0.15[-0.28, -0.02] -0.18[-0.27, -0.09] 0.03[-0.07, 0.13] 0.15[-0.16, 0.46] Country (United States v The Netherlands) 0.03[-0.08, 0.14] Personality Scale Scale (NEO-FFI v Eysenck) 0.02[-0.07, 0.12] -0.21[-0.31, -0.11] 0.07[-0.005, 0.15] 0.07[-0.37, 0.51] Scale (NEO-FFI v BFI-S) 0.10[0.01, 0.18] -0.09[-0.17, -0.010] 0.08[0.02, 0.14] -0.14[-0.57, 0.28] Scale (NEO-FFI v DPQ) 0.07[0.01, 0.12] Scale (NEO-FFI v IPIP NEO) 0.08[-0.04, 0.20] -0.13[-0.24, -0.01] 0.06[-0.04, 0.17] 0.04[-0.39, 0.48] Scale (NEO-FFI v MIDI) -0.04[-0.11, 0.03] -0.02[-0.08, 0.04] 0.09[0.04, 0.14] -0.13[-0.55, 0.29] Scale (NEO-FFI v TDA-40) 0.03[-0.05, 0.10] -0.09[-0.15, -0.03] -0.003[-0.05, 0.05] -0.01[-0.43, 0.41] Baseline Age Study Baseline Age -0.001[-0.003, 0.002] 0.002[-0.001, 0.004] 0.002[-0.001, 0.006] -0.000[-0.003, 0.002] 0.001[-0.005, 0.007] Baseline Year Study Baseline Year 0.001[-0.004, 0.006] 0.005[0.001, 0.009] 0.004[-0.003, 0.01] -0.000[-0.005, 0.004] -0.006[-0.01, 0.003] Prediction Interval Prediction Interval -0.003[-0.01, 0.009] -0.007[-0.02, 0.001] -0.008[-0.02, 0.006] 0.001[-0.010, 0.01] 0.007[-0.01, 0.03] To better understand the moderation, we examined fully adjusted simple effects plots for tests of moderators of personality-cognitive ability associations in Figure S7. Although the figure demonstrates the simple effects for all of the Big Five, gender only significantly moderated openness to experience (b = -0.04, 95% CI [-0.07, -0.01]). In addition, the overall association between openness-crystallized ability association was positive for males and females. However, the interaction indicates that females had a significantly lower association than males. Figure 5.1: Figure S7. Prospective sample-specific and overall associations between extraversion (in POMP units, 0-10) and crystallized abilities (in POMP units, 0-10) across genders (male, female). Different colors and line types indicate different samples. Thicker, black lines indicate the average association across samples, while thinner lines indicate sample-specific associations. Finally, we examined the consistency of the prospective associations across samples for both personality-cognitive ability associations and the simple effects across samples for each moderator. Figure S8 presents the forest plots of the fully adjusted sample-specific and meta-analytic estimates of Big Five personality characteristic-crystallized ability associations across samples. These associations were very consistent for openness, with all samples except for ROS demonstrating a positive association between openness and crystallized abilities. Other estimates were less consistent, with three samples (HRS, MAP, and ROS) showing a positive association between conscientiousness and crystallized abilities, one sample (SATSA) showing a negative association, and two samples (HILDA, GSOEP) showing a null association. Figure 5.2: Figure S8. Forest plot of fully adjusted prospective associations between Big Five personality characteristics and crystallized abilities across samples for using one-stage pooled integrative data analysis via effects coded contrasts. Overall point estimates (squares) represent the grand-mean estimates of the association across samples, while sample point estimates represent regression terms or linear combinations of regression terms. Error bars capture the 95% CI around the point estimate. Arrows indicate the confidence band was truncated to better visualize the estimates. (Although gender did not moderate the association between extraversion and crystallized abilities in Method 3, for consistency with other methods, we include interpretation here.) Next, we examined the consistency of moderator associations across samples. Figure S7 displays the overall fully adjusted predicted crystallized abilities levels at different levels of extraversion across samples for those males and females for comparison to other methods. As is clear in the Figure, the overall trend suggests a null association for women and slight negative association for men, such that men who were higher in extraversion tended to score slightly worse on crystallized domain tasks. HRS (b = 0.04, 95% CI [-0.07, -0.02]) showed a negative association between extraversion and crystallized abilities for women, HILDA (b = 0.05, 95% CI [0.02, 0.08]) and GSOEP (b = 0.10, 95% CI [0.03, 0.17]) showed positive associations, and all other samples showed null associations. For men, HRS (b = -0.05, 95% CI [-0.08, -0.02]) and SATSA (b = -0.17, 95% CI [-0.30, -0.03]) demonstrated a negative association, only GSOEP demonstrated a positive association (b = 0.08, 95% CI [0.01, 0.14]), and all other samples demonstrated a null effect. Among sample-level moderators, 15 of the 62 (24.19%) tested sample-level moderators were significant (fully adjusted). The most notable of these were country-level differences in the association between Conscientiousness and crystallized / knowledge domain cognitive ability and differences in the associations between Neuroticism and Conscientiousness’s associations with cognitive ability across different personality scales. Specifically, although there was a positive association between Conscientiousness and crystallized / knowledge domain cognitive ability in the United States (b = 0.06, 95% CI [0.04, 0.09]), that association was null (Germany, b = 0.001, 95% CI [-0.055, 0.057]; Australia, b = 0.003, 95% CI [-0.023, 0.030]) or negative (Sweden, b = -0.12, 95% CI [-0.20, -0.03]). Similarly, the association for Conscientiousness was positive when using the NEO-FFI (b = 0.09, 95% CI [0.03, 0.14]) and MIDI (b = 0.07, 95% CI [0.04, 0.09, negative when using the measures in SATSA and OCTO-TWIN (b = -0.12, 95% CI [-0.20, -0.03]). and null when using IPIP NEO (b = -0.04, 95% CI [-0.14, 0.06]), BFI-S (b = 0.001, 95% CI [-0.06, 0.06]), and TDA-40 (b = 0.003, 95% CI [-0.023, 0.029]). For Neuroticism, the association was negative for the NEO-FFI (b = -0.11, 95% CI [-0.15, -0.07]), MIDI (b = -0.02, 95% CI [-0.04, -0.00]), DPQ (b = -0.04, 95% CI [-0.08, -0.01]), and TDA-40 (b = -0.12, 95% CI [-0.14, -0.09]), and null for the IPIP NEO (b = -0.05, 95% CI [-0.14, 0.05]), BFI-S (b = -0.04, 95% CI [-0.08, 0.01]), and the measure used in SATSA and OCTO-TWIN (b = -0.04, 95% CI [-0.11, 0.02]). Simple effects plots for all sample-level moderators can be found in the online materials and web app. rm(list = ls()[grepl(&quot;ipd3&quot;, ls())]) "],["method-3-one-stage-individual-participant-analyses-reported-together.html", "Chapter 6 Method 3: One-Stage Individual Participant Analyses Reported Together 6.1 Analytic Plan 6.2 Step 1: Combine Data 6.3 Step 2: Run Models for Each Study 6.4 Sample Results Section", " Chapter 6 Method 3: One-Stage Individual Participant Analyses Reported Together 6.1 Analytic Plan In the present study, we estimate associations between the Big Five personality traits and crystallized cognitive abilities using a series of separate regression models for each sample (also known as a coordinated data analysis when multiple analysts are used). The procedure is as follows: Models were run separately for each sample, personality characteristic, outcome, covariate, and moderator combination. To do so, we wrote a series of functions in the R programming language (see online materials) to (1) set up and run the model and extract model coefficients, (2) extract simple-effects predictions for moderator models (i.e. predicted values across levels of the moderator values), and (3) extract effect size metrics for the later meta-analysis. The basic form of the model is as follows: \\(Y_{ij}=b_0+b_1\\ast predictor_{ij}+\\epsilon_{ij}\\) \\(\\epsilon_{ij}\\sim\\mathcal{N}(0, \\sigma^2)\\), where \\(b_1\\) represents the effect of personality predicting the outcome separately in each sample. The modeling function used the base R lm() function to run the models and the tidy() function from the broom package to extract model coefficients and confidence intervals (CI). Inferences will be made based on the 95% confidence intervals. Effect sizes and their standard errors were extracted from the model summary(). Simple-effects predictions were calculated by providing the full range of personality levels (0-10) and average levels of the covariates from the data used to estimate the model as the \"newdata\" argument in the base R predict() function. 6.2 Step 1: Combine Data We again need to combine data. However, rather than combining data across studies, for the two-stage approach, we’ll be combining data within studies in order to run separate analyses for each before combining via meta-analytic tools. loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) load(path) get(ls()[grepl(type, ls())]) } ipd4_reg_data &lt;- tibble( study = studies[!studies %in% c(&quot;CNLSY&quot;, &quot;SLS&quot;)] , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID))) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% mutate(age = ifelse(is.na(age), p_year - yearBrth, age)) ipd4_reg_data ## # A tibble: 119,597 × 13 ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 3.83 1990 10004 crystallized 2.17 2000 17 0 4 1918 72 ## 2 BASE E 3.83 1990 10010 crystallized 3.08 1995 11 0 2 1911 79 ## 3 BASE E 2.5 1990 10033 crystallized 0.909 1997 8 1 5 1910 80 ## 4 BASE E 3 1990 10034 crystallized 6.54 1995 10 0 5 1914 76 ## 5 BASE E 2.5 1990 10111 crystallized 6.54 1995 13 1 4 1901 89 ## 6 BASE E 3.17 1990 10115 crystallized 10 1995 11 0 2 1918 72 ## 7 BASE E 3 1990 10116 crystallized 3.85 1995 10 0 4 1917 73 ## 8 BASE E 3 1990 10145 crystallized 6.36 1997 10 1 5 1897 93 ## 9 BASE E 3.33 1990 10175 crystallized 2.31 1995 8 1 3 1911 79 ## 10 BASE E 3.33 1990 10188 crystallized 5.77 2004 10 1 2 1903 87 ## # ℹ 119,587 more rows 6.2.1 Harmonize Data ipd4_reg_data &lt;- ipd4_reg_data %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, o_value, SRhealth), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate(gender = factor(gender, levels = c(0,1), labels = c(&quot;Male&quot;, &quot;Female&quot;)), education = education - 12, age = age - mean(age, na.rm = T)) ipd4_reg_data ## # A tibble: 119,597 × 13 ## # Groups: study, Trait, Outcome [40] ## study Trait p_value p_year SID Outcome o_value o_year education gender SRhealth yearBrth age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 BASE E 7 1990 10004 crystallized 2.17 2000 5 Male 7.5 1918 -6.23 ## 2 BASE E 7 1990 10010 crystallized 3.08 1995 -1 Male 2.5 1911 0.766 ## 3 BASE E 3 1990 10033 crystallized 0.909 1997 -4 Female 10 1910 1.77 ## 4 BASE E 4.5 1990 10034 crystallized 6.54 1995 -2 Male 10 1914 -2.23 ## 5 BASE E 3 1990 10111 crystallized 6.54 1995 1 Female 7.5 1901 10.8 ## 6 BASE E 5 1990 10115 crystallized 10 1995 -1 Male 2.5 1918 -6.23 ## 7 BASE E 4.5 1990 10116 crystallized 3.85 1995 -2 Male 7.5 1917 -5.23 ## 8 BASE E 4.5 1990 10145 crystallized 6.36 1997 -2 Female 10 1897 14.8 ## 9 BASE E 5.5 1990 10175 crystallized 2.31 1995 -4 Female 5 1911 0.766 ## 10 BASE E 5.5 1990 10188 crystallized 5.77 2004 -2 Female 2.5 1903 8.77 ## # ℹ 119,587 more rows 6.2.2 Save Data Files save_fun &lt;- function(d, trait, outcome, study){ save(d, file = sprintf(&quot;%s/data/two_stage/%s_%s_%s.RData&quot;, local_path, trait, outcome, study)) } ipd4_reg_data %&gt;% group_by(study, Trait, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, Trait, Outcome, study), save_fun)) ## # A tibble: 40 × 4 ## study Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 BASE E crystallized &lt;NULL&gt; ## 2 BASE N crystallized &lt;NULL&gt; ## 3 BASE O crystallized &lt;NULL&gt; ## 4 EAS A crystallized &lt;NULL&gt; ## 5 EAS C crystallized &lt;NULL&gt; ## 6 EAS E crystallized &lt;NULL&gt; ## 7 EAS N crystallized &lt;NULL&gt; ## 8 EAS O crystallized &lt;NULL&gt; ## 9 GSOEP A crystallized &lt;NULL&gt; ## 10 GSOEP C crystallized &lt;NULL&gt; ## # ℹ 30 more rows 6.3 Step 2: Run Models for Each Study 6.3.1 Functions 6.3.1.1 Model Function ipd4_study_mod_fun &lt;- function(trait, outcome, type, mod, study, cov){ ## load the data load(sprintf(&quot;%s/data/two_stage/%s_%s_%s.RData&quot;, local_path, trait, outcome, study)) ## compiled Bayesian model to speed up processing and avoid crashing if(type == &quot;Bayesian&quot;) load(sprintf(&quot;%s/results/4_ca_reptog/bayes_sample_mod.RData&quot;, local_path)) ## model formula if (cov == &quot;all&quot;) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if (!cov %in% c(&quot;all&quot;, &quot;none&quot;)) cv &lt;- cov rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;none&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;){rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;))} rhs &lt;- paste(rhs, collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## run the models &amp; save m &lt;- if(type == &quot;Frequentist&quot;){do.call(&quot;lm&quot;, list(formula = f, data = quote(d)))} else {update(m, formula = f, newdata = d, warmup = 1000, iter = 2000)} save(m, file = sprintf(&quot;%s/results/4_ca_reptog/%s/models/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) save(fx, file = sprintf(&quot;%s/results/4_ca_reptog/%s/summary/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) ## calculate simple effects if(mod != &quot;none&quot;){ pred.rx &lt;- ipd4_study_simpeff_fun(m, mod, type) save(pred.rx, file = sprintf(&quot;%s/results/4_ca_reptog/%s/predicted/%s_%s_%s_%s_%s.RData&quot; , local_path, type, outcome, trait, mod, cov, study)) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;es&quot;, &quot;rhs&quot;)) gc() } 6.3.1.2 Study-Specific Simple Effects Function ipd4_study_simpeff_fun &lt;- function(m, moder, type){ d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(unique(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;, &quot;baseAge&quot;, &quot;baseYear&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;predInt&quot;, &quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { unique(fct_lev[,moder][[1]]) } mod_frame &lt;- crossing( p_value = seq(0,10,.5) , modvalue = md_levs ) %&gt;% setNames(c(&quot;p_value&quot;, moder)) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.factor) %&gt;% summarize_all(~levels(.)[1])) } } pred.fx &lt;- if(type == &quot;Bayesian&quot;){ bind_cols( mod_frame, fitted(m, newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), pred = Estimate, lower = Q2.5, upper = Q97.5) } else { bind_cols( mod_frame, predict(m, newdata = mod_frame, interval = &quot;confidence&quot;) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$model)), pred = fit, lower = lwr, upper = upr) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 6.3.2 Run Models load(sprintf(&quot;%s/data/two_stage/N_crystallized_HILDA.RData&quot;, local_path)) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = F)) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- bf(o_value ~ p_value + age + gender + education) m &lt;- brm(formula = f , data = d , prior = Prior , iter = Iter , warmup = Warmup) ## ## SAMPLING FOR MODEL &#39;anon_model&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 3.8e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: WARNING: There aren&#39;t enough warmup iterations to fit the ## Chain 1: three stages of adaptation as currently configured. ## Chain 1: Reducing each adaptation stage to 15%/75%/10% of ## Chain 1: the given number of warmup iterations: ## Chain 1: init_buffer = 3 ## Chain 1: adapt_window = 16 ## Chain 1: term_buffer = 2 ## Chain 1: ## Chain 1: Iteration: 1 / 30 [ 3%] (Warmup) ## Chain 1: Iteration: 3 / 30 [ 10%] (Warmup) ## Chain 1: Iteration: 6 / 30 [ 20%] (Warmup) ## Chain 1: Iteration: 9 / 30 [ 30%] (Warmup) ## Chain 1: Iteration: 12 / 30 [ 40%] (Warmup) ## Chain 1: Iteration: 15 / 30 [ 50%] (Warmup) ## Chain 1: Iteration: 18 / 30 [ 60%] (Warmup) ## Chain 1: Iteration: 21 / 30 [ 70%] (Warmup) ## Chain 1: Iteration: 22 / 30 [ 73%] (Sampling) ## Chain 1: Iteration: 24 / 30 [ 80%] (Sampling) ## Chain 1: Iteration: 27 / 30 [ 90%] (Sampling) ## Chain 1: Iteration: 30 / 30 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.002 seconds (Warm-up) ## Chain 1: 0 seconds (Sampling) ## Chain 1: 0.002 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;anon_model&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 4e-06 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: WARNING: There aren&#39;t enough warmup iterations to fit the ## Chain 2: three stages of adaptation as currently configured. ## Chain 2: Reducing each adaptation stage to 15%/75%/10% of ## Chain 2: the given number of warmup iterations: ## Chain 2: init_buffer = 3 ## Chain 2: adapt_window = 16 ## Chain 2: term_buffer = 2 ## Chain 2: ## Chain 2: Iteration: 1 / 30 [ 3%] (Warmup) ## Chain 2: Iteration: 3 / 30 [ 10%] (Warmup) ## Chain 2: Iteration: 6 / 30 [ 20%] (Warmup) ## Chain 2: Iteration: 9 / 30 [ 30%] (Warmup) ## Chain 2: Iteration: 12 / 30 [ 40%] (Warmup) ## Chain 2: Iteration: 15 / 30 [ 50%] (Warmup) ## Chain 2: Iteration: 18 / 30 [ 60%] (Warmup) ## Chain 2: Iteration: 21 / 30 [ 70%] (Warmup) ## Chain 2: Iteration: 22 / 30 [ 73%] (Sampling) ## Chain 2: Iteration: 24 / 30 [ 80%] (Sampling) ## Chain 2: Iteration: 27 / 30 [ 90%] (Sampling) ## Chain 2: Iteration: 30 / 30 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.004 seconds (Warm-up) ## Chain 2: 0 seconds (Sampling) ## Chain 2: 0.004 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;anon_model&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 3e-06 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: WARNING: There aren&#39;t enough warmup iterations to fit the ## Chain 3: three stages of adaptation as currently configured. ## Chain 3: Reducing each adaptation stage to 15%/75%/10% of ## Chain 3: the given number of warmup iterations: ## Chain 3: init_buffer = 3 ## Chain 3: adapt_window = 16 ## Chain 3: term_buffer = 2 ## Chain 3: ## Chain 3: Iteration: 1 / 30 [ 3%] (Warmup) ## Chain 3: Iteration: 3 / 30 [ 10%] (Warmup) ## Chain 3: Iteration: 6 / 30 [ 20%] (Warmup) ## Chain 3: Iteration: 9 / 30 [ 30%] (Warmup) ## Chain 3: Iteration: 12 / 30 [ 40%] (Warmup) ## Chain 3: Iteration: 15 / 30 [ 50%] (Warmup) ## Chain 3: Iteration: 18 / 30 [ 60%] (Warmup) ## Chain 3: Iteration: 21 / 30 [ 70%] (Warmup) ## Chain 3: Iteration: 22 / 30 [ 73%] (Sampling) ## Chain 3: Iteration: 24 / 30 [ 80%] (Sampling) ## Chain 3: Iteration: 27 / 30 [ 90%] (Sampling) ## Chain 3: Iteration: 30 / 30 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.003 seconds (Warm-up) ## Chain 3: 0 seconds (Sampling) ## Chain 3: 0.003 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL &#39;anon_model&#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 3e-06 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: WARNING: There aren&#39;t enough warmup iterations to fit the ## Chain 4: three stages of adaptation as currently configured. ## Chain 4: Reducing each adaptation stage to 15%/75%/10% of ## Chain 4: the given number of warmup iterations: ## Chain 4: init_buffer = 3 ## Chain 4: adapt_window = 16 ## Chain 4: term_buffer = 2 ## Chain 4: ## Chain 4: Iteration: 1 / 30 [ 3%] (Warmup) ## Chain 4: Iteration: 3 / 30 [ 10%] (Warmup) ## Chain 4: Iteration: 6 / 30 [ 20%] (Warmup) ## Chain 4: Iteration: 9 / 30 [ 30%] (Warmup) ## Chain 4: Iteration: 12 / 30 [ 40%] (Warmup) ## Chain 4: Iteration: 15 / 30 [ 50%] (Warmup) ## Chain 4: Iteration: 18 / 30 [ 60%] (Warmup) ## Chain 4: Iteration: 21 / 30 [ 70%] (Warmup) ## Chain 4: Iteration: 22 / 30 [ 73%] (Sampling) ## Chain 4: Iteration: 24 / 30 [ 80%] (Sampling) ## Chain 4: Iteration: 27 / 30 [ 90%] (Sampling) ## Chain 4: Iteration: 30 / 30 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 0.002 seconds (Warm-up) ## Chain 4: 0 seconds (Sampling) ## Chain 4: 0.002 seconds (Total) ## Chain 4: save(m, file = sprintf(&quot;%s/results/4_ca_reptog/bayes_sample_mod.RData&quot;, local_path)) rm(list = c(&quot;d&quot;, &quot;Prior&quot;, &quot;Iter&quot;, &quot;Warmup&quot;, &quot;treedepth&quot;, &quot;f&quot;, &quot;m&quot;)) # done &lt;- tibble(file = list.files(sprintf(&quot;%s/results/4_ca_reptog/Bayesian/studyModels&quot;, local_path))) %&gt;% # separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;) %&gt;% # mutate(study = str_remove_all(study, &quot;.RData&quot;), # done = &quot;done&quot;) plan(multisession(workers = 12L)) nested_ipd_reg &lt;- tibble(files = list.files(sprintf(&quot;%s/data/two_stage&quot;, local_path))) %&gt;% separate(files, c(&quot;Trait&quot;, &quot;Outcome&quot;, &quot;study&quot;), sep = &quot;_&quot;) %&gt;% filter(!is.na(study)) %&gt;% mutate(study = str_remove(study, &quot;.RData&quot;)) %&gt;% left_join( crossing( study = studies , Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) , Covariate = c(&quot;none&quot;, &quot;all&quot;) ) %&gt;% full_join( crossing( study = studies , Trait = traits$short_name , Outcome = outcomes$short_name , type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , Moderator = &quot;none&quot; , Covariate = c(&quot;none&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;all&quot;) ) ) ) %&gt;% filter(!is.na(Covariate)) %&gt;% # full_join(done) %&gt;% filter(is.na(done)) %&gt;% # filter(type != &quot;Frequentist&quot;) %&gt;% filter(Trait == &quot;N&quot;) %&gt;% mutate(run = # pmap(list(Trait, Outcome, type, Moderator, study, Covariate) future_pmap(list(Trait, Outcome, type, Moderator, study, Covariate) , ipd4_study_mod_fun , .progress = T , .options = furrr_options( globals = c(&quot;ipd4_study_simpeff_fun&quot; , &quot;read_path&quot; , &quot;local_path&quot; , &quot;local_path&quot; , &quot;codebook&quot; , &quot;covars&quot; , &quot;moders&quot; , &quot;outcomes&quot; , &quot;studies&quot; , &quot;stdyModers&quot; , &quot;traits&quot; , &quot;data_path&quot;) , packages = c(&quot;lme4&quot; , &quot;broom&quot; , &quot;psych&quot; , &quot;knitr&quot; , &quot;broom.mixed&quot; , &quot;brms&quot; #, &quot;tidybayes&quot; #, &quot;bootpredictlme4&quot; , &quot;rstan&quot; , &quot;estimatr&quot; #, &quot;merTools&quot; , &quot;plyr&quot; , &quot;tidyverse&quot;)) )) closeAllConnections() 6.3.3 Compile Results loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/4_ca_reptog/%s/%s/%s&quot;, local_path, type, folder, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } n_fun &lt;- function(fileName, type){ m &lt;- loadRData(fileName, type, &quot;^m&quot;, &quot;models&quot;) d &lt;- if(type == &quot;Bayesian&quot;) m$data else m$model n &lt;- nrow(d) return(n) } ## load in effect size data ## first get file names nested_ipd4_ca &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/4_ca_reptog/%s/summary&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!is.na(study)) %&gt;% ## read in the files mutate(study = str_remove(study, &quot;.RData&quot;), fx = map2(file, type, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;)), n = map2_dbl(file, type, n_fun)) %&gt;% select(-file) %&gt;% unnest(fx) This results in a nested data frame, with columns: studyEff = standardized study-specific effects from stage 1 regressions nested_ipd4_ca ## # A tibble: 4,120 × 11 ## type Outcome Trait Moderator Covariate study term estimate conf.low conf.high n ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Frequentist crystallized A age all EAS (Intercept) 5.67 4.99 6.35 788 ## 2 Frequentist crystallized A age all EAS p_value 0.0812 -0.0121 0.174 788 ## 3 Frequentist crystallized A age all EAS age 0.0136 -0.110 0.138 788 ## 4 Frequentist crystallized A age all EAS genderFemale -0.445 -0.774 -0.116 788 ## 5 Frequentist crystallized A age all EAS education 0.233 0.185 0.281 788 ## 6 Frequentist crystallized A age all EAS p_value:age -0.0103 -0.0276 0.00702 788 ## 7 Frequentist crystallized A age all GSOEP (Intercept) 8.08 7.67 8.48 647 ## 8 Frequentist crystallized A age all GSOEP p_value 0.0196 -0.0343 0.0736 647 ## 9 Frequentist crystallized A age all GSOEP age 0.00909 -0.0209 0.0391 647 ## 10 Frequentist crystallized A age all GSOEP genderFemale 0.0439 -0.140 0.227 647 ## # ℹ 4,110 more rows 6.3.3.0.1 Tables 6.3.3.0.1.1 Study-Specific We’ll make a table of the results, separately for each moderator. To do this efficiently, we’ll make a function that creates those tables across all combinations. Before calling that function, we’ll do some reformatting and reshaping to get the data ready. ipd4_res_tab &lt;- nested_ipd4_ca %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% # significance marker mutate_at(vars(estimate:conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;,.))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;)), study = factor(study, c(studies_long, &quot;Meta-Analytic&quot;)), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name)) %&gt;% select(type:Covariate, term, study, est) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) %&gt;% select(type:study, E, A, C, N, O) %&gt;% arrange(type, Outcome, Moderator, Covariate, study) ipd4_res_tab ## # A tibble: 242 × 11 ## type Outcome Moderator Covariate term study E A C N O ## &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Bayesian Crystallized Ability age all p_value:age BASE 0.002&lt;br&gt;[-0.03, 0.04] &lt;NA&gt; &lt;NA&gt; 0.01… -0.0… ## 2 Bayesian Crystallized Ability age all p_value:age EAS -0.005&lt;br&gt;[-0.02, 0.01] -0.01… &lt;str… &lt;str… -0.0… ## 3 Bayesian Crystallized Ability age all p_value:age GSOEP -0.000&lt;br&gt;[-0.004, 0.003] -0.00… 0.00… 0.00… -0.0… ## 4 Bayesian Crystallized Ability age all p_value:age HILDA 0.001&lt;br&gt;[-0.000, 0.003] 0.000… &lt;str… &lt;str… &lt;str… ## 5 Bayesian Crystallized Ability age all p_value:age HRS -0.002&lt;br&gt;[-0.005, 0.001] -0.00… &lt;str… 0.00… &lt;str… ## 6 Bayesian Crystallized Ability age all p_value:age LASA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; -0.0… &lt;NA&gt; ## 7 Bayesian Crystallized Ability age all p_value:age MAP -0.002&lt;br&gt;[-0.009, 0.005] &lt;NA&gt; 0.00… -0.0… &lt;NA&gt; ## 8 Bayesian Crystallized Ability age all p_value:age MARS &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; -0.0… &lt;NA&gt; ## 9 Bayesian Crystallized Ability age all p_value:age OCTO-Twin -0.01&lt;br&gt;[-0.06, 0.03] &lt;NA&gt; &lt;NA&gt; 0.03… &lt;NA&gt; ## 10 Bayesian Crystallized Ability age all p_value:age ROS 0.004&lt;br&gt;[-0.006, 0.01] &lt;stro… 0.00… &lt;str… &lt;str… ## # ℹ 232 more rows ipd4_std_table_fun &lt;- function(d, type, moder, cov){ cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) if(!grepl(&quot;djust&quot;, cv)) cv &lt;- paste(cv, &quot;Adjusted&quot;) md &lt;- mapvalues(moder, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) rs &lt;- d %&gt;% group_by(Outcome) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- rep(1,6); names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$short_name, &quot;&lt;/strong&gt;&quot;)) cap &lt;- if(moder == &quot;none&quot;) { sprintf(&quot;&lt;strong&gt;Table X.&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Method 4 Coordinated Analyses Reported Together: Sample Estimates of %s Personality-Cognitive Domain Relationships&lt;/em&gt;&quot;, cv) } else { sprintf(&quot;&lt;strong&gt;Table X.&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Method 4 Coordinated Analyses Reported Together: Sample %s Moderation of %s Personality-Cognitive Domain Relationships&lt;/em&gt;&quot;, md, cv) } tab &lt;- d %&gt;% select(-Outcome) %&gt;% kable(., &quot;html&quot; , escape = F , booktabs = T , col.names = c(&quot;Study&quot;, rep(&quot;b [CI]&quot;, 5)) , align = c(&quot;r&quot;, rep(&quot;c&quot;, 5)) , caption = cap) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Outcome[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/4_ca_reptog/%s/tables/study specific/%s_%s.html&quot;, local_path, type, moder, cov)) return(tab) } ipd4_std_tab &lt;- ipd4_res_tab %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% select(-term) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator, Covariate), ipd4_std_table_fun)) 6.3.3.0.1.2 Meta-Analytic Results are not meta-analyzed, so there are no meta-analytic results. 6.3.3.0.1.3 All Model Terms ipd4_mod_tab &lt;- nested_ipd4_ca %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, moders$short_name, moders$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_replace_all(term, &quot;metamod&quot;, paste0(&quot;p_value:&quot;, Moderator))) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig, -n) %&gt;% arrange(type, Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd4_mod_tab_fun &lt;- function(d, type, out, moder, cov){ md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) cs &lt;- rep(1,6) names(cs) &lt;- c(&quot; &quot;, traits$long_name) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) cln &lt;- c(&quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) # caption cap &lt;- if(md == &quot;none&quot;) &quot;4 Coordinated Analyses Reported Together: All Model Estimates of Fixed Effect Personality-Crystallized Domain Associations&quot; else sprintf(&quot;4 Coordinated Analyses Reported Together: All Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, md) d &lt;- d %&gt;% arrange(study, term) rs &lt;- d %&gt;% group_by(study) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # kable the table tab &lt;- d %&gt;% select(-study) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) for(i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$study[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/4_ca_reptog/%s/tables/all terms/%s-%s-%s.html&quot; , local_path, type, o, md, cv)) return(tab) # return the html table } ipd4_mod_tab2 &lt;- ipd4_res_tab %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Outcome, Moderator, Covariate), ipd4_mod_tab_fun)) 6.3.4 Figures 6.3.4.1 Overall Forest Results are not meta-analyzes, so there is no overall estimate. 6.3.4.2 Study-Specific Forest ipd4_rx_plot_fun &lt;- function(df, outcome, mod, type, cov, trait){ print(paste(outcome, mod)) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- round(c(0-d-(d/5), 0, 0+d+(d/5)),2) lab &lt;- str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){trt} else {sprintf(&quot;%s x %s&quot;, trt, m)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} df &lt;- df %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) %&gt;% full_join(tibble(study = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) stds &lt;- df$study[df$study != &quot; &quot;] df &lt;- df %&gt;% mutate(study = factor(study, rev(c(&quot; &quot;, stds))) # , conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low) # , conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot; , ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;neither&quot;)) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) # , study = factor(study, levels = str_remove_all(c(&quot;Overall&quot;, studies_long), &quot;-&quot;), labels = c(&quot;Overall&quot;, studies_long)) # Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), , type = &quot;random&quot;) p1 &lt;- df %&gt;% ggplot(aes(x = study, y = estimate)) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high) , position = &quot;dodge&quot; , width = .2) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(lb == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + # geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + annotate(&quot;rect&quot;, xmin = length(stds) + .5, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = &quot; &quot; ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1)) d2 &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high) , ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^0.&quot;, &quot;.&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^-0.&quot;, &quot;-.&quot;)) %&gt;% mutate(est = ifelse(study != &quot; &quot;, sprintf(&quot;%s [%s, %s] &quot;, estimate, conf.low, conf.high), &quot;&quot;) , n = as.character(n) ) %&gt;% select(study, n, est) %&gt;% pivot_longer(cols = c(n, est), names_to = &quot;est&quot;, values_to = &quot;value&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = study, y = est)) + geom_text(aes(label = value), hjust = .5, size = 3.5) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(stds) + .75, y = &quot;est&quot;, hjust = .5, vjust = 0) + annotate(&quot;text&quot;, label = &quot;N&quot;, x = length(stds) + .75, y = &quot;n&quot;, hjust = .5, vjust = 0) + # geom_vline(aes(xintercept = .5)) + geom_vline(aes(xintercept = length(stds) + .5)) + coord_flip() + theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;, hjust = 0) , axis.text = element_blank() , axis.ticks = element_blank() , axis.title = element_blank() , axis.line.y = element_blank()) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) p3 &lt;- cowplot::plot_grid(p1, p2 , rel_widths = c(.4, .6) , align = &quot;h&quot; ) # p &lt;- cowplot::plot_grid(ttl, subttl, p3, rel_heights = c(.05, .05, .9), nrow = 3) p &lt;- cowplot::plot_grid(ttl, p3, rel_heights = c(.05, .95), nrow = 2) gc() save(p , file = sprintf(&quot;%s/results/4_ca_reptog/%s/figures/study specific forest/rdata/%s_%s_%s_%s.RData&quot;, local_path, type, outcome, trait, mod, cov)) return(p) } ## fixed effects nested_ipd4_reg_fp &lt;- nested_ipd4_ca %&gt;% filter(Moderator %in% moders$short_name) %&gt;% ## filter key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;) , study = mapvalues(study, studies_long, studies_sp, warn_missing = F)) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, type, Covariate, Trait) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, type, Covariate, Trait), ipd4_rx_plot_fun)) ipd4_rx_plot_comb_fun &lt;- function(outcome, cov, mod, type, d){ o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) titl &lt;- paste0(o, &quot;,&quot;) titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(titl, cv, &quot;Adjusted&quot;, collapse = &quot;, &quot;) else paste(titl, cv, collapse = &quot;, &quot;) p1 &lt;- plot_grid( d$p[[1]] , d$p[[2]] , d$p[[3]] , d$p[[4]] , d$p[[5]] , nrow = 3 , ncol = 2 , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) my_theme &lt;- function(...) { theme_classic() + theme(plot.subtitle = element_text(hjust = 0)) } subtitle_theme &lt;- calc_element(&quot;subplot.title&quot;, my_theme()) subttl &lt;- ggdraw() + draw_label( &quot;Method 4: Coordinated Analyses Reported Together&quot;, fontfamily = subtitle_theme$family, fontface = subtitle_theme$face, size = subtitle_theme$size ) p &lt;- cowplot::plot_grid(ttl, subttl, p1, rel_heights = c(.03, .03, .94), nrow = 3) ggsave(p , file = sprintf(&quot;%s/results/4_ca_reptog/%s/figures/study specific forest/%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) ggsave(p , file = sprintf(&quot;%s/results/4_ca_reptog/%s/figures/study specific forest/%s_%s_%s.pdf&quot;, local_path, type, outcome, mod, cov) , width = 10, height = 10) return(T) } nested_ipd4_reg_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(Trait) %&gt;% select(-data) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(Outcome, Covariate, Moderator, type, data), ipd4_rx_plot_comb_fun)) ipd4_rx_plot_fun &lt;- function(df, outcome, mod, type, cov){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) lim &lt;- if(mod == &quot;none&quot;){c(-.25, .25)} else{c(0-d-(d/2.5), 0+d+(d/2.5))} brk &lt;- if(mod == &quot;none&quot;){seq(-.2,.2,.2)} else{round(c(0-d-(d/5), 0, 0+d+(d/5)),2)} lab &lt;- if(mod == &quot;none&quot;){c(&quot;-.2&quot;, &quot;0&quot;, &quot;.2&quot;)} else{str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;)} shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s,&quot;, o, m)} titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(titl, cv, &quot;Adjusted&quot;, collapse = &quot; &quot;) else paste(titl, cv, collapse = &quot; &quot;) leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- df %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high), study = factor(study, levels = c(&quot;Overall&quot;, studies_long)), Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), type = ifelse(study == &quot;Overall&quot;, &quot;fixed&quot;, &quot;random&quot;)) %&gt;% ggplot(aes(x = study, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(2.5, 1.5)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;blue&quot;, &quot;black&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = type, size = type, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL , y = &quot;Estimate (POMP)&quot; , title = titl , subtitle = &quot;Method 2B: Pooled Regression Using Random Effects&quot; ) + facet_wrap(~Trait, scales = &quot;free_y&quot;, nrow = 3) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5), strip.background = element_rect(fill = &quot;black&quot;), strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;), axis.text = element_text(color = &quot;black&quot;)) ht &lt;- length(unique(df$study)) local_path &lt;- length(unique(df$Trait)) ggsave(p, file = sprintf(&quot;%s/results/4_ca_reptog/%s/figures/study specific forest/%s_%s_fixed.png&quot; , local_path, type, mod, cov) , width = local_path*2 , height = ht*.75) rm(p) gc() return(T) } ## fixed effects nested_ipd4_ca %&gt;% mutate(term = ifelse(is.na(term), names, term)) %&gt;% # rename(names = term) ## filter key terms filter(Moderator %in% moders$short_name) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;)) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, type, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(pmap(list(data, Outcome, Moderator, type, Covariate), ipd4_rx_plot_fun)) 6.3.4.3 Overall Simple Effects Plots There are no overall effects when coordinated analyses are reported together without random effects meta-analysis. loadRData &lt;- function(fileName, type, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/4_ca_reptog/%s/%s/%s&quot;, local_path, type, folder, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } ## load in effect size data ## first get file names nested_ipd4_ca &lt;- tibble(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;)) %&gt;% mutate(file = map(type, ~list.files(sprintf(&quot;%s/results/4_ca_reptog/%s/predicted&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!is.na(study)) %&gt;% ## read in the files mutate(study = str_remove(study, &quot;.RData&quot;), pred.rx = map2(file, type, ~loadRData(.x, .y, &quot;pred.rx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) %&gt;% unnest(pred.rx) %&gt;% group_by(type, Trait, Outcome, Moderator, Covariate) %&gt;% nest(pred.rx = study:upper) %&gt;% ungroup() 6.3.4.4 Study-Specific Simple Effects Plots ipd4_std_se_plot_fun &lt;- function(d, outcome, trait, mod, cov, type){ # print(paste(int, mod, cov, random, imp)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} d &lt;- d %&gt;% mutate(study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;)), study = factor(study, levels = stdcolors$studies)) std &lt;- unique(d$study) cols &lt;- (stdcolors %&gt;% filter(studies %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies %in% std))$lt d &lt;- d %&gt;% unclass %&gt;% data.frame d$mod_value &lt;- d[,mod] d &lt;- d %&gt;% select(-all_of(mod)) %&gt;% as_tibble d &lt;- if(class(d$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){ d %&gt;% mutate(mod_fac = factor(mod_value)) } else{ d %&gt;% full_join( d %&gt;% select(study, mod_value) %&gt;% distinct() %&gt;% arrange(study, mod_value) %&gt;% group_by(study) %&gt;% mutate(mod_fac = factor(c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;), levels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% ungroup() ) } ht &lt;- length(unique(d$mod_fac)) p &lt;- d %&gt;% ggplot(aes(x = p_value, y = pred)) + geom_line(aes(color = study , group = interaction(study, mod_fac) , linetype = study) , size = 1) + # geom_ribbon(aes(fill = study # , group = interaction(study, mod_fac) # , ymin = lower # , ymax = upper) # , alpha = .25) + # stat_smooth(aes(weight = n) # , method = &quot;lm&quot; # , formula = y~x # , size = 1.2 # , color = &quot;darkslateblue&quot; # ) + scale_y_continuous(limits = c(0,10) , breaks = c(0,5,10) , labels = c(0,5,10)) + scale_color_manual(values = cols) + scale_linetype_manual(values = lt) + labs(x = &quot;Personality Score (POMP)&quot; , y = &quot;Cognition Score (POMP)&quot; , color = &quot;Study&quot; , fill = &quot;Study&quot; , linetype = &quot;Study&quot; , title = titl , subtitle = &quot;Method 4: Coordinated Analyses Reported Together&quot; ) + facet_wrap(~mod_fac) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, hjust = .5, size = rel(.95)) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/4_ca_reptog/%s/figures/study specific simple effects/%s_%s_%s_%s.png&quot;, local_path, type, outcome, trt, mod, cov), width = 3*ht, height = 5) } nested_ipd4_ca %&gt;% mutate(p = pmap(list(pred.rx, Outcome, Trait, Moderator, Covariate, type), ipd4_std_se_plot_fun)) 6.4 Sample Results Section We examined estimates of overall prospective associations between Big Five personality characteristics and crystallized abilities as well as participant and sample-level moderators of those associations using separate regression models of individual participant data of 11 studies. Fully adjusted Big Five personality trait-crystallized ability associations as well as participant- and sample-level moderators of these associations can be found in the forest plot in Figure S8. Of all estimates, openness was most consistently associated with later crystallized abilities, with positive associations in six of seven studies (all except ROS). Neuroticism (-) was somewhat consistently associated with crystallized abilities, demonstrating a negative association in five of the 11 samples. In contrast, extraversion and conscientiousness were less consistently associated with crystallized abilities with significant effects for at least one study in both directions. For extraversion, only two of nine studies were significant: a positive association in GSOEP and a negative association in HRS. Similarly, while there was a positive association between conscientiousness and crystallized abilities in HRS, MAP, and ROS but a negative association in SATSA. Figure 6.1: Figure S8. Forest plot of fully adjusted prospective associations between Big Five personality characteristics and crystallized abilities across samples for using one-stage pooled integrative data analysis via effects coded contrasts. Overall point estimates (squares) represent the grand-mean estimates of the association across samples, while sample point estimates represent regression terms or linear combinations of regression terms. Error bars capture the 95% CI around the point estimate. Arrows indicate the confidence band was truncated to better visualize the estimates. Next, we examined participant-level moderators of the association between personality traits and crystallized abilities. Moderator associations in each sample can be seen in Table S6. For age, 12 of the 40 tested moderators were significant. Of these, the most consistent were for conscientiousness (3/7) and openness (3/7). However, for each of these, the overall pattern was less clear because moderator associations were in both directions. For example, for openness (see Figure S9), age negatively moderated the association between openness and crystallized abilities in HILDA and HRS such that associations were weaker for younger relative to older participants. In contrast, age positively moderated the association in ROS such that associations were stronger for older relative to younger participants. Table 6.1: Table X.Method 4 Coordinated Analyses Reported Together: Sample Age Moderation of Fully Adjusted Personality-Cognitive Domain Relationships E A C N O Study b [CI] b [CI] b [CI] b [CI] b [CI] Crystallized Ability BASE 0.002[-0.03, 0.04] 0.01[-0.01, 0.03] -0.006[-0.03, 0.02] EAS -0.005[-0.02, 0.01] -0.01[-0.03, 0.007] -0.03[-0.05, -0.009] 0.02[0.006, 0.04] -0.007[-0.03, 0.01] GSOEP -0.000[-0.004, 0.003] -0.002[-0.005, 0.002] 0.004[-0.000, 0.008] 0.001[-0.002, 0.004] -0.001[-0.004, 0.002] HILDA 0.001[0.000, 0.003] 0.000[-0.001, 0.002] 0.003[0.002, 0.005] -0.003[-0.004, -0.001] -0.002[-0.003, -0.000] HRS -0.002[-0.005, 0.001] -0.001[-0.005, 0.002] -0.006[-0.010, -0.003] 0.002[-0.001, 0.004] -0.005[-0.008, -0.002] LASA -0.000[-0.003, 0.002] MAP -0.002[-0.009, 0.005] 0.003[-0.006, 0.01] -0.005[-0.01, 0.002] MARS -0.01[-0.03, 0.009] OCTO-Twin -0.01[-0.06, 0.03] 0.03[-0.01, 0.07] ROS 0.004[-0.006, 0.01] 0.01[0.001, 0.03] 0.002[-0.01, 0.01] -0.01[-0.02, -0.001] 0.02[0.009, 0.04] SATSA -0.007[-0.02, 0.001] -0.005[-0.01, 0.005] 0.002[-0.007, 0.01] 0.009[0.001, 0.02] 0.006[-0.007, 0.02] Figure 6.2: Figure S9. Prospective sample-specific and overall associations between extraversion (in POMP units, 0-10) and crystallized abilities (in POMP units, 0-10) across age (M = 60, +/- 1 SD in each sample). Different colors and line types indicate different samples. For education, 12 of the 40 tested moderators were significant. Of these, the traits where education most consistently moderated the association with crystallized abilities included extraversion (3/9) and agreeableness (3/6). For agreeableness (see Figure S10), all of the moderator associations were in the same direction (-) suggested that more educated people had weaker associations than less educated people in those samples. In contrast, for extraversion, education negatively moderated the association in HILDA and GSOEP (i.e. the association was weaker for more educated people relative to less educated people) but positive for HRS (i.e. the association was less negative for more educated people relative to less educated people). Figure 6.3: Figure S10. Prospective sample-specific and overall associations between extraversion (in POMP units, 0-10) and crystallized abilities (in POMP units, 0-10) across education (M = 12 years, +/- 1 SD in each sample). Different colors and line types indicate different samples. rm(list = ls()[grepl(&quot;ipd4&quot;, ls())]) "],["method-3-one-stage-individual-participant-analyses-reported-together-1.html", "Chapter 7 Method 3: One-Stage Individual Participant Analyses Reported Together 7.1 Comparisons Across the Taxonomy 7.2 Comparisons Across Methods: Bayesian versus Frequentist", " Chapter 7 Method 3: One-Stage Individual Participant Analyses Reported Together 7.1 Comparisons Across the Taxonomy We again need to combine data. However, rather than combining data across studies, for the two-stage approach, we’ll be combining data within studies in order to run separate analyses for each before combining via meta-analytic tools. To do: ADD HETEROGENEITY ESTIMATES AND OTHER META-ANALYTIC TERMS 7.1.1 Tables 7.1.1.1 Meta-Analytic Estimates loadRData &lt;- function(fileName, type, method, obj, dir){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s/%s&quot;, local_path, method, type, dir, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } nested_ipd_fx &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , method = c(&quot;1a_ipd_reg&quot;, &quot;1b_ipd_fixef&quot;, &quot;2a_ipd_dc&quot;, &quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% mutate(dir = ifelse(method == &quot;3_ipd_meta&quot;, &quot;metaSummary&quot;, &quot;summary&quot;) , file = pmap(list(method, type, dir, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/%s&quot;, ..4, ..1, ..2, ..3)))) %&gt;% # filter(type != &quot;Bayesian&quot;) %&gt;% unnest(file) %&gt;% mutate(fx = pmap(list(file, type, method, &quot;fx&quot;, dir), loadRData)) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;) %&gt;% mutate(Covariate = str_remove_all(Covariate, &quot;.RData&quot;)) # loadRData &lt;- function(fileName, obj){ # #loads an RData file, and returns it # path &lt;- sprintf(&quot;%s/%s&quot;, res_path, fileName) # # print(path) # load(url(path)) # get(ls()[grepl(obj, ls())]) # } # library(httr) # repo_req &lt;- GET(&quot;https://api.github.com/repos/emoriebeck/data-synthesis-tutorial/git/trees/main?recursive=1&quot;) # stop_for_status(repo_req) # repo_filelist &lt;- unlist(lapply(content(req)$tree, &quot;[&quot;, &quot;path&quot;), use.names = F) # # list_files_github &lt;- function(method, type, dir){ # grep(sprintf(&quot;results/%s/%s/%s&quot;, method, type, dir), repo_filelist, value = TRUE, fixed = TRUE) # } # # nested_ipd_fx &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) # , method = c(&quot;1a_ipd_reg&quot;, &quot;1b_ipd_fixef&quot;, &quot;2a_ipd_dc&quot;, &quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% # mutate(dir = ifelse(method == &quot;3_ipd_meta&quot;, &quot;metaSummary&quot;, &quot;summary&quot;) # , file = pmap(list(method, type, dir), list_files_github)) %&gt;% # # , file = pmap(list(method, type, dir, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/%s&quot;, ..4, ..1, ..2, ..3)))) %&gt;% # # filter(type != &quot;Bayesian&quot;) %&gt;% # unnest(file) %&gt;% # filter(grepl(&quot;.RData&quot;, file)) %&gt;% # mutate(fx = pmap(list(file, &quot;fx&quot;), loadRData)) # cols_ord &lt;- paste(rep(c(&quot;b&quot;, &quot;CI&quot;), times = 5), rep(c(&quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;), each = 2), sep = &quot;_&quot;) ipd_fx_tab &lt;- nested_ipd_fx %&gt;% unnest(fx) %&gt;% mutate(term = ifelse(method == &quot;3_ipd_meta&quot;, str_replace_all(term, &quot;metamod&quot;, paste0(&quot;p_value:&quot;, Moderator)), term)) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term) &amp; !(grepl(&quot;cor_&quot;, term) | grepl(&quot;sd_&quot;, term)))) %&gt;% # filter(!Moderator %in% unique(stdyModers$short_name)) %&gt;% # filter(!Moderator %in% c(&quot;scale&quot;, &quot;continent&quot;, &quot;country&quot;)) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), mod_type = ifelse(Moderator %in% moders$short_name, &quot;Person-Level&quot;, &quot;Study-Level&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = mapvalues(term, c(&quot;scaleBFIMS&quot;, &quot;scaleIPIPNEO&quot;, &quot;scaleTDAM40&quot;, &quot;countryTheNetherlands&quot;, &quot;gender&quot;) , c(&quot;scaleBFI-S&quot;, &quot;scaleIPIP NEO&quot;, &quot;scaleTDA-40&quot;, &quot;countryThe Netherlands&quot;, &quot;genderFemale&quot;)), term = str_replace(term, &quot;metamod&quot;, Moderator), term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name) , c(moders$long_name, stdyModers$long_name))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high) , est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate_at(vars(estimate, CI), ~ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, .), .)) %&gt;% select(type, method, Outcome, Trait, Moderator, mod_type, Covariate, term, est) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = est) %&gt;% select(type:term, E, A, C, N, O) ## table function ipd_fx_tab_fun &lt;- function(d, type, moder_type, cov){ md &lt;- mapvalues(moder_type, c(&quot;Study-Level&quot;, &quot;Person-Level&quot;), c(&quot;study&quot;, &quot;person&quot;) , warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) d &lt;- d %&gt;% arrange(method, Moderator) rs &lt;- d %&gt;% mutate(method = factor(method, mthds$old_name, mthds$long_name)) %&gt;% group_by(method) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) if(all((d %&gt;% group_by(Moderator, method) %&gt;% tally())$n == 1)){ cs &lt;- rep(1,6) cln &lt;- c(&quot; &quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, times = 5)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 5)) d &lt;- d %&gt;% select(-Moderator) } else { cs &lt;- c(2, rep(1,5)) cln &lt;- c(&quot; &quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, times = 5)) al &lt;- c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 5)) } names(cs) &lt;- c(&quot; &quot;, traits$short_name) # caption cap &lt;- if(md == &quot;person&quot;) &quot;Cross-Method Comparison of Overall Effects and Person-Level Moderators of Personality-Crystallized Domain Associations&quot; else &quot;Cross-Method Comparison of Overall Study-Level Moderators of Personality-Crystallized Domain Associations&quot; tab &lt;- d %&gt;% select(-method) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs) %&gt;% collapse_rows(1, valign = &quot;top&quot;, row_group_label_position = &quot;stack&quot;) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$method[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/tables/cross-method/overall/%s_%s_%s.html&quot; , local_path, type, md, cv)) return(tab) } nested_ipd_fx_tab &lt;- ipd_fx_tab %&gt;% filter(Covariate %in% c(&quot;Fully Adjusted&quot;, &quot;Unadjusted&quot;)) %&gt;% group_by(type, mod_type, Outcome, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, mod_type, Covariate), ipd_fx_tab_fun)) # save(nested_ipd_fx_tab, file = sprintf(&quot;%s/manuscript/results/ct_fx_tab.RData&quot;, res_path)) nested_ipd_fx_tab$tab[[6]] Table 7.1: Cross-Method Comparison of Overall Effects and Person-Level Moderators of Personality-Crystallized Domain Associations E A C N O b [CI] b [CI] b [CI] b [CI] b [CI] 1A: Pooled Analysis of Individual Participant Data Personality -0.08[-0.10, -0.07] -0.14[-0.16, -0.12] 0.007[-0.01, 0.02] -0.003[-0.02, 0.01] 0.20[0.19, 0.22] Age 0.000[-0.001, 0.002] -0.001[-0.002, 0.001] -0.002[-0.003, -0.000] 0.002[0.001, 0.003] -0.001[-0.002, 0.000] Gender (Male v Female) 0.07[0.04, 0.11] 0.04[0.008, 0.08] 0.007[-0.03, 0.04] -0.03[-0.05, 0.002] -0.01[-0.05, 0.02] Education (Years) 0.005[0.000, 0.009] -0.004[-0.008, 0.001] -0.007[-0.01, -0.002] -0.002[-0.005, 0.002] 0.002[-0.003, 0.007] 1B: Pooled Analysis of Individual Participant Data with Cluster Corrected Errors Personality -0.08[-0.27, 0.10] -0.14[-0.36, 0.08] 0.007[-0.17, 0.18] -0.003[-0.15, 0.14] 0.20[0.06, 0.34] Age 0.000[-0.004, 0.005] -0.001[-0.005, 0.003] -0.002[-0.006, 0.003] 0.002[0.000, 0.004] -0.001[-0.006, 0.004] Gender (Male v Female) 0.07[0.004, 0.14] 0.04[-0.04, 0.12] 0.007[-0.11, 0.12] -0.03[-0.14, 0.08] -0.01[-0.08, 0.05] Education (Years) 0.005[-0.008, 0.02] -0.004[-0.03, 0.02] -0.007[-0.03, 0.02] -0.002[-0.02, 0.01] 0.002[-0.008, 0.01] 2A: Pooled Analysis of Individual Participant Data using Contrasts Personality 0.05[0.02, 0.08] -0.001[-0.03, 0.03] 0.04[0.02, 0.07] -0.13[-0.15, -0.11] 0.29[0.25, 0.32] Age -0.003[-0.008, 0.003] -0.003[-0.006, 0.001] -0.005[-0.008, -0.001] 0.005[0.001, 0.009] 0.002[-0.003, 0.007] Gender (Male v Female) 0.06[0.003, 0.12] 0.02[-0.04, 0.08] -0.02[-0.08, 0.03] -0.03[-0.08, 0.02] 0.005[-0.07, 0.08] Education (Years) -0.002[-0.01, 0.009] -0.003[-0.02, 0.010] 0.010[-0.001, 0.02] -0.003[-0.01, 0.006] -0.003[-0.02, 0.01] 2B: Pooled Analysis of Individual Participant Data using Random Effects Personality 0.04[0.009, 0.08] 0.005[-0.08, 0.09] 0.05[-0.03, 0.12] -0.12[-0.15, -0.09] 0.27[0.18, 0.36] Age -0.006[-0.01, 0.000] -0.002[-0.006, 0.003] -0.003[-0.008, 0.002] 0.005[-0.04, 0.05] 0.002[-0.10, 0.10] Gender (Male v Female) 0.05[-0.02, 0.12] -0.000[-0.07, 0.07] 0.003[-0.04, 0.05] -0.01[-0.05, 0.02] 0.005[-0.07, 0.08] Education (Years) -0.003[-0.01, 0.005] -0.002[-0.02, 0.01] 0.01[-0.009, 0.03] 0.002[-0.006, 0.010] -0.01[-0.09, 0.06] 3: Separate Analyses Followed by Meta-Analysis Personality 0.04[0.009, 0.08] 0.003[-0.08, 0.09] 0.04[-0.04, 0.12] -0.12[-0.15, -0.09] 0.27[0.18, 0.37] Age -0.000[-0.003, 0.002] -0.001[-0.002, 0.000] -0.002[-0.007, 0.003] 0.001[-0.003, 0.005] 0.001[-0.005, 0.008] Gender (Male v Female) 0.06[0.002, 0.11] 0.03[-0.01, 0.06] -0.008[-0.05, 0.03] -0.006[-0.04, 0.03] -0.03[-0.07, 0.02] Education (Years) -0.003[-0.01, 0.010] -0.006[-0.02, 0.010] 0.004[-0.01, 0.02] -0.002[-0.01, 0.008] -0.005[-0.02, 0.008] ipd_fx_tab_stdm &lt;-ipd_fx_tab %&gt;% filter(type == &quot;Frequentist&quot; &amp; mod_type == &quot;Study-Level&quot; &amp; Covariate %in% &quot;Fully Adjusted&quot; &amp; !method %in% c(&quot;2a_ipd_dc&quot;, &quot;1b_ipd_fixef&quot;)) %&gt;% pivot_longer(names_to = &quot;Trait&quot; , values_to = &quot;value&quot; , cols = E:O) %&gt;% pivot_wider(names_from = c(&quot;method&quot;, &quot;Trait&quot;) , values_from = &quot;value&quot;) rs &lt;- ipd_fx_tab_stdm %&gt;% arrange(type, Outcome, Moderator, term) %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cln1 &lt;- rep(1,16); names(cln1) &lt;- c(&quot; &quot;, rep(c(&quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;), times = 3)) cln2 &lt;- c(1, rep(5, 3)); names(cln2) &lt;- c(&quot; &quot;, &quot;Method 1A&quot;, &quot;Method 2B&quot;, &quot;Method 3&quot;) cap &lt;- &quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Cross-Method Comparison of Overall Study-Level Moderators of Personality-Crystallized Domain Associations&lt;/em&gt;&quot; tab &lt;- ipd_fx_tab_stdm %&gt;% arrange(type, Outcome, Moderator, term) %&gt;% mutate(term = mapvalues(term, stdyModers$long_term, stdyModers$medium_term)) %&gt;% mutate_at(vars(`1a_ipd_reg_E`:`3_ipd_meta_O`), ~str_replace_all(., &quot;0\\\\.&quot;, &quot;.&quot;)) %&gt;% # mutate_at(vars(`1a_ipd_reg_E`:`3_ipd_meta_O`), ~str_replace_all(., &quot;-0.&quot;, &quot;-.&quot;)) %&gt;% select(-type, -Outcome, -Moderator, -mod_type, -Covariate) %&gt;% kable(., &quot;html&quot; , col.names = c(&quot;Term&quot;, rep(&quot;b [CI]&quot;, 15)) , align = c(&quot;r&quot;, rep(&quot;c&quot;, 15)) , escape = F , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cln1) %&gt;% add_header_above(cln2) for(i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/tables/cross-method/overall/Frequentist_crystallized_study_all.html&quot;, local_path)) tab Table 7.2: Table XCross-Method Comparison of Overall Study-Level Moderators of Personality-Crystallized Domain Associations Method 1A Method 2B Method 3 E A C N O E A C N O E A C N O Term b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] b [CI] Continent North America v Europe .15[.10, .20] -.03[-.09, .04] -.04[-.10, .01] .06[.03, .09] .04[-.01, .10] .07[.004, .14] -.12[-.26, .03] -.12[-.24, .005] -.03[-.06, .009] .14[-.08, .36] .06[-.02, .14] -.08[-.19, .03] -.11[-.21, -.006] .02[-.04, .08] .08[-.13, .28] North America v Australia .06[.02, .09] .002[-.04, .04] -.04[-.08, -.008] -.13[-.17, -.10] .11[.08, .14] .03[-.05, .10] -.01[-.18, .15] -.02[-.16, .11] -.11[-.14, -.08] .11[-.19, .40] .03[-.06, .12] -.03[-.15, .08] -.06[-.17, .06] -.05[-.13, .04] .06[-.21, .33] Country US v Germany .20[.12, .27] .005[-.08, .09] -.06[-.15, .04] .10[.03, .17] .02[-.04, .09] .08[-.02, .18] -.009[-.10, .08] -.05[-.19, .09] -.02[-.09, .05] .12[-.15, .38] .09[.002, .18] -.03[-.12, .07] -.06[-.12, -.003] .02[-.08, .12] .04[-.20, .28] US v Sweden .08[.02, .15] -.22[-.33, -.11] -.21[-.30, -.11] .03[-.03, .09] .23[.09, .36] .07[-.03, .16] -.23[-.35, -.12] -.20[-.34, -.06] -.05[-.11, .01] .22[-.13, .58] .03[-.06, .13] -.15[-.28, -.02] -.18[-.27, -.09] .03[-.07, .13] .15[-.16, .46] US v Netherlands -.02[-.07, .03] -.02[-.06, .03] .03[-.08, .14] US v Australia .06[.02, .09] .001[-.04, .04] -.05[-.08, -.01] -.13[-.17, -.10] .11[.08, .14] .02[-.06, .11] -.008[-.05, .03] -.02[-.13, .08] -.11[-.14, -.08] .11[-.21, .43] .03[-.05, .12] -.03[-.11, .06] -.06[-.10, -.03] -.04[-.14, .06] .06[-.22, .34] Personality Scale NEO-FFI v DPQ .11[.06, .17] .009[-.09, .11] .07[.01, .12] NEO-FFI v Eysenck .02[-.15, .20] -.23[-.36, -.09] -.15[-.28, -.02] .21[.14, .27] -.06[-.25, .13] .09[-.007, .18] -.24[-9.45, 8.97] -.21[-.33, -.10] -.02[-.11, .08] .14[-.50, .77] .02[-.07, .12] -.21[-.31, -.11] .07[-.005, .15] .07[-.37, .51] NEO-FFI v MIDI -.06[-.22, .11] -.005[-.09, .08] .06[-.04, .15] .14[.10, .18] -.28[-.42, -.14] -.002[-.08, .08] -.007[-9.22, 9.20] .01[-.06, .08] .03[-.06, .12] -.07[-.70, .55] -.04[-.11, .03] -.02[-.08, .04] .09[.04, .14] -.13[-.55, .29] NEO-FFI v BFI-S .07[-.11, .25] .14[.05, .22] -.32[-.47, -.16] .12[.005, .23] -.01[-9.22, 9.20] -.07[-.18, .05] .03[-.09, .14] -.12[-.75, .51] .10[.01, .18] -.09[-.17, -.010] .08[.02, .14] -.14[-.57, .28] NEO-FFI v IPIP NEO .10[.01, .19] .11[-.009, .22] .01[-9.20, 9.22] -.12[-.22, -.01] -.003[-.12, .12] .01[-.61, .64] .08[-.04, .20] -.13[-.24, -.01] .06[-.04, .17] .04[-.39, .48] TDA-40 -.003[-.17, .16] -.004[-.09, .08] .01[-.08, .10] .02[-.02, .07] -.17[-.31, -.03] .04[-.04, .13] -.010[-9.22, 9.20] -.04[-.11, .02] -.08[-.17, .009] .02[-.60, .65] .03[-.05, .10] -.09[-.15, -.03] -.003[-.05, .05] -.01[-.43, .41] Baseline Age Study Baseline Age -.004[-.005, -.003] -.001[-.002, .001] -.000[-.002, .001] -.000[-.001, .001] -.004[-.005, -.003] -.001[-.003, .002] .002[-.003, .007] .002[-.002, .006] .001[-.001, .003] -.000[-.007, .007] -.001[-.003, .002] .002[-.001, .004] .002[-.001, .006] -.000[-.003, .002] .001[-.005, .007] Baseline Year Study Baseline Year -.003[-.006, .001] .007[.002, .01] .007[.003, .01] .002[.000, .005] -.010[-.01, -.004] -.000[-.005, .005] .008[.004, .01] .005[-.002, .01] .001[-.003, .005] -.008[-.02, .002] .001[-.004, .006] .005[.001, .009] .004[-.003, .01] -.000[-.005, .004] -.006[-.01, .003] Prediction Interval Prediction Interval .002[-.005, .009] -.03[-.04, -.03] -.03[-.03, -.02] -.006[-.01, -.000] .02[.01, .03] -.003[-.01, .009] -.01[-.02, -.004] -.009[-.02, .005] -.001[-.01, .010] .009[-.02, .04] -.003[-.01, .009] -.007[-.02, .001] -.008[-.02, .006] .001[-.010, .01] .007[-.01, .03] 7.1.1.2 Sample-Specific Estimates loadRData &lt;- function(fileName, type, method, obj, dir){ #loads an RData file, and returns it print(paste(type, method, fileName, dir, obj)) path &lt;- sprintf(&quot;%s/results/%s/%s/%s/%s&quot;, local_path, method, type, dir, fileName) load(path) get(ls()[grepl(obj, ls())]) } nested_ipd_rx &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , method = c(&quot;2a_ipd_dc&quot;, &quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% mutate(dir = ifelse(method == &quot;3_ipd_meta&quot;, &quot;studySummary&quot;, &quot;summary&quot;) , obj = &quot;rx&quot; # ifelse(method == &quot;3_ipd_meta&quot; &amp; type == &quot;Frequentist&quot;, &quot;fx&quot;, &quot;rx&quot;) , file = pmap(list(method, type, dir, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/%s&quot;, ..4, ..1, ..2, ..3)))) %&gt;% # filter(type != &quot;Bayesian&quot;) %&gt;% unnest(file) %&gt;% # filter(method == &quot;3_ipd_meta&quot; &amp; type == &quot;Frequentist&quot;) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% mutate(rx = pmap(list(file, type, method, obj, dir), loadRData)) %&gt;% mutate(study = str_remove_all(study, &quot;.RData&quot;) , Covariate = str_remove_all(Covariate, &quot;.RData&quot;)) %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% mutate(rx = ifelse(!is.na(study), map2(rx, study, ~(.x) %&gt;% mutate(study = .y)), rx)) %&gt;% select(-study, -dir, -file) ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_A_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_C_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_E_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_N_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2a_ipd_dc crystallized_O_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_A_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_C_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_E_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_N_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_age_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_age_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_education_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_education_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_gender_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_gender_none.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_none_age.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_none_all.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_none_education.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_none_gender.RData summary rx&quot; ## [1] &quot;Bayesian 2b_ipd_mlm crystallized_O_none_none.RData summary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_A_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_C_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_E_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_LASA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_MAP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_MARS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_N_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Bayesian 3_ipd_meta crystallized_O_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_A_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_C_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_E_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_N_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2a_ipd_dc crystallized_O_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_A_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_C_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_E_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_N_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_age_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_age_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_education_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_education_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_gender_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_gender_none.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_none_age.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_none_all.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_none_education.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_none_gender.RData summary rx&quot; ## [1] &quot;Frequentist 2b_ipd_mlm crystallized_O_none_none.RData summary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_A_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_C_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_E_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_LASA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_MAP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_MARS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_OCTO-TWIN.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_N_none_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_age_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_education_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_gender_none_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_age_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_all_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_education_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_gender_SATSA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_BASE-I.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_EAS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_GSOEP.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_HILDA.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_HRS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_ROS.RData studySummary rx&quot; ## [1] &quot;Frequentist 3_ipd_meta crystallized_O_none_none_SATSA.RData studySummary rx&quot; cols_ord &lt;- paste(rep(c(&quot;b&quot;, &quot;CI&quot;), times = 5), rep(c(&quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;), each = 2), sep = &quot;_&quot;) ipd_rx_tab &lt;- nested_ipd_rx %&gt;% unnest(rx) %&gt;% mutate(term = ifelse(is.na(term), names, term)) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name) , c(moders$long_name, stdyModers$long_name))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(CI = sprintf(&quot;[%s, %s]&quot;, conf.low, conf.high)) %&gt;% mutate_at(vars(estimate, CI), ~ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, .), .)) %&gt;% select(type, method, Outcome, Trait, Moderator, Covariate, study, term, b = estimate, CI) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = c(&quot;b&quot;, &quot;CI&quot;)) %&gt;% select(type:term, study, one_of(cols_ord)) ipd_rx_tab_fun &lt;- function(d, type, moder){ print(moder) md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) d &lt;- d %&gt;% arrange(Covariate, study, method) rs &lt;- d %&gt;% group_by(Covariate) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term)) == 1) rep(2,6) else c(3, rep(2,5)) names(cs) &lt;- c(&quot; &quot;, traits$short_name) cln &lt;- if(length(unique(d$term)) == 1) c(&quot; &quot;, &quot;Study&quot;, rep(c(&quot;&lt;em&gt;b&lt;/em&gt;&quot;, &quot;CI&quot;), times = 5)) else c(&quot; &quot;, &quot;Study&quot;, &quot;Term&quot;, rep(c(&quot;&lt;em&gt;b&lt;/em&gt;&quot;, &quot;[CI]&quot;), times = 5)) al &lt;- if(length(unique(d$term))) c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 10)) else c(&quot;r&quot;, &quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 10)) if(length(unique(d$term)) == 1) { d &lt;- d %&gt;% select(-term); dubs &lt;- F } #else { # rs2 &lt;- d %&gt;% group_by(Covariate, method) %&gt;% tally() %&gt;% # mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # d &lt;- d %&gt;% select(-method); dubs &lt;- T # } # caption cap &lt;- if(md == &quot;none&quot;) &quot;Cross-Method Comparison of Study-Specific Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;Cross-Method Comparison of Study-Specific %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% select(-Covariate) %&gt;% kable(., &quot;html&quot; , escape = F , booktabs = T , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs) %&gt;% collapse_rows(1, valign = &quot;top&quot;, row_group_label_position = &quot;stack&quot;) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Covariate[i], rs$start[i], rs$end[i]) } # if(dubs == T) for(i in 1:nrow(rs2)) { # tab &lt;- tab %&gt;% kableExtra::group_rows(rs2$method[i], rs2$start[i], rs2$end[i] # , indent = T, hline_after = F) # } save_kable(tab, file = sprintf(&quot;%s/results/tables/cross-method/study-specific/%s_%s.html&quot; , local_path, type, md)) return(tab) } nested_ipd_rx_tab &lt;- ipd_rx_tab %&gt;% mutate(study = mapvalues(study, c(&quot;BASEI&quot;, &quot;OCTOTWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;)), study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) %&gt;% select(type, Moderator, Outcome, Covariate, study, method, term, everything()) %&gt;% group_by(type, Moderator, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, type, Moderator), ipd_rx_tab_fun)) ## [1] Age ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] Education ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] Gender ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] None ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] Age ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] Education ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] Gender ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval ## [1] None ## 12 Levels: None Age Gender Self-Rated Physical Health Education Fully Adjusted Continent Country ... Prediction Interval tmp &lt;- nested_ipd_rx_tab %&gt;% filter(type == &quot;Frequentist&quot;) for(i in 1:4){ cat(&quot;#####&quot;, as.character(tmp$Moderator[[i]]), &quot;\\n\\n&quot;) print(tmp$tab[[i]]) } 7.1.1.2.1 Age 7.1.1.2.2 Education 7.1.1.2.3 Gender 7.1.1.2.4 None 7.1.1.3 Heterogeneity loadRData &lt;- function(fileName, type, method, obj, dir){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s/%s&quot;, local_path, method, type, dir, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } nested_ipd_fx &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , method = c(&quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% mutate(dir = ifelse(method == &quot;3_ipd_meta&quot;, &quot;metaHetero&quot;, &quot;heterogeneity&quot;) , file = pmap(list(method, type, dir, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/%s&quot;, ..4, ..1, ..2, ..3)))) %&gt;% # filter(type != &quot;Bayesian&quot;) %&gt;% unnest(file) %&gt;% mutate(fx = pmap(list(file, type, method, &quot;fx&quot;, dir), loadRData)) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;) %&gt;% mutate(Covariate = str_remove_all(Covariate, &quot;.RData&quot;)) 7.1.2 Figures 7.1.2.1 Meta-Analytic Estimates fx_forest_fun &lt;- function(df, outcome, mod, type, cov, mthd){ print(paste(outcome, mod)) meth &lt;- mapvalues(mthd, mthds$old_name, mthds$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- if(d &gt; .01) round(c(0-d-(d/5), 0, 0+d+(d/5)),2) else round(c(0-d-(d/5), 0, 0+d+(d/5)),3) lim_high &lt;- lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;)#str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){&quot;Main Effects&quot;} else {sprintf(&quot;Personality x %s&quot;, mod)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} trm &lt;- if(mod != &quot;None&quot;) paste(&quot;Personality x&quot;, unique(df$term[!is.na(df$term)])) df &lt;- df %&gt;% full_join(tibble(Trait = &quot; &quot;, estimate = NA, n = NA)) # df &lt;- df %&gt;% arrange(estimate) trts &lt;- df$Trait[!df$Trait %in% c(&quot; &quot;)] df &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high), lst(f = ~ifelse(abs(.) &lt; .001, sprintf(&quot;%.4f&quot;, .), ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))))) %&gt;% mutate(Trait = factor(Trait, rev(c(&quot; &quot;, traits$short_name)), rev(c(&quot; &quot;, traits$long_name))) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot; , ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;neither&quot;)) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , est = ifelse(Trait != &quot; &quot;, sprintf(&quot;%s [%s, %s]&quot;, estimate_f, conf.low_f, conf.high_f), &quot;&quot;) ) %&gt;% arrange(Trait) p1 &lt;- df %&gt;% ggplot(aes(x = Trait, y = estimate)) + geom_errorbar(aes(ymin = conf.low2, ymax = conf.high2) , position = &quot;dodge&quot; , width = 0) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = Trait) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(lb == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = Trait) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = length(trts) + .5)) + annotate(&quot;rect&quot;, xmin = length(trts) + .6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(trts) + .75, y = lim_high*.75, hjust = .5, vjust = 0, fontface = 2, size = 3) + annotate(&quot;text&quot;, label = trm, x = length(trts) + .75, y = 0, hjust = .5, vjust = 0, fontface = 2, size = 3) + geom_text(aes(y = lim_high*.75, label = est), size = 3.5) + scale_y_continuous(limits = c(lim[1], lim_high), breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = meth ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1) # , panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA) # , plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA) ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( str_wrap(meth, 50), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p &lt;- cowplot::plot_grid(ttl, p1, rel_heights = c(.15, .85), nrow = 2) return(p) } nested_ipd_fx_fig &lt;- nested_ipd_fx %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term) &amp; !(grepl(&quot;cor_&quot;, term) | grepl(&quot;sd_&quot;, term)))) %&gt;% # filter(!Moderator %in% unique(stdyModers$short_name)) %&gt;% filter(!Moderator %in% c(&quot;scale&quot;, &quot;continent&quot;, &quot;country&quot;)) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = str_replace(term, &quot;metamod&quot;, Moderator), term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name) , c(moders$long_name, stdyModers$long_name))) %&gt;% group_by(type, Moderator, Covariate, method, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, type, Covariate, method), possibly(fx_forest_fun, NA_real_))) fx_forest_comb_fun &lt;- function(d, type, out, mod, cov){ m &lt;- mapvalues(mod, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) p1 &lt;- plot_grid(plotlist = d$p , nrow = ceiling(nrow(d)/2)) titl &lt;- if(mod == &quot;None&quot;) sprintf(&quot;Personality-%s Associations&quot;, out) else sprintf(&quot;%s Moderators of Personality x %s Associations&quot;, mod, out) titl &lt;- str_wrap(if(grepl(&quot;djust&quot;, cov)) sprintf(&quot;%s: %s %s %s&quot;, out, cov, type, titl) else sprintf(&quot;%s: %s Adjusted %s %s&quot;, out, cov, type, titl), 60) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-1 ) p &lt;- cowplot::plot_grid(ttl, p1, rel_heights = c(.1, .9), nrow = 2) ht &lt;- nrow(d) ggsave(file = sprintf(&quot;%s/results/figures/cross-method/overall forest/%s_%s_%s_%s_fixed.png&quot; , local_path, o, type, m, cv) , width = 10, height = ht*1.5) ggsave(file = sprintf(&quot;%s/results/figures/cross-method/overall forest/%s_%s_%s_%s_fixed.pdf&quot; , local_path, o, type, m, cv) , width = 10, height = ht*1.5) rm(p) gc() return(T) } nested_ipd_fx_fig &lt;- nested_ipd_fx_fig %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, type, Outcome, Moderator, Covariate), fx_forest_comb_fun)) include_graphics(&quot;https://github.com/emoriebeck/data-synthesis-tutorial/raw/main/results/figures/cross-method/overall%20forest/crystallized_Frequentist_none_all_fixed.pdf&quot;) 7.1.2.2 Study-Specific Estimates loadRData &lt;- function(fileName, type, method, obj){ #loads an RData file, and returns it # print(paste(type, method, fileName, dir, obj)) path &lt;- sprintf(&quot;%s/results/%s/%s/figures/study specific forest/rdata/%s&quot;, local_path, method, type, fileName) load(path) get(ls()[ls() == obj]) } nested_ipd_fp &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , method = c(&quot;2a_ipd_dc&quot;, &quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% mutate(file = pmap(list(method, type, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/figures/study specific forest/rdata&quot;, ..3, ..1, ..2)))) %&gt;% # filter(type != &quot;Bayesian&quot;) %&gt;% unnest(file) %&gt;% # filter(method == &quot;3_ipd_meta&quot; &amp; type == &quot;Frequentist&quot;) %&gt;% mutate(p = pmap(list(file, type, method, &quot;p&quot;), loadRData)) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;) %&gt;% mutate(Covariate = str_remove_all(Covariate, &quot;.RData&quot;)) %&gt;% filter(!Moderator %in% stdyModers$short_name) %&gt;% left_join( nested_ipd_rx %&gt;% unnest(rx) %&gt;% mutate(term = ifelse(is.na(term), names, term)) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(study = mapvalues(study, c(&quot;BASEI&quot;, &quot;OCTOTWIN&quot;), c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;)), study = mapvalues(study, c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;), c(&quot;BASE&quot;, &quot;OCTO-Twin&quot;))) %&gt;% group_by(type, method, Outcome, Trait, Moderator, Covariate) %&gt;% summarize(nstd = n()) %&gt;% ungroup() ) ipd_study_fp_fun &lt;- function(d, outcome, cov, mod, type){ print(paste(outcome, cov, mod, type)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) md &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) titl &lt;- paste0(o, &quot;,&quot;) titl &lt;- if(!cov %in% c(&quot;none&quot;, &quot;all&quot;)) paste(titl, cv, &quot;Adjusted&quot;, collapse = &quot;, &quot;) else paste(titl, cv, collapse = &quot;, &quot;) ns &lt;- d %&gt;% group_by(method) %&gt;% mutate(nstd = ((nstd + 2))/sum(nstd+2)) %&gt;% group_by(Trait) %&gt;% summarize(nstd = mean(nstd)) # + theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA), plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA)) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold.italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) p1 &lt;- plot_grid( d$p[[1]] , d$p[[2]] , d$p[[3]] , d$p[[4]] , d$p[[5]] , nrow = 5 , ncol = 1 , rel_heights = ns$nstd , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) ttl &lt;- ggdraw() + draw_label( str_wrap(mthds$long_name[3], 40), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) p1 &lt;- plot_grid( ttl, p1, rel_heights = c(.05, .95), ncol = 1 ) p2 &lt;- plot_grid( d$p[[6]] , d$p[[7]] , d$p[[8]] , d$p[[9]] , d$p[[10]] , nrow = 5 , ncol = 1 , rel_heights = ns$nstd , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) ttl &lt;- ggdraw() + draw_label( str_wrap(mthds$long_name[4], 40), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) p2 &lt;- plot_grid( ttl, p2, rel_heights = c(.05, .95), ncol = 1 ) p3 &lt;- plot_grid( d$p[[11]] , d$p[[12]] , d$p[[13]] , d$p[[14]] , d$p[[15]] , nrow = 5 , ncol = 1 , rel_heights = ns$nstd , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) ttl &lt;- ggdraw() + draw_label( str_wrap(mthds$long_name[5], 40), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) p3 &lt;- plot_grid( ttl, p3, rel_heights = c(.05, .95), ncol = 1 ) p &lt;- plot_grid( p1, p2, p3 , ncol = 3 ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;, size = rel(1.8))) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( str_wrap(&quot;Point Estimates Are Quite Consistent Across Methods, While Confidence Intervals Vary Slightly Across Methods, Especially for Methods 2A and 3 versus 2B&quot;, 80), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) p &lt;- plot_grid( ttl, p, rel_heights = c(.05, .95), ncol = 1 ) ggsave(p, file = sprintf(&quot;%s/results/figures/cross-method/study-specific forest/%s-%s-%s-%s.png&quot;, local_path, type, outcome, mod, cov) , width = 14 , height = 14) ggsave(p, file = sprintf(&quot;%s/results/figures/cross-method/study-specific forest/%s-%s-%s-%s.pdf&quot;, local_path, type, outcome, mod, cov) , width = 14 , height = 14) return(p) } nested_ipd_fp_comb &lt;- nested_ipd_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(type, method, Outcome, Trait, Moderator, Covariate) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(type == &quot;Frequentist&quot;) %&gt;% mutate(p = pmap(list(data, Outcome, Covariate, Moderator, type), ipd_study_fp_fun)) tmp &lt;- nested_ipd_fp_comb %&gt;% filter(type == &quot;Frequentist&quot; &amp; Covariate == &quot;all&quot;) for(i in 1:4){ cat(&quot;#####&quot;, as.character(tmp$Moderator[[i]]), &quot;\\n\\n&quot;) print(tmp$p[[i]]) } 7.1.2.3 Overall Simple Effects loadRData &lt;- function(fileName, type, method, obj, dir){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s/%s&quot;, local_path, method, type, dir, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } nested_simp_fx &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , method = c(&quot;1a_ipd_reg&quot;, &quot;1b_ipd_fixef&quot;, &quot;2a_ipd_dc&quot;, &quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% mutate(dirfx = ifelse(method != &quot;3_ipd_meta&quot;, &quot;predicted&quot;, &quot;metaPredicted&quot;) , dirrx = ifelse(method != &quot;3_ipd_meta&quot;, &quot;predicted&quot;, &quot;studyPredicted&quot;) , file = pmap(list(method, type, dirfx, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/%s&quot;, ..4, ..1, ..2, ..3)))) %&gt;% unnest(file) %&gt;% # filter(method == &quot;3_ipd_meta&quot;) %&gt;% mutate(pred.fx = pmap(list(file, type, method, &quot;pred.fx&quot;, dirfx), possibly(loadRData, NA_real_))#, # pred.rx = pmap(list(file, type, method, &quot;pred.rx&quot;, dirrx), possibly(loadRData, NA_real_)) ) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;), sep = &quot;_&quot;) %&gt;% mutate(Covariate = str_remove_all(Covariate, &quot;.RData&quot;)) pred_fx_prep_fun &lt;- function(d, mod, method){ # print(paste(mod, method)) if(method == &quot;3_ipd_meta&quot; &amp; mod %in% moders$short_name) return(d) else d &lt;- d %&gt;% unclass %&gt;% data.frame d$mod_value &lt;- d[,mod] d &lt;- d %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(d$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value))} else { if(mod == &quot;age&quot;) d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;-10 yrs&quot;, &quot;M&quot;, &quot;+10 yrs&quot;))) else if(mod == &quot;baseYear&quot;) d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;1990&quot;, &quot;200)0&quot;, &quot;2010&quot;))) else if(mod == &quot;baseAge&quot;) d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;50&quot;, &quot;60&quot;, &quot;70&quot;))) else if(mod == &quot;predInt&quot;) d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;5 yrs&quot;, &quot;+5 yrs&quot;))) else if(mod == &quot;education&quot;) d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;))) else d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) } d %&gt;% group_by(p_value, mod_fac) %&gt;% summarize_at(vars(one_of(c(&quot;pred&quot;, &quot;lower&quot;, &quot;upper&quot;))), mean) %&gt;% ungroup() } nested_simp_fx &lt;- nested_simp_fx %&gt;% # filter(Moderator == &quot;baseAge&quot; &amp; type == &quot;Frequentist&quot; &amp; method == &quot;3_ipd_meta&quot;) %&gt;% mutate(pred.fx = pmap(list(pred.fx, Moderator, method), pred_fx_prep_fun)) ipd_se_plot_fun &lt;- function(d, outcome, mod, cov, type){ print(paste(mod, cov, type, outcome)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, c(moders$short_name, stdyModers$short_name), c(moders$long_name, stdyModers$long_name), warn_missing = F) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s&quot;, o)} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} # lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(d$mod_fac))] ht &lt;- length(unique(d$mod_fac)) mini &lt;- floor(min(d$pred)); maxi &lt;- 10 p &lt;- d %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name)#, labels = traits$long_name) , method = mapvalues(method, mthds$old_name, str_wrap(mthds$long_name, 28), warn_missing = F) , lower = ifelse(lower &lt; mini, mini, lower) , upper = ifelse(upper &gt; maxi, maxi, upper)) %&gt;% ggplot(aes(x = p_value, y = pred, group = interaction(Trait, mod_fac), linetype = mod_fac)) + geom_line(aes(#color = mod_fac , group = mod_fac , linetype = mod_fac) , size = .75) + geom_ribbon(aes(fill = mod_fac , group = mod_fac , ymin = lower , ymax = upper) , alpha = .25) + facet_grid(Trait~method, scales = &quot;free&quot;) + scale_y_continuous(limits = c(mini,maxi) , breaks = seq(mini, maxi, by = 2) , labels = seq(mini, maxi, by = 2)) + # scale_color_manual(values = cols) + # scale_linetype_manual(values = lt) + labs(x = &quot;Personality Score (POMP)&quot; , y = &quot;Cognition Score (POMP)&quot; # , color = m , fill = m , linetype = m , title = titl # , subtitle = &quot;Method 3: Two-Stage Individual Participant Meta-Analysis&quot; ) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) # , strip.background.y = element_rect(fill = &quot;white&quot;, color = &quot;white&quot;) , strip.text.x = element_text(face = &quot;bold&quot;, color = &quot;white&quot;, size = rel(1)) , strip.text.y = element_text(face = &quot;bold&quot;, color = &quot;white&quot;, size = rel(1))#, angle = 0) , axis.text = element_text(color = &quot;black&quot;)) local_path &lt;- length(unique(d$method))*2 ggsave(p, file = sprintf(&quot;%s/results/figures/cross-method/overall simple effects/%s_%s_%s_%s.png&quot;, local_path, type, outcome, mod, cov) , width = local_path, height = 7) ggsave(p, file = sprintf(&quot;%s/results/figures/cross-method/overall simple effects/%s_%s_%s_%s.pdf&quot;, local_path, type, outcome, mod, cov) , width = local_path, height = 7) return(p) } nested_simp_fx_fp &lt;- nested_simp_fx %&gt;% filter(!(method %in% c(&quot;1b_ipd_fixef&quot;, &quot;2a_ipd_dc&quot;) &amp; Moderator %in% stdyModers$short_name)) %&gt;% group_by(type, Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.fx)) , p = pmap(list(data, Outcome, Moderator, Covariate, type), ipd_se_plot_fun)) 7.1.2.4 Study-Specific Simple Effects loadRData &lt;- function(fileName, type, method, obj, dir){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s/%s&quot;, local_path, method, type, dir, fileName) # print(path) load(path) get(ls()[grepl(obj, ls())]) } nested_simp_rx &lt;- crossing(type = c(&quot;Frequentist&quot;, &quot;Bayesian&quot;) , method = c(&quot;2a_ipd_dc&quot;, &quot;2b_ipd_mlm&quot;, &quot;3_ipd_meta&quot;)) %&gt;% mutate(dir = ifelse(method != &quot;3_ipd_meta&quot;, &quot;predicted&quot;, &quot;studyPredicted&quot;) , file = pmap(list(method, type, dir, local_path), ~list.files(sprintf(&quot;%s/results/%s/%s/%s&quot;, ..4, ..1, ..2, ..3)))) %&gt;% unnest(file) %&gt;% # filter(method == &quot;3_ipd_meta&quot;) %&gt;% mutate(pred.rx = pmap(list(file, type, method, &quot;pred.rx&quot;, dir), loadRData)) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;, &quot;Covariate&quot;, &quot;study&quot;), sep = &quot;_&quot;) %&gt;% mutate(study = str_remove_all(study, &quot;.RData&quot;) , Covariate = str_remove_all(Covariate, &quot;.RData&quot;)) %&gt;% filter(!Moderator %in% stdyModers$short_name &amp; Moderator != &quot;SRhealth&quot;) %&gt;% mutate(pred.rx = ifelse(!is.na(study), map2(pred.rx, study, ~(.x) %&gt;% mutate(study = .y)), pred.rx)) %&gt;% select(-study, -dir) pred_rx_prep_fun &lt;- function(d, mod){ d &lt;- d %&gt;% unclass %&gt;% data.frame d$mod_value &lt;- d[,mod] d &lt;- d %&gt;% select(-all_of(mod)) %&gt;% as_tibble if(class(d$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){ d &lt;- d %&gt;% mutate(mod_fac = factor(mod_value)) } else{ d2 &lt;- d %&gt;% select(study, mod_value) %&gt;% distinct() %&gt;% arrange(study, mod_value) if(mod == &quot;age&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;-10 yrs&quot;, &quot;M&quot;, &quot;+10 yrs&quot;))) else if(mod == &quot;baseYear&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;1990&quot;, &quot;200)0&quot;, &quot;2010&quot;))) else if(mod == &quot;baseAge&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;50&quot;, &quot;60&quot;, &quot;70&quot;))) else if(mod == &quot;predInt&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;5 yrs&quot;, &quot;+5 yrs&quot;))) else if(mod == &quot;education&quot;) d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;))) else d2 &lt;- d2 %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) d &lt;- d %&gt;% full_join(d2) %&gt;% ungroup() } d %&gt;% group_by(study, mod_fac, p_value) %&gt;% summarize_at(vars(one_of(c(&quot;pred&quot;, &quot;lower&quot;, &quot;upper&quot;))), mean) %&gt;% ungroup() } nested_simp_rx &lt;- nested_simp_rx %&gt;% unnest(pred.rx) %&gt;% group_by(type, Outcome, Trait, Moderator, Covariate) %&gt;% nest(pred.rx = p_value:upper) %&gt;% ungroup() %&gt;% mutate(pred.rx = map2(pred.rx, Moderator, pred_rx_prep_fun)) ipd_std_se_plot_fun &lt;- function(df, outcome, trait, mod, cov, type){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} std &lt;- unique(df$study) cols &lt;- (stdcolors %&gt;% filter(studies %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies %in% std))$lt ht &lt;- length(unique(df$mod_fac)) mini &lt;- if(min(df$pred) &gt; 0) floor(min(df$pred)) else 0; maxi &lt;- 10 p &lt;- df %&gt;% filter(!is.na(study)) %&gt;% mutate(study = factor(study, levels = stdcolors$studies), method = mapvalues(method, mthds$old_name, str_wrap(mthds$long_name, 25), warn_missing = F), # lower = ifelse(lower &lt; 4, 4, lower), # upper = ifelse(upper &gt; 10, 10, upper), gr = ifelse(study == &quot;Overall&quot;, &quot;Overall&quot;, &quot;study&quot;)) %&gt;% group_by(study, mod_fac, p_value, gr, method) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() %&gt;% ggplot(aes(x = p_value , y = pred , group = study)) + scale_y_continuous(limits = c(mini,maxi) , breaks = seq(mini, maxi, by = 2) , labels = seq(mini, maxi, by = 2)) + scale_linetype_manual(values = lt) + scale_color_manual(values = cols) + scale_fill_manual(values = cols) + scale_size_manual(values = c(2,.8)) + geom_line(aes(linetype = study, color = study, size = gr)) + labs(x = &quot;Personality (POMP)&quot; , y = paste(o, &quot;(POMP)&quot;) , title = titl , linetype = &quot;Study&quot; , color = &quot;Study&quot; , fill = &quot;Study&quot; # , subtitle = &quot;Method 2B: Pooled Regression Using Random Effects&quot; ) + guides(size = &quot;none&quot;) + facet_grid(mod_fac ~ method, scales = &quot;free&quot;) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) # , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;, color = &quot;black&quot;) , panel.background = element_rect(color = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(p, file = sprintf(&quot;%s/results/figures/cross-method/study specific simple effects/%s_%s_%s_%s_%s.png&quot;, local_path, type, outcome, trt, mod, cov), width = 8, height = 3*ht) ggsave(p, file = sprintf(&quot;%s/results/figures/cross-method/study specific simple effects/%s_%s_%s_%s_%s.pdf&quot;, local_path, type, outcome, trt, mod, cov), width = 8, height = 3*ht) return(p) } nested_simp_fx %&gt;% select(-contains(&quot;dir&quot;)) %&gt;% right_join(nested_simp_rx %&gt;% mutate(pred.rx = map(pred.rx , ~(.) %&gt;% mutate(study = mapvalues( study, c(&quot;OCTOTWIN&quot;, &quot;OCTO-TWIN&quot;, &quot;BASEI&quot;, &quot;BASE-I&quot;) , c(&quot;OCTO-Twin&quot;, &quot;OCTO-Twin&quot;, &quot;BASE&quot;, &quot;BASE&quot;) , warn_missing = F)) ))) %&gt;% filter(!map_lgl(pred.fx, is.null)) %&gt;% mutate(pred.comb = map2(pred.fx, pred.rx, ~(.x) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% full_join(.y))) %&gt;% select(-pred.fx, -pred.rx) %&gt;% group_by(type, Outcome, Trait, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(type == &quot;Frequentist&quot; &amp; Moderator == &quot;gender&quot; &amp; Trait == &quot;E&quot;) %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.comb)) , pmap(list(data, Outcome, Trait, Moderator, Covariate, type), ipd_std_se_plot_fun)) 7.2 Comparisons Across Methods: Bayesian versus Frequentist 7.2.1 Tables 7.2.1.1 Fixed Effects ## table function ipd_comp_fx_tab_fun &lt;- function(d, moder, covar){ print(moder) md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) cv &lt;- mapvalues(covar, covars$long_name, covars$short_name) rs &lt;- d %&gt;% mutate(method = factor(method, levels = mthds$old_name, labels = mthds$long_name)) %&gt;% group_by(method) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term)) == 1) c(1, rep(2,5)) else rep(2,6) names(cs) &lt;- c(&quot; &quot;, traits$short_name) cln &lt;- if(length(unique(d$term)) == 1) c(&quot; &quot;, rep(c(&quot;&lt;em&gt;b&lt;/em&gt;&quot;, &quot;CI&quot;), times = 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(c(&quot;&lt;em&gt;b&lt;/em&gt;&quot;, &quot;[CI]&quot;), times = 5)) al &lt;- if(length(unique(d$term))) c(&quot;r&quot;, rep(&quot;c&quot;, 10)) else c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 10)) if(length(unique(d$term)) == 1) { d &lt;- d %&gt;% select(-term) } cap &lt;- if(md == &quot;none&quot;) &quot;Comparison of Bayesian and Frequentist Approaches to Overall Effects of Personality-Crystallized Domain Associations&quot; else sprintf(&quot;Comparison of Bayesian and Frequentist Approaches to Overall %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% select(-method) %&gt;% kable(., &quot;html&quot; , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs) %&gt;% collapse_rows(1, valign = &quot;top&quot;, row_group_label_position = &quot;stack&quot;) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$method[i], rs$start[i], rs$end[i]) } # if(dubs == T) for(i in 1:nrow(rs2)) { # tab &lt;- tab %&gt;% kableExtra::group_rows(rs2$method[i], rs2$start[i], rs2$end[i] # , indent = T, hline_after = F) # } save_kable(tab, file = sprintf(&quot;%s/results/tables/bayes-v-freq/overall/%s_%s.html&quot; , local_path, md, cv)) return(tab) } nested_comp_fx_tab &lt;- ipd_fx_tab %&gt;% group_by(Moderator, Covariate, Outcome) %&gt;% arrange(method, type) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Moderator, Covariate), ipd_comp_fx_tab_fun)) 7.2.1.2 Study-Specific ipd_rx_comp_tab_fun &lt;- function(d, moder, covar){ print(moder) md &lt;- mapvalues(moder, c(moders$long_name, stdyModers$long_name), c(moders$short_name, stdyModers$short_name), warn_missing = F) cv &lt;- mapvalues(covar, covars$long_name, covars$short_name) rs &lt;- d %&gt;% mutate(method = factor(method, levels = mthds$old_name, labels = mthds$long_name)) %&gt;% group_by(method) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- if(length(unique(d$term)) == 1) rep(2,6) else c(3, rep(2,5)) names(cs) &lt;- c(&quot; &quot;, traits$short_name) cln &lt;- if(length(unique(d$term)) == 1) c(&quot; &quot;, &quot;Study&quot;, rep(c(&quot;&lt;em&gt;b&lt;/em&gt;&quot;, &quot;CI&quot;), times = 5)) else c(&quot; &quot;, &quot;Study&quot;, &quot;Term&quot;, rep(c(&quot;&lt;em&gt;b&lt;/em&gt;&quot;, &quot;[CI]&quot;), times = 5)) al &lt;- if(length(unique(d$term))) c(&quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 10)) else c(&quot;r&quot;, &quot;r&quot;, &quot;r&quot;, rep(&quot;c&quot;, 10)) if(length(unique(d$term)) == 1) { d &lt;- d %&gt;% select(-term); dubs &lt;- F } #else { # rs2 &lt;- d %&gt;% group_by(Covariate, method) %&gt;% tally() %&gt;% # mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # d &lt;- d %&gt;% select(-method); dubs &lt;- T # } # caption cap &lt;- if(md == &quot;none&quot;) &quot;Comparison of Bayesian and Frequentist Approaches to Personality-Crystallized Domain Associations&quot; else sprintf(&quot;Comparison of Bayesian and Frequentist Approaches to Study-Specific %s Moderation of Personality-Crystallized Domain Associations&quot;, md) tab &lt;- d %&gt;% select(study, type, everything(), -method) %&gt;% kable(., &quot;html&quot; , escape = F , booktabs = T , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs) %&gt;% collapse_rows(1:2, valign = &quot;top&quot;, row_group_label_position = &quot;stack&quot;) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$method[i], rs$start[i], rs$end[i]) } # if(dubs == T) for(i in 1:nrow(rs2)) { # tab &lt;- tab %&gt;% kableExtra::group_rows(rs2$method[i], rs2$start[i], rs2$end[i] # , indent = T, hline_after = F) # } save_kable(tab, file = sprintf(&quot;%s/results/tables/bayes-v-freq/study-specific/%s_%s.html&quot; , local_path, md, cv, md)) return(tab) } nested_comp_fx_tab &lt;- ipd_rx_tab %&gt;% mutate(study = mapvalues(study, c(&quot;BASEI&quot;, &quot;OCTOTWIN&quot;), c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;))) %&gt;% group_by(Moderator, Covariate, Outcome) %&gt;% arrange(method, study, type) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Moderator, Covariate), ipd_rx_comp_tab_fun)) 7.2.2 Figures 7.2.2.1 Fixed Effects fx_forest_fun &lt;- function(d, mod, type, cov){ print(paste(mod, cov)) m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) d &lt;- d %&gt;% filter(!is.na(estimate)) dl &lt;- round(max(abs(min(d$estimate)), abs(max(d$estimate))), 3) dig &lt;- if(dl &lt; .01) 3 else 2 lim &lt;- if(mod == &quot;none&quot;){c(-.25, .25)} else{c(round_any(0-dl-(dl/2.5), .001, floor), round_any(0+dl+(dl/2.5), .001, ceiling))} brk &lt;- if(mod == &quot;none&quot;){seq(-.2,.2,.2)} else{round(c(0-dl-(dl/5), 0, 0+dl+(dl/5)),3)} lab &lt;- if(mod == &quot;none&quot;){c(&quot;-.2&quot;, &quot;0&quot;, &quot;.2&quot;)} else{round(c(0-dl-(dl/5), 0, 0+dl+(dl/5)),dig)} shapes &lt;- c(15, 16)[1:length(unique(d$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(d$term))) titl &lt;- if(m == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, mod)} titl &lt;- if(!cv %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cov, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cov, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(d$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- d %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high)) %&gt;% ggplot(aes(x = method, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(1.3, .85)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;blue&quot;, &quot;black&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .25, color = &quot;gray50&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL, y = &quot;Estimate (POMP)&quot;, title = titl) + facet_grid(Outcome~Trait, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(d$Outcome)) local_path &lt;- length(unique(d$Trait)) ggsave(file = sprintf(&quot;%s/results/figures/bayes-v-freq/overall forest/%s_%s_%s_fixed.png&quot;, local_path, type, mod, cv), width = local_path*2, height = ht*3) gc() return(p) } nested_ipd_fx_fig &lt;- nested_ipd_fx %&gt;% unnest(fx) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term) &amp; !(grepl(&quot;cor_&quot;, term) | grepl(&quot;sd_&quot;, term)))) %&gt;% # filter(!Moderator %in% unique(stdyModers$short_name)) %&gt;% filter(!Moderator %in% c(&quot;scale&quot;, &quot;continent&quot;, &quot;country&quot;)) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = ifelse(term == &quot;gender&quot;, &quot;genderFemale&quot;, term), term = str_replace(term, &quot;metamod&quot;, Moderator), term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name) , c(moders$long_name, stdyModers$long_name))) %&gt;% group_by(type, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Moderator == &quot;Gender&quot;) %&gt;% mutate(p = pmap(list(data, Moderator, type, Covariate), fx_forest_fun)) 7.2.2.2 Study-Specific Effects rx_forest_fun &lt;- function(d, mod, type, cov, out){ print(paste(mod, cov)) m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$long_name, covars$short_name, warn_missing = F) d &lt;- d %&gt;% filter(!is.na(estimate)) dl &lt;- round(max(abs(min(d$estimate)), abs(max(d$estimate))), 3) lim &lt;- if(mod == &quot;none&quot;){c(-.25, .25)} else{c(0-dl-(dl/2.5), 0+dl+(dl/2.5))} brk &lt;- if(mod == &quot;none&quot;){seq(-.2,.2,.2)} else{round(c(0-dl-(dl/5), 0, 0+dl+(dl/5)),2)} lab &lt;- if(mod == &quot;none&quot;){c(&quot;-.2&quot;, &quot;0&quot;, &quot;.2&quot;)} else{str_remove(round(c(0-dl-(dl/5), 0, 0+dl+(dl/5)),2), &quot;^0&quot;)} shapes &lt;- c(15, 16)[1:length(unique(d$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(d$term))) titl &lt;- if(m == &quot;none&quot;){NULL} else {sprintf(&quot;%s Moderation of Personality-Outcome Associations&quot;, mod)} titl &lt;- if(!cv %in% c(&quot;none&quot;, &quot;all&quot;)) paste(cov, &quot;Adjusted&quot;, titl, collapse = &quot; &quot;) else paste(cov, titl, collapse = &quot; &quot;) leg &lt;- if(length(unique(d$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} p &lt;- d %&gt;% mutate(conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low), conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high), Trait = factor(Trait, levels = traits$short_name)) %&gt;% ggplot(aes(x = method, y = estimate)) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_manual(values = c(.85, 1.3)) + scale_shape_manual(values = shapes) + scale_color_manual(values = c(&quot;black&quot;, &quot;blue&quot;)) + scale_linetype_manual(values = lt) + geom_hline(aes(yintercept = 0), size = .25, color = &quot;gray50&quot;) + geom_errorbar(aes(ymin = conf.low, ymax = conf.high, linetype = term) , width = 0 , position = position_dodge(width = .9)) + geom_point(aes(color = sig, size = sig, shape = term) , position = position_dodge(width = .9)) + labs(x = NULL, y = &quot;Estimate (POMP)&quot;, title = titl) + facet_grid(Trait~study, scales = &quot;free_y&quot;, space = &quot;free&quot;) + coord_flip() + theme_classic() + theme(legend.position = leg, plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5), panel.background = element_rect(color = &quot;black&quot;, fill = &quot;white&quot;), strip.background = element_blank(), strip.text.y = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.4)), strip.text.x = element_text(face = &quot;bold&quot;, color = &quot;black&quot;, size = rel(1.3)), axis.text = element_text(color = &quot;black&quot;), axis.text.y = element_text(size = rel(1))) ht &lt;- length(unique(d$Trait)) local_path &lt;- length(unique(d$study)) ggsave(file = sprintf(&quot;%s/results/figures/bayes-v-freq/study-specific/%s_%s_%s_%s_fixed.png&quot;, local_path, type, out, mod, cv), width = local_path*1.5, height = ht*2) gc() return(p) } nested_ipd_rx_fig &lt;- nested_ipd_rx %&gt;% unnest(rx) %&gt;% mutate(term = ifelse(is.na(term), names, term)) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = ifelse(term == &quot;gender&quot;, &quot;genderFemale&quot;, term), term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, c(moders$short_name, stdyModers$short_name) , c(moders$long_name, stdyModers$long_name)), study = mapvalues(study, c(&quot;BASEI&quot;, &quot;OCTOTWIN&quot;), c(&quot;BASE-I&quot;, &quot;OCTO-TWIN&quot;))) %&gt;% group_by(type, Moderator, Covariate, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Moderator, type, Covariate, Outcome), rx_forest_fun)) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
