---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Data Cleaning {#cleaning}

```{r mode fun}
Mode <- function(x) {
  ux <- unique(x)
  ux <- ux[!is.na(ux)]
  ux[which.max(tabulate(match(x, ux)))]
}
```

## Berlin Aging Study (BASE-I)  

The Berlin Aging Study (I) is a longitudinal interdisciplinary study of aging that began in 1990. The data are available, by application, from https://www.base-berlin.mpg.de/en/system/files/media/pdf/a97295f241d06bf496b5eeae4251a34e/base-data-transfer_form_online.pdf.  

Participants included 516 individuals over 70, stratified on age and gender, recruited from a sample of the Berlin City Registry. To date, most participants are deceased, with most attrition from the study due to mortality or severe health complications. Since 1990, there have been seven follow-up measurement occasions (8 total).  

Sample sizes vary over time, from 516 (T1) to 23 (T8). To ensure adequate sample sizes, the present study will use data up to the fourth wave, which included 164 participants with full data. This provides 99% power to detect a correlation effect size of ~.32, two-tailed alpha at .05.  

### Load Data  

```{r base i codebook}
(basei_codebook <- (codebook %>% filter(study == "BASE-I"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r base i data, eval = F}
basei <- sprintf("%s/base-i/Beck_202010.sav", data_path) %>% read_sav() %>%
  full_join(sprintf("%s/base-i/Beck_202010_2.sav", data_path) %>% read_sav())
```

### Recoding & Reverse Scoring  

```{r base i recode, eval = F}
rename_fun <- function(cb, var){
  old.names <- unique((basei_codebook %>% filter(name == var))$orig_itemname)
  df <- basei %>% 
    select(SID = id, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, na.rm=T)
  if(length(old.names) > 1){
      df %>% left_join(cb %>% select(itemname, wave, orig_itemname, reverse_code:long_rule))
  } else {
    df %>% left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule) %>% distinct()) %>% mutate(wave = "0")
  }
}

`
# join data with recoding info 
basei_recode <- basei_codebook %>%
  select(category, name, itemname, wave, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

basei_recode <- basei_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
basei_recode <- basei_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```


### Covariates  

```{r basei covariates, eval = F}
# composite WITHIN years 
basei_cov <- basei_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave <= 1)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
basei_cov <- basei_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  
```{r basei personality, eval = F}
basei_pers <- basei_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(wave == 1 & !is.na(value)) %>%
  group_by(SID, wave, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
basei_alpha <- basei_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, wave, SID, value) %>%
  group_by(name, wave) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID), check.keys = T), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
basei_pers <- basei_pers %>%
  group_by(name, comp_rule, wave) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  
```{r basei out, eval = F}
basei_cog_waves <- basei_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

# composite within years
basei_out <- basei_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  right_join(basei_cog_waves) %>%
  filter(wave == o_year & wave > 1) %>%
  group_by(name, wave, SID) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  
```{r basei combine, eval = F}
basei_combined <- basei_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    basei_out %>% 
      rename(Outcome = name, o_value = value, o_year = wave)
    ) %>% full_join(basei_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r basei save, eval = F}
save(basei_cov, basei_alpha, basei_pers, basei_out, basei_combined,
     file = sprintf("%s/data/clean/base-i_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("basei", ls())])
```

## Einstein Aging Study (EAS)  
The Einstein Aging Study is an ongoing longitudinal study of older adults in the United States that began in 1980. The data are available on a project-by-project basis by submitting a concept proposal at https://www.einstein.yu.edu/departments/neurology/clinical-research-program/eas/data-sharing.aspx.  

Since 1993, the EAS has systematically recruited a representative aging sample in the Bronx, New York. As of 2017, 2,600 participants were enrolled in the study. As of 2010, approximately 200 of the enrolled participants had autopsy data. More information on the study can be found at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/EAS/.  

Sample sizes vary over time, with ranges across waves not publicly available. However, we suspect approximately 2,000 participants to have basic personality and cognitive ability data. This yields 99\% power to detect a zero-order correlation effect size of .10, two-tailed at alpha .05.    


### Load Data  
```{r eas codebook}
(eas_codebook <- (codebook %>% filter(study == "EAS"))$codebook[[1]])
```

```{r nlsy data, eval = F}
# old.names1 <- unique((eas_codebook %>% filter(dataset == "jrp"))$orig_itemname)
# old.names2 <- unique((eas_codebook %>% filter(dataset == "dataset"))$orig_itemname)
old.names <- unique(eas_codebook$orig_itemname)
eas <- sprintf("%s/eas/Behavior_with_Master_Data_2021_09_24.xlsx", data_path) %>% 
  read_excel(.) %>% 
  select(SID = Id, wave = Wave, year = BehaviorDate, one_of(old.names)) %>%
  mutate(year = lubridate::year(year)
        , Gender = as.numeric(mapvalues(Gender, c("M", "F"), c(0,1))))
  # full_join(
  #   sprintf("%s/eas/dataset.xlsx", data_path) %>% 
  #     read_excel(.) %>% 
  #     select(SID = id, one_of(old.names2))
  # )

eas_long <- eas %>%
  pivot_longer(values_to = "value"
               , names_to = "orig_itemname"
               , cols = c(-SID, -wave, -year)
               , values_drop_na = T)
```

### Recoding & Reverse Scoring  
```{r eas recode, eval = F}
# join data with recoding info 
eas_recode <- eas_codebook %>%
  filter(category %in% c("pers", "outcome", "covariates") & !is.na(orig_itemname)) %>%
  select(category, name, itemname, orig_itemname, reverse_code:long_rule) %>%
  group_by(category, name) %>% 
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(eas_long))) 

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

eas_recode <- eas_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    group_by(recode, year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
eas_recode <- eas_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```

```{r, eval = F}
eas_waves <- eas_recode %>% 
  filter(category == "pers") %>%
  unnest(data) %>% 
  select(SID, p_year = year) %>%
  distinct() %>%
  group_by(SID) %>%
  filter(p_year == min(p_year)) %>%
  ungroup()
```

### Covariates  

```{r eas covariates, eval = F}
# composite WITHIN years 
eas_cov <- eas_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      left_join(eas_waves) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, year, p_year, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(year <= p_year)
      # summarize(value = fun_call(value, comp_rule)) %>%
      # ungroup() %>% 
      # mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
      ))

comp_fun <- function(d, rule, p_year){
  print(paste(rule, p_year))
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
eas_cov <- eas_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  filter(year <= p_year) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  
```{r eas personality, eval = F}
eas_pers <- eas_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  left_join(eas_waves) %>%
  group_by(SID, p_year, year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
eas_alpha <- eas_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
eas_pers <- eas_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  
```{r eas out, eval = F}
# composite within years
eas_out <- eas_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  filter(year == max(year)) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, year, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup() 
```

### Combine Data  
```{r eas combine, eval = F}
eas_combined <- eas_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(eas_out %>% rename(Outcome = name, o_value = value, o_year = year)) %>%
  full_join(eas_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r eas save, eval = F}
save(eas_cov, eas_alpha, eas_pers, eas_out, eas_combined,
     file = sprintf("%s/data/clean/eas_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("eas", ls())])
```

## German Socioeconomic Panel (GSOEP)  

The German Socioeconomic Panel Study (GSOEP; Socio-Economic Panel, 2017) is an ongoing longitudinal study of Germans collected by the German Institute of Economic Research (DIW Berlin). The data are freely available at https://www.diw.de/soep by application.  

Data have been collected annually since 1984 (the latest data release includes data up to 2017). Participants have been recruited from more than 11,000 households, which are nationally representative of private German households. 20,000 individuals are sampled each year, on average. It is critical to note that the GSOEP samples households, not individuals, and the households consist of individuals living in both the “old” and “new” federal states (the former West and East Germany), foreigners, and recent immigrants to Germany.  

 Sample size varies by year, ranging from approximately 10,000 (1989) to 31,000 (2013). This provides 99\% power to detect a zero-order correlation effect size of ~.06, two-tailed at alpha < .05.  
 
### Load Data  

```{r gsoep clean fun, eval = F}
gsoep_read_fun <- function(Year, WL){
  old.names <- (gsoep_codebook %>% filter(year == Year | category == "proc"))$orig_itemname 
  p <- sprintf("%s/gsoep/%sp.sav", data_path, WL) %>% haven::read_sav(.) %>%
    full_join(sprintf("%s/gsoep/%skind.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    full_join(sprintf("%s/gsoep/%spequiv.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    full_join(sprintf("%s/gsoep/%spgen.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    full_join(sprintf("%s/gsoep/%spkal.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    select(one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -persnr, -hhnr, na.rm = T)
  
 sprintf("%s/gsoep/%shbrutto.sav", data_path, WL) %>% haven::read_sav(.) %>%
    full_join(sprintf("%s/gsoep/%sh.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    select(one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -hhnr, na.rm = T) %>%
    full_join(p %>% select(persnr, hhnr) %>% distinct()) %>%
    full_join(p) 
}
```

```{r gsoep codebook}
gsoep_codebook <- (codebook %>% filter(study == "GSOEP"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname))
gsoep_codebook
```

```{r gsoep data, eval = F}
gsoep <- gsoep_codebook %>% 
  select(wave, waveletter, year) %>%
  filter(complete.cases(.)) %>%
  distinct() %>%
  arrange(year) %>%
  filter(year != "2018") %>%
  mutate(data = map2(year, waveletter, gsoep_read_fun)) 

old.names <- unique(gsoep_codebook$orig_itemname)
gsoep_cog <- sprintf("%s/gsoep/cognit.sav", data_path) %>% haven::read_sav(.) %>%
  select(persnr, hhnr, year = syear, one_of(old.names)) %>%
  filter(year == 2012) %>%
  haven::zap_labels(.) %>%
  select(-hhnr) %>%
  gather(key = orig_itemname, value = value, -persnr, -year, na.rm = T)

gsoep_cog_subs <- unique(gsoep_cog$persnr)

gsoep_long <- gsoep %>% unnest(data) %>%
  select(-hhnr) %>%
  filter(persnr %in% gsoep_cog_subs) %>%
  full_join(gsoep_cog) %>%
  select(-wave, -waveletter) %>%
  rename(SID = persnr)

save(gsoep, file = sprintf("%s/data/clean/gsoep_raw.RData", local_path))
rm(gsoep)
```

### Recoding & Reverse Scoring  
```{r gsoep recode, eval = F}
gsoep_waves <- p_waves %>% filter(Study == "GSOEP") %>% select(Used) %>% distinct()

# join data with recoding info 
gsoep_recode <- gsoep_codebook %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %>%
  group_by(category, name) %>% 
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(gsoep_long))) 

# recode 
recode_fun <- function(rule, y, year, p_year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

gsoep_recode <- gsoep_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(p_year = 2005) %>%
    group_by(recode, year, p_year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
gsoep_recode <- gsoep_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```


### Covariates  

```{r gsoep covariates, eval = F}
# composite WITHIN years 
gsoep_cov <- gsoep_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, year, p_year, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(year <= p_year)
      # summarize(value = fun_call(value, comp_rule)) %>%
      # ungroup() %>% 
      # mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
      ))

comp_fun <- function(d, rule, p_year){
  print(paste(rule, p_year))
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
gsoep_cov <- gsoep_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  filter(year <= p_year) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r gsoep personality, eval = F}
gsoep_pers <- gsoep_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(year == "2005" & !is.na(value)) %>%
  group_by(SID, p_year, year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
gsoep_alpha <- gsoep_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
gsoep_pers <- gsoep_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  

```{r gsoep out, eval = F}
# composite within years
gsoep_out <- gsoep_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  group_by(name, year, SID) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  
```{r gsoep combine, eval = F}
gsoep_combined <- gsoep_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(gsoep_out %>% rename(Outcome = name, o_value = value, o_year = year)) %>%
  full_join(gsoep_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r gsoep save, eval = F}
save(gsoep_cov, gsoep_alpha, gsoep_pers, gsoep_out, gsoep_combined,
     file = sprintf("%s/data/clean/gsoep_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("gsoep", ls())])
```
 
## Household, Income, and Labour Dynamics in Australia (HILDA)  

The Household Income and Labour Dynamics in Australia (HILDA; Wilkins, Laß, Butterworth, & Vera-Toscano, 2019) study is an ongoing longitudinal study of Australian households. These data are available through application from https://melbourneinstitute.unimelb.edu.au/hilda/for-data-users.  

Participants were recruited from more than 17,000 individuals. Data have been collected annually since 2001. The latest data release includes 17 waves of data from 2001 to 2017. More documentation can be found in the HILDA data dictionary at https://www.online.fbe.unimelb.edu.au/HILDAodd/srchSubjectAreas.aspx.  

Sample sizes vary by year, ranging from 12,408 (2004) to 17,693 (2016). This provides 99\% power to detect a zero-order correlation effect size of ~.03, two tailed at alpha .05.  

### Load Data  
```{r hilda clean fun, eval = F}
hilda_read_fun <- function(Year, WL){
  old.names <- (hilda_codebook %>% filter(year == Year | year == 0))$orig_itemname
  sprintf("%s/hilda/Combined %s180c.sav", data_path, WL) %>% haven::read_sav(.) %>%
    select(one_of(old.names)) 
}
```

```{r hilda codebook}
hilda_codebook <- (codebook %>% filter(study == "HILDA"))$codebook[[1]]
hilda_codebook
```

```{r hilda data, eval = F}
hilda <- hilda_codebook %>% 
  select(year, wave_letter) %>%
  filter(!is.na(wave_letter)) %>%
  distinct() %>%
  mutate(wave_letter = tolower(wave_letter), 
         data = map2(year, wave_letter, hilda_read_fun)) 

save(hilda, file = sprintf("%s/data/clean/hilda_raw.RData", local_path))
```

### Recoding & Reverse Scoring  

```{r hilda recode, eval = F}
hilda_waves <- p_waves %>% filter(Study == "HILDA") %>% select(Used) %>% distinct()

rename_fun <- function(df, Year){
  df <- df %>%
    haven::zap_labels(.) %>%
    gather(key = orig_itemname, value = value, -xwaveid, na.rm=T) %>%
    mutate(value=as.numeric(value))
  hilda_codebook %>% 
    select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
    filter(year == Year & category %in% c("pers", "outcome", "covariates")) %>%
    full_join(df)
}

# join data with recoding info 
hilda_recode <- hilda %>%
  mutate(data = map2(data, year, rename_fun)) %>% 
  select(-year, -wave_letter) %>%
  unnest(data) %>%
  distinct() %>%
  rename(SID = xwaveid) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup()

# recode 
recode_fun <- function(rule, y, year, p_year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

hilda_recode <- hilda_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(p_year = 2005) %>%
    group_by(recode, year, p_year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
hilda_recode <- hilda_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```


### Covariates  

```{r hilda covariates, eval = F}
# composite WITHIN years 
hilda_cov <- hilda_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, year, p_year, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(year <= p_year)
      # summarize(value = fun_call(value, comp_rule)) %>%
      # ungroup() %>% 
      # mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
      ))

comp_fun <- function(d, rule, p_year){
  print(paste(rule, p_year))
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
hilda_cov <- hilda_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  filter(year <= p_year) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r hilda personality, eval = F}
hilda_pers <- hilda_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(year == "2005" & !is.na(value)) %>%
  group_by(SID, p_year, year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
hilda_alpha <- hilda_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
hilda_pers <- hilda_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  

```{r hilda out, eval = F}
# composite within years
hilda_out <- hilda_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  group_by(name, year, SID) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  

```{r hilda combine, eval = F}
hilda_combined <- hilda_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(hilda_out %>% rename(Outcome = name, o_value = value, o_year = year)) %>%
  full_join(hilda_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r hilda save, eval = F}
save(hilda_cov, hilda_alpha, hilda_pers, hilda_out, hilda_combined,
     file = sprintf("%s/data/clean/hilda_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("hilda", ls())])
```

## Health and Retirement Study (HRS)  
The Health and Retirement Study [HRS; @juster1995overview] is an ongoing longitudinal study of households in the United States. These data are available at https://hrs.isr.umich.edu by creating a free account.  

Participants were recruited from more than 35,000 individuals from the financial households of individuals born between 1931 and 1941 in the US. Data have been collected biannually since 1992. The latest data release includes data up to 2016. On average, 10,000 individuals are sampled each wave More information on the HRS can be found at https://hrs.isr.umich.edu/documentation/survey-design, but, in short, the HRS is a nationally representative sample of adults over 50 in the US. It is critical to note that the HRS samples households of the original cohort and follows individuals and their spouses or partners until their death.  

Sample size varies by year, ranging from approximately 7,500 (2014) to 15,500 (1992). (https://hrs.isr.umich.edu/sites/default/files/biblio/ResponseRates_2017.pdf). This provides 99% power to detect a zero-order correlation effect size of ~.04, two-tailed at alpha .05.  

### Load Data  

```{r hrs clean fun, eval = F}
hrs_read_fun <- function(year) {
  read_da <- function(da, dct, Year){
    print(paste(da, dct, year, sep = " "))
    data.file <- sprintf("%s/hrs/%s/%s", data_path, Year, da)
    # Set path to the dictionary file "*.DCT"
    dict.file <- sprintf("%s/hrs/%s/%s", data_path, Year, dct)
    # Read the dictionary file
    df.dict <- read.table(dict.file, skip = 1, fill = TRUE, stringsAsFactors = FALSE)
    # Set column names for dictionary dataframe
    colnames(df.dict) <- c("col.num","col.type","col.name","col.width","col.lbl")
    # Remove last row which only contains a closing }
    row <- which(df.dict$col.name == "HHID")
    df.dict <- df.dict[-nrow(df.dict),]
    if(row == 2){df.dict <- df.dict[-1,]}
    # Extract numeric value from column width field
    df.dict$col.width <- as.integer(sapply(df.dict$col.width, gsub, pattern = "[^0-9\\.]", replacement = ""))
    # Convert column types to format to be used with read_fwf function
    df.dict$col.type <- sapply(df.dict$col.type, function(x) ifelse(x %in% c("int","byte","long"), "i", ifelse(x == "float", "n", ifelse(x == "double", "d", "c"))))
    # Read the data file into a dataframe
    df <- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = ""))
    # Add column labels to headers
    attributes(df)$variable.labels <- df.dict$col.lbl
    old.names <- (hrs_codebook %>% filter(year == Year))$orig_itemname
    if(any(c("PN", "HHID") %in% colnames(df)) & any(old.names %in% colnames(df))){
    # if(any(c("PN", "HHID") %in% colnames(df))){
      df <- df %>%
      mutate(hhidpn = 1000*as.numeric(HHID) + as.numeric(PN)) %>%
      select(one_of(c("PN", "HHID")), one_of(old.names)) %>%
        distinct()
      # gather(key = item, value = value, -hhidpn)
    } else {df <- NA}
    return(df)
  }
    # Set path to the data file "*.DA"
  files <- list.files(sprintf("%s/hrs/%s", data_path, year))
  df2 <- tibble(
    da = files[grepl(".da",  files) | grepl(".DA", files)],
    dct = files[grepl(".dct", files) | grepl(".DCT", files)]
  ) %>%
    mutate(data = map2(da, dct, possibly(~read_da(.x, .y, year), NA_real_))) %>%
    filter(!is.na(data)) %>%
    select(-da, -dct) 
  if(nrow(df2) != 0){df2$data %>% reduce(full_join) %>% distinct()} else {NA}
}
```

```{r hrs codebook}
hrs_codebook <- (codebook %>% filter(study == "HRS"))$codebook[[1]] %>% 
  mutate(orig_itemname = str_to_upper(orig_itemname)) %>%
  mutate_at(vars(orig_itemname, name, itemname), ~str_remove_all(., "[[:space:]]"))
hrs_codebook
```

```{r hrs data, eval = F}
old.names <- unique(hrs_codebook$orig_itemname)
hrs.paq <- tibble(
  year = sprintf("%s/hrs", data_path) %>% list.files(., pattern = "^[0-9]")
  , data = map(year, hrs_read_fun)
  , names = map(data, colnames)
  ) %>%
  filter(!is.na(data))

old.names <- unique((hrs_codebook %>% filter(dataset == "Rand"))$orig_itemname)
hrs.rand <- sprintf("%s/hrs/randhrs1992_2016v1.sav", data_path) %>% 
  haven::read_sav(.) %>%
  haven::zap_labels(.) %>%
  select(SID = HHIDPN, one_of(old.names)) %>%
  gather(key = orig_itemname, value = value, -SID, na.rm = T)


hrs_long <- hrs.paq %>%
  mutate(data = map(data, ~(.) %>% 
      gather(key = orig_itemname, value = value, -HHID, -PN))) %>%
  select(-names, -year) %>%
  unnest(data) %>%
  mutate(SID = 1000*as.numeric(HHID) + as.numeric(PN)) %>%
  select(-PN, -HHID) 

hrs.subs <- unique(hrs_long$SID)[unique(hrs_long$SID) %in% unique(hrs.rand$SID)]
hrs_long <- hrs_long %>%
  bind_rows(hrs.rand %>% select(orig_itemname, value, SID)) %>%
  filter(SID %in% hrs.subs)

save(hrs.rand, hrs.paq, file = sprintf("%s/data/clean/hrs_raw.RData", local_path))
rm(list = c("hrs.paq", "hrs.rand"))
```

### Recoding & Reverse Scoring  
```{r hrs recode, eval = F}
hrs_waves <- p_waves %>% filter(Study == "HRS") %>% select(Used) %>% distinct()

# join data with recoding info 
hrs_recode <- hrs_codebook %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %>%
  group_by(category, name) %>% 
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(hrs_long))) 

# recode 
recode_fun <- function(rule, y, year, p_year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

hrs_recode <- hrs_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(year = mapvalues(year, seq(2006, 2016, 2), rep(c(2006, 2010, 2014), each = 2)),
           p_year = 2006) %>%
    group_by(recode, year, p_year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
hrs_recode <- hrs_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```


### Covariates  

```{r hrs covariates, eval = F}
# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, p_year, long_rule) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# composite WITHIN years 
hrs_cov <- hrs_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  unnest(data) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

comp_fun <- function(d, rule, p_year){
  d %>%
    filter(year <= p_year) %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
hrs_cov <- hrs_cov %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r hrs personality, eval = F}
hrs_pers <- hrs_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(year == "2006" & !is.na(value)) %>%
  group_by(SID, p_year, year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
hrs_alpha <- hrs_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
hrs_pers <- hrs_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  
```{r hrs out, eval = F}
# composite within years
hrs_out <- hrs_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  group_by(name, year, SID, long_rule) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  filter(year == 2010) %>%
  ungroup() %>%
  select(-long_rule)
```

### Combine Data  
```{r hrs combine, eval = F}
hrs_combined <- hrs_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(hrs_out %>% rename(Outcome = name, o_value = value, o_year = year)) %>%
  full_join(hrs_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r hrs save, eval = F}
save(hrs_cov, hrs_alpha, hrs_pers, hrs_out, hrs_combined,
     file = sprintf("%s/data/clean/hrs_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("hrs", ls())])
```

## Longitudinal Aging Study Amsterdam (LASA)  

The Longitudinal Aging Study Amsterdam is an ongoing longitudinal study that began in 1992. These data are available, through application at https://www.lasa-vu.nl/data/availability_data/availability_data.htm.

Participants who were between 55 and 84 years at the start of the study were recruited from the NESTOR study on Living Arrangements and Social Networks of older adults, which was randomly selected from municipality registers in 1992, with an oversampling of the oldest old and men. Data are collected approximately every three years (1992, 1995, 1998, 2001, 2005, 2008, 2011, 2015, 2018). Additional cohorts are introduced every 10 years, with additional participants (Cohorts 2 and 3) recruited in 2002 and 2012. Additional information and documentation are available at https://www.lasa-vu.nl/index.htm.  

Sample sizes vary by year, ranging from 1522 (Wave H; 763 Cohort 1, 759 Cohort 2) to 3107 (Wave B, Cohort 1). This provides 99\% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 

### Load Data  

```{r lasa clean fun, eval = F}
lasa_read_fun <- function(x){
  d <- sprintf("%s/lasa/%s", data_path, x) %>% 
    read_sav(.) %>% 
    select(one_of(lasa_sids),
           one_of(old.names), 
           one_of(str_to_lower(old.names)),
           one_of(str_to_upper(old.names))) %>%
    as_tibble() %>%
    haven::zap_labels(.)
  colnames(d) <- str_to_lower(colnames(d))
  return(d)
}
```

```{r lasa codebook}
lasa_codebook <- (codebook %>% filter(study == "LASA"))$codebook[[1]] %>%
  mutate(orig_itemname = orig_itemname)
lasa_codebook
```

```{r lasa data, eval = F}
lasa_sids <- c("respnr", "RESPNR", "RespNr", "Respnr")
old.names <- unique(lasa_codebook$orig_itemname)
datasets <- sprintf("%s/lasa", data_path) %>% list.files(., pattern = "SAV")
lasa <- tibble(datasets = datasets) %>%
  mutate(data = map(datasets, lasa_read_fun),
         ncol = map_dbl(data, ncol)) %>%
  filter(ncol > 1)

lasa <- reduce(lasa$data, full_join) %>% 
  haven::zap_labels(.) 

lasa_long <- lasa %>%
  rename(SID = respnr) %>%
  pivot_longer(-SID
               , names_to = "orig_itemname"
               , values_to = "value"
               , values_drop_na = T)

save(lasa, file = sprintf("%s/data/clean/lasa_raw.RData", local_path))
```

### Recoding & Reverse Scoring  

```{r lasa recode, eval = F}
# join data with recoding info 
lasa_recode <- lasa_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(lasa_long)))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

lasa_recode <- lasa_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    group_by(recode, year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
lasa_recode <- lasa_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}

lasa_waves <- lasa_recode %>%
  filter(category == "pers") %>%
  unnest(data) %>%
  group_by(SID) %>%
  summarize(p_year = min(year)) %>%
  ungroup()
```

### Covariates  

```{r lasa covariates, eval = F}
# composite WITHIN years 
lasa_cov <- lasa_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      left_join(lasa_waves) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, year, p_year, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(year <= p_year)
      ))

comp_fun <- function(d, rule, p_year){
  print(paste(rule, p_year))
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
lasa_cov <- lasa_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  filter(year <= p_year) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r lasa personality, eval = F}
lasa_pers <- lasa_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  left_join(lasa_waves) %>%
  filter(year == p_year) %>%
  filter(!is.na(value)) %>%
  group_by(SID, year, p_year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
lasa_alpha <- lasa_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
lasa_pers <- lasa_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  

```{r lasa out, eval = F}
lasa_cog_waves <- lasa_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(name, SID) %>%
  summarize(o_year = max(year)) %>%
  ungroup()
# composite within years
lasa_out <- lasa_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  right_join(lasa_cog_waves) %>%
  filter(year == o_year) %>%
  group_by(name, year, SID) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  

```{r lasa combine, eval = F}
lasa_combined <- lasa_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(
    lasa_out %>% 
      rename(Outcome = name, o_value = value, o_year = year)
    ) %>% full_join(lasa_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r lasa save, eval = F}
save(lasa_cov, lasa_alpha, lasa_pers, lasa_out, lasa_combined,
     file = sprintf("%s/data/clean/lasa_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("lasa", ls())])
```

## MAP  
The RUSH Memory and Aging Project (MAP) is an ongoing longitudinal study that began in 1997 [@a2012overview]. These data are available, through application from https://www.radc.rush.edu/requests.htm.  

Participants who were 65 and older were recruited from retirement communities and subsidized senior housing facilities throughout Chicagoland and northeastern Illinois beginning in 1997. Data are collected annually, and all participants are organ donors. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm.  

Sample sizes vary by year, ranging from 52 (1997) to 2205 participants. This provides 99\% power to detect a zero-order correlation effect size of ~.09, two-tailed at alpha .05.  

### Load Data  

```{r map codebook}
(map_codebook <- (codebook %>% filter(study == "RADC-MAP"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r nlsy data, eval = F}
map <- sprintf("%s/rush-radc/dataset_1034_long_03-25-2021.xlsx", data_path) %>% read_excel() %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx", data_path) %>% read_excel()) %>%
  filter(study == "MAP")
```

### Recoding & Reverse Scoring  

```{r nlsy match, eval = F}
rename_fun <- function(cb, var){
  old.names <- unique((map_codebook %>% filter(name == var))$orig_itemname)
  df <- map %>% 
    select(SID = projid, wave = fu_year, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %>%
    left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule))
}

# join data with recoding info 
map_recode <- map_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

map_recode <- map_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))

# reverse code 
map_recode <- map_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```


### Covariates  

```{r map covariates, eval = F}
# composite WITHIN years 
map_cov <- map_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave == 0)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
map_cov <- map_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r map personality, eval = F}
map_pers <- map_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>% 
  distinct() %>%
  group_by(SID, name) %>%
  filter(wave == min(wave)) %>%
  ungroup() %>%
  select(SID, name, wave, value)
```

### Outcome Variables  

```{r map out, eval = F}
map_cog_waves <- map_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

# composite within years
map_out <- map_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  right_join(map_cog_waves) %>%
  filter(wave == o_year & wave > 0) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, wave) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, wave, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  

```{r map combine}
map_combined <- map_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    map_out %>% 
      rename(Outcome = name, o_value = value, o_year = wave)
    ) %>% full_join(map_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r map save}
save(map_cov, map_pers, map_out, map_combined,
     file = sprintf("%s/data/clean/map_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("map", ls())])
```

## MARS  

The RUSH Minority Aging Research Study (MARS) is an ongoing longitudinal study that began in 2004. These data are available, through application, from https://www.radc.rush.edu/requests.htm.  

Participants were Black individuals 65 and older who were recruited from community locations in the Chicago Metropolitan area and suburbs beginning in 2004. Data are collected annually. Additional participants are recruited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm.  

Sample sizes vary by year, ranging from 80 (2004) to 790 (2020). This provides 99% power to detect a zero-order correlation effect size of ~.17, two-tailed at alpha .05.  


```{r mars codebook}
(mars_codebook <- (codebook %>% filter(study == "MARS"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r mars data, eval = F}
mars <- sprintf("%s/rush-radc/dataset_1034_long_03-26-2021.xlsx", data_path) %>% read_excel() %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_basic_03-26-2021.xlsx", data_path) %>% read_excel()) %>%
  filter(study == "MARS")
```

### Recoding & Reverse Scoring  

```{r nlsy match, eval = F}
rename_fun <- function(cb, var){
  old.names <- unique((mars_codebook %>% filter(name == var))$orig_itemname)
  df <- mars %>% 
    select(SID = projid, wave = fu_year, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %>%
    left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule))
}

# join data with recoding info 
mars_recode <- mars_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

mars_recode <- mars_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))

# reverse code 
mars_recode <- mars_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```


### Covariates  

```{r mars covariates, eval = F}
# composite WITHIN years 
mars_cov <- mars_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave == 0)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
mars_cov <- mars_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r mars personality, eval = F}
mars_pers <- mars_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>% 
  distinct() %>%
  group_by(SID, name) %>%
  filter(wave == min(wave)) %>%
  ungroup() %>%
  select(SID, name, wave, value)
```

### Outcome Variables  

```{r mars out, eval = F}
mars_cog_waves <- mars_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

# composite within years
mars_out <- mars_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  right_join(mars_cog_waves) %>%
  filter(wave == o_year & wave > 0) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, wave) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, wave, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  

```{r mars combine, eval = F}
mars_combined <- mars_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    mars_out %>% 
      rename(Outcome = name, o_value = value, o_year = wave)
    ) %>% full_join(mars_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r mars save, eval = F}
save(mars_cov, mars_pers, mars_out, mars_combined,
     file = sprintf("%s/data/clean/mars_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("mars", ls())])
```

## ROS  
The RUSH Religious Orders Study (ROS) is an ongoing longitudinal study that began in 1994 [@a2012overview]. These data are available, through application from https://www.radc.rush.edu/requests.htm. 

Older (65 and above) Catholic nuns, priests, and brothers with no prior dementia diagnosis and who agreed to annual evaluations and eventual organ donation were recruited from more than 40 groups across the United States. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm.  

Sample sizes vary bt year from 353 participants (1994) to 1487 participants, including 797 deceased participants with autopsy data (2019, 2020). This provides 99\% power to detect a zero-order correlation effect size of ~.11, two-tailed at alpha .05.  

### Load Data  

```{r ros codebook}
(ros_codebook <- (codebook %>% filter(study == "ROS"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r nlsy data, eval = F}
ros <- sprintf("%s/rush-radc/dataset_1034_long_03-25-2021.xlsx", data_path) %>% read_excel() %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx", data_path) %>% read_excel()) %>%
  filter(study == "ROS")
```

### Recoding & Reverse Scoring  

```{r ros match, eval = F}
rename_fun <- function(cb, var){
  old.names <- unique((ros_codebook %>% filter(name == var))$orig_itemname)
  df <- ros %>% 
    select(SID = projid, wave = fu_year, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %>%
    left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule))
}

# join data with recoding info 
ros_recode <- ros_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

ros_recode <- ros_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))

# reverse code 
ros_recode <- ros_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```


### Covariates  

```{r ros covariates, eval = F}
# composite WITHIN years 
ros_cov <- ros_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave == 0)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
ros_cov <- ros_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  
```{r ros personality, eval = F}
ros_pers <- ros_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>% 
  distinct() %>%
  group_by(SID, name) %>%
  filter(wave == min(wave)) %>%
  ungroup() %>%
  select(SID, name, wave, value)
```

### Outcome Variables  
```{r ros out, eval = F}
ros_cog_waves <- ros_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

# composite within years
ros_out <- ros_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  right_join(ros_cog_waves) %>%
  filter(wave == o_year & wave > 0) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, wave) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, wave, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  
```{r ros combine, eval = F}
ros_combined <- ros_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    ros_out %>% 
      rename(Outcome = name, o_value = value, o_year = wave)
    ) %>% full_join(ros_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r ros save, eval = F}
save(ros_cov, ros_pers, ros_out, ros_combined,
     file = sprintf("%s/data/clean/ros_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("ros", ls())])
```

## Origins of the Variances of the Oldest-Old: Octogenarian Twins (OCTO-TWIN)  
The Origins of the Variances of the Oldest-Old: Octogenarian Twins (OCTO-TWIN) study was a longitudinal study of twin-pairs in Sweden born before 1913 that began in 1991. Data are available, by application, from the study leaders at the Karolinska Institute.  

Twin-pairs from the Swedish Twin registry who were born before 1913 were invited to be part of the study in 1991. Additional follow-ups were collected in 1993, 1995, 1997, and 1999 on all surviving twins. The initial sample included 351 twin pairs (149 monozygotic and 202 same-sex dizygotic pairs). More information on the study can be found at https://webcache.googleusercontent.com/search?q=cache:HcheF2l9zc0J:https://psy.gu.se/digitalAssets/1469/1469717_octo-twin-brief-presentation.pdf+&cd=1&hl=en&ct=clnk&gl=us&client=safari.  

Sample sizes vary by year, from 222 (wave 5; 43 pairs) to 702 (wave 1; 351 pairs), which yields 99% power to detect a correlation effect size of ~.19, two-tailed at alpha .05.  

### Load Data  

```{r octo twin codebook}
(octotwin_codebook <- (codebook %>% filter(study == "OCTO-TWIN"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r octo twin data, eval = F}
octotwin <- sprintf("%s/octo-twin/OCTO_Twin_Emorie.sav", data_path) %>% 
  read_sav() %>%
  haven::zap_labels(.)
```

### Recoding & Reverse Scoring  

```{r octo twin match, eval = F}
rename_fun <- function(cb, var){
  old.names <- unique((octotwin_codebook %>% filter(name == var))$orig_itemname)
  df <- octotwin %>% 
    mutate(SID = paste0(v1, v2)) %>%
    select(SID, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, na.rm=T)
  if(length(old.names) > 1){
      df %>% left_join(cb %>% select(itemname, wave, orig_itemname, reverse_code:long_rule))
  } else {
    df %>% left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule) %>% distinct()) %>% mutate(wave = "0")
  }
}

`
# join data with recoding info 
octotwin_recode <- octotwin_codebook %>%
  select(category, name, itemname, wave, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, possibly(rename_fun, NA_real_)))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

octotwin_recode <- octotwin_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
octotwin_recode <- octotwin_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```

### Covariates  

```{r octotwin covariates, eval = F}
# composite WITHIN years 
octotwin_cov <- octotwin_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave <= 1)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
octotwin_cov <- octotwin_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r octotwin personality, eval = F}
octotwin_pers <- octotwin_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(wave == 1 & !is.na(value)) %>%
  group_by(SID, wave, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
octotwin_alpha <- octotwin_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, wave, SID, value) %>%
  group_by(name, wave) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID), check.keys = T), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
octotwin_pers <- octotwin_pers %>%
  group_by(name, comp_rule, wave) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  

```{r octotwin out, eval = F}
octotwin_cog_waves <- octotwin_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

# composite within years
octotwin_out <- octotwin_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  right_join(octotwin_cog_waves) %>%
  filter(wave == o_year & wave > 1) %>%
  group_by(name, wave, SID) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  

```{r octotwin combine, eval = F}
octotwin_combined <- octotwin_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    octotwin_out %>% 
      rename(Outcome = name, o_value = value, o_year = wave)
    ) %>% full_join(octotwin_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r octotwin save, eval = F}
save(octotwin_cov, octotwin_alpha, octotwin_pers, octotwin_out, octotwin_combined,
     file = sprintf("%s/data/clean/octo-twin_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("octotwin", ls())])
```


## Swedish Adoption Twin Study of Aging (SATSA)  

The Swedish Adoption Twin Study of Aging (SATSA) is a longitudinal study of twin pairs from the Swedish Twin Registry that began in 1984. Data are available through the ICPSR database at https://www.icpsr.umich.edu/web/ICPSR/studies/3843.  

All twin-pairs on the Swedish Twin Registry who were separated at an early age were invited to be a part of the study in 1984. A control sample of twins reared together were also included. Additional waves of all participants were collected in 1987, 1990, 1993, 2004, 2007, 2010, 2012, and 2014. More information, including codebooks, scales, and variable search functions can be found at https://www.maelstrom-research.org/mica/individual-study/satsa/#.

Sample sizes vary by wave, ranging from 2018 participants at baseline (1984) to 379 participants (IPT7). Given that the target measures were collected at baseline, this provides 99\% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05.  


### Load Data  

```{r satsa load fun} 
loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}

satsa_read_fun <- function(x){
  # prob_vars <- c("FHEART", "FPARKIN", "FSTROKE")
  y <- sprintf("%s/satsa/%s", data_path, x) %>% loadRData(.) %>% 
    select(SID = TWINNR, one_of(old.names)) %>%
    as_tibble()
  # if(any(prob_vars %in% colnames(y))){
  #   y <- y %>% mutate_at(vars(one_of(prob_vars)), ~as.numeric(as.character(.)))
  #   }
  return(y)
}
```

```{r midus codebook}
satsa_codebook <- (codebook %>% filter(study == "SATSA"))$codebook[[1]] %>%
  mutate_at(vars(orig_itemname), str_to_upper)
satsa_codebook
```

```{r satsa data, eval = F}
old.names <- unique(satsa_codebook$orig_itemname) %>% str_to_upper
datasets <- sprintf("%s/satsa", data_path) %>% list.files(., pattern = ".rda")
satsa <- tibble(datasets = datasets) %>%
  mutate(data = map(datasets, satsa_read_fun),
         ncol = map_dbl(data, ncol)) %>%
  filter(ncol != 0)

satsa <- reduce(satsa$data, full_join) %>% haven::zap_labels(.)
satsa <- satsa %>%
  mutate_if(is.factor, ~as.numeric(sub("^\\(0*([0-9]+)\\).+$", "\\1", .))) 
satsa_long <- satsa %>% 
  gather(key = orig_itemname, value = value, -SID, na.rm = T)
save(satsa, file = sprintf("%s/data/clean/satsa_raw.RData", local_path))
```

### Recoding & Reverse Scoring  

```{r satsa recode, eval = F}
satsa_waves <- p_waves %>% filter(Study == "SATSA") %>% select(Used) %>% distinct()

# join data with recoding info 
satsa_recode <- satsa_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(satsa_long)))

# recode 
recode_fun <- function(rule, y, year, p_year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

satsa_recode <- satsa_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(p_year = 1984) %>%
    group_by(recode, year, p_year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
satsa_recode <- satsa_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```


### Covariates  

```{r satsa covariates, eval = F}
# composite WITHIN years 
satsa_cov <- satsa_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, year, p_year, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(year <= p_year)
      ))

comp_fun <- function(d, rule, p_year){
  print(paste(rule, p_year))
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
satsa_cov <- satsa_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  filter(year <= p_year) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  

```{r satsa personality, eval = F}
satsa_pers <- satsa_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(year == 1984 & !is.na(value)) %>%
  group_by(SID, p_year, year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
satsa_alpha <- satsa_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
satsa_pers <- satsa_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Outcome Variables  

```{r satsa out, eval = F}
# composite within years
satsa_out <- satsa_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) %>%
  filter(year == 1999) %>%
  group_by(name, year, SID) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  ungroup()
```

### Combine Data  

```{r satsa combine, eval = F}
satsa_combined <- satsa_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(satsa_out %>% rename(Outcome = name, o_value = value, o_year = year)) %>%
  full_join(satsa_cov) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r satsa save, eval = F}
save(satsa_cov, satsa_alpha, satsa_pers, satsa_out, satsa_combined,
     file = sprintf("%s/data/clean/satsa_cleaned.RData", local_path))
```

```{r}
rm(list =ls()[grepl("satsa", ls())])
```

## Seattle Longitudinal Study (SLS)  
The Seattle Longitudinal Study is an ongoing longitudinal study of adult Seattle residents that began in 1956. Data are available, by request from https://sls.psychiatry.uw.edu/researchers/public-access-data-sets/.

The first cohort of participants were recruited from HMO plan members of the Group Health Cooperative of Puget Sound in Seattle. Seven years later, the first cohort and a new cohort of similarly aged participants were solicited again. Over the next half century, this procedure was repeated every seven years and is ongoing. More information on the measures collected can be found at https://sls.psychiatry.uw.edu/researchers/measures/. 

Sample sizes vary by year, from 302 (1956) to 421 (2005). This provides 99\% power to detect correlation effect sizes of ~.23, two-tailed alpha at .05.  

## Descriptives of All Studies
```{r}
loadRData <- function(fileName, type){
#loads an RData file, and returns it
    path <- sprintf("%s/data/clean/%s_cleaned.RData", local_path, fileName)
    load(path)
    get(ls()[grepl(type, ls())])
}

ipd_data <- tibble(
  study = studies[!studies %in% c("CNLSY", "SLS")]
  , data = map(str_to_lower(study), ~loadRData(., "combined"))
  ) %>% mutate(
    data = map(data, ~(.) %>% 
                 ungroup() %>% 
                 mutate(SID = as.character(SID)))
    , study = mapvalues(study, studies, studies_long)
  ) %>%
  unnest(data) %>%
  mutate(age = ifelse(is.na(age), p_year - yearBrth, age))

ipd_data <- ipd_data %>% 
  group_by(study, Trait, SID) %>%
  filter(p_year == min(p_year)) %>%
  ungroup() %>%
  select(-p_year, -o_year, -Outcome) %>%
  rename(crystallized = o_value) %>%
  distinct() %>%
  group_by(study) %>%
  nest() %>%
  ungroup() %>%
  mutate(wide_data = map(data, ~(.) %>% pivot_wider(names_from = "Trait", values_from = "p_value")))
```

```{r}
cln <- c("Study", "E", "A", "C", "N", "O", "Crystallized / Knowledge", "Age (Years)", "Education (Years)", "% Women", "Valid N (Range)")

desc_tab <- ipd_data %>%
  select(-p_year, -o_year, -yearBrth, -SRhealth, -gender) %>%
  group_by(study, Trait, Outcome) %>%
  mutate_at(vars(p_value, o_value), 
            ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %>%
  pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %>%
  pivot_wider(names_from = Trait, values_from = p_value, values_fn = mean) %>%
  pivot_longer(cols = c(education:C), values_to = "value", names_to = "item", values_drop_na = T) %>%
  group_by(study, item) %>%
  summarize(est = sprintf("%.2f (%.2f)", mean(value, na.rm = T), sd(value, na.rm = T))) %>%
  ungroup() %>%
  pivot_wider(names_from = item, values_from = est) %>%
  full_join(
    ipd_data %>% 
      select(study, Trait, p_value, Outcome, SID, o_value) %>%
      distinct() %>%
      group_by(study, Trait) %>% 
      tally() %>%
      group_by(study) %>%
      summarize(n = sprintf("%i - %i", min(n), max(n)))
    ) %>%
  full_join(
    ipd_data %>% 
      select(study, SID, gender) %>% 
      distinct()  %>% 
      group_by(study) %>% 
      summarize(gender = mean(gender, na.rm = T)*100) %>% 
      ungroup()
    ) %>%
  select(study, E, A, C, N, O, crystallized, age, education, gender, n) %>%
  kable(., "html"
        , digits = 2
        , col.names = cln
        , caption = "<strong>Table 3</strong><br><em>Descriptive Statistics of All Harmonized Measures Across Samples"
        , align = c("l", rep("c",9))) %>%
  kable_classic(full_width = F, html_font = "Times New Roman") %>%
  add_header_above(c(" " = 1, "Personality Characteristics" = 5, " " = 5)) %>% 
  add_footnote(notation = "none", label = "<em>Note.</em> E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness; Age, education, and gender were assessed at the first baseline personality assessment. Valid N (Range) indicates the range of valid observations with complete personality trait and outcome data across different trait measures.", escape = F)
desc_tab
save_kable(desc_tab, file = sprintf("%s/results/tables/tab-3-desc.html", local_path))
```

```{r}
r_fun <- function(d, study){
  cols <- c("E", "A", "C", "N", "O", "crystallized", "age", "gender", "education")
  cols_long <- mapvalues(cols, c(traits$short_name, outcomes$short_name, covars$short_name)
                         , c(traits$long_name, outcomes$long_name, covars$long_name))
  colns <- paste(1:length(cols), ". ", cols_long, sep = "")
  r <- d %>% 
    select(all_of(cols)) %>%
    cor(., use = "pairwise") 
  r <- apply(r, c(1,2), function(x) ifelse(is.na(x), "", ifelse(x == 1, "--", sprintf("%.2f", x))))
  r[upper.tri(r)] <- ""
  diag(r) <- "--"
  rownames(r) <- colns; colnames(r) <- seq(1,length(cols))
  tab <- r %>% 
    as.data.frame() %>%
    rownames_to_column(" ") %>%
    kable(.
          , "html"
          , escape = F
          , align = c("l", rep("c", length(cols)))
          , caption = sprintf("<strong>Table SX</strong><br><em>Zero-Order Correlations Between All Study Variables in %s</em>", study)
          ) %>%
    kable_classic(full_width = F, html_font = "Times New Roman")
  save_kable(tab, file = sprintf("%s/results/tables/zero-order-cors/%s.html", wd, study))
  return(tab)
}

ipd_cors <- ipd3_meta_data %>%
  select(-p_year, -o_year, -yearBrth, -SRhealth) %>%
  group_by(study, Trait, Outcome) %>%
  mutate_at(vars(p_value, o_value), 
            ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %>%
  pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %>%
  pivot_wider(names_from = Trait, values_from = p_value, values_fn = mean) %>%
  group_by(study) %>% 
  nest() %>% 
  ungroup() %>%
  mutate(rtab = map2(data, study, r_fun))
```


